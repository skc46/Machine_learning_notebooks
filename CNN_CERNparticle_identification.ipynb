{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3DtjEbf8M4I"
   },
   "source": [
    "**Introduction**\n",
    "\n",
    "Machine Learning algorithms have become an increasingly important tool for analyzing the data from the Large Hadron Collider (LHC). Identification of particles in LHC collisions is an important task of LHC detector reconstruction algorithms.\n",
    "\n",
    "Here we present a challenge where one of the detectors (the Electromagnetic Calorimeter or ECAL) is used as a camera to analyze detector images from two types of particles: electrons and photons that deposit their energy in this detector.\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "Each pixel in the image corresponds to a detector cell, while the intensity of the pixel corresponds to how much energy is measured in that cell. Timing of the energy deposits are also available, though this may or may not be relevant. The dataset contains 32x32 Images of the energy hits and their timing (channel 1: hit energy and channel 2: its timing) in each calorimeter cell (one cell = one pixel) for the two classes of particles: Electrons and Photons. The dataset contains around four hundred thousand images for electrons and photons. Please note that your final model will be evaluated on an unseen test dataset.\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    "Please use a Machine Learning model of your choice to achieve the highest possible classification performance on the provided dataset. Please provide a Jupyter Notebook that shows your solution.\n",
    "\n",
    "Evaluation Metrics\n",
    "ROC curve (Receiver Operating Characteristic curve) and AUC score (Area Under the ROC Curve)\n",
    "Training and Validation Accuracy\n",
    "The model performance will be tested on a hidden test dataset based on the above metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0b6SRpWl2Xh"
   },
   "source": [
    "## Create the appropriate project folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OYRULwKaw_A6"
   },
   "outputs": [],
   "source": [
    "mkdir Particle_Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "at-4-Xub8DYW",
    "outputId": "0599feb1-5c1e-472c-ccf5-1a9c0c349ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shambhu\\Desktop\\Projects\\PH482_582\\Particle_Images\n"
     ]
    }
   ],
   "source": [
    "cd Particle_Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BQGKM10j2CiQ"
   },
   "outputs": [],
   "source": [
    "mkdir data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEtRyfNv9XVn"
   },
   "source": [
    "# Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcK1wY4Qt_7Y"
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "!wget https://cernbox.cern.ch/index.php/s/69nGEZjOy3xGxBq/download -O data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BepRE7pn8Du7"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import h5py\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZnLzC5paz0hb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import h5py\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation, GlobalAvgPool2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az_MoJwZ8K6l"
   },
   "source": [
    "# Keras Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZzF8AHl_4yUA"
   },
   "outputs": [],
   "source": [
    "lr_init     = 1.e-3    # Initial learning rate  \n",
    "batch_size  = 64       # Training batch size\n",
    "train_size  = 16000     # Training size\n",
    "valid_size  = 1000     # Validation size\n",
    "test_size   = 1000     # Test size\n",
    "epochs      = 20       # Number of epochs\n",
    "doGPU       = True    # Use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jX_l-WmplJx"
   },
   "source": [
    "## It is recommended to use GPU for training and inference if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PVq1XGr640nJ"
   },
   "outputs": [],
   "source": [
    "if doGPU:\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwc56kXJ8TLo"
   },
   "source": [
    "# Load Image Data\n",
    "### Two classes of particles: electrons and photons\n",
    "### 32x32 matrices (two channels - hit energy and time) for the two classes of particles electrons and photons impinging on a calorimeter (one calorimetric cell = one pixel).\n",
    "#### Please note that although timing channel is provided, it may not necessarily help the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kr4QIMlt424u"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols, nb_channels = 32, 32, 2        \n",
    "input_dir = 'data'\n",
    "decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1_gzip', 'SingleElectronPt50_IMGCROPS_n249k_RHv1_gzip']\n",
    "\n",
    "def load_data(decays, start, stop):\n",
    "    global input_dir\n",
    "    dsets = [h5py.File('%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n",
    "    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n",
    "    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n",
    "    assert len(X) == len(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JpHCOf38fDL"
   },
   "source": [
    "# Configure Training / Validation / Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-RTXS58x46Fq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shambhu\\anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:7: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Set range of training set\n",
    "train_start, train_stop = 0, train_size\n",
    "assert train_stop > train_start\n",
    "assert (len(decays)*train_size) % batch_size == 0\n",
    "X_train, y_train = load_data(decays,train_start,train_stop)\n",
    "\n",
    "# Set range of validation set\n",
    "valid_start, valid_stop = 160000, 160000+valid_size\n",
    "assert valid_stop  >  valid_start\n",
    "assert valid_start >= train_stop\n",
    "X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n",
    "\n",
    "# Set range of test set\n",
    "test_start, test_stop = 180000, 180000+test_size\n",
    "assert test_stop  >  test_start\n",
    "assert test_start >= valid_stop\n",
    "X_test, y_test = load_data(decays,test_start,test_stop)\n",
    "\n",
    "samples_requested = len(decays) * (train_size + valid_size + test_size)\n",
    "samples_available = len(y_train) + len(y_valid) + len(y_test)\n",
    "assert samples_requested == samples_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 32, 32, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = X_train[:,:,:,0]\n",
    "X_valid_1 = X_valid[:,:,:,0]\n",
    "X_train_1 = X_train_1[...,np.newaxis]\n",
    "X_valid_1 = X_valid_1[...,np.newaxis]\n",
    "X_test_1 = X_test[:,:,:,0]\n",
    "X_test_1 = X_test_1[...,np.newaxis]\n",
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTFIMRnL8w41"
   },
   "source": [
    "# Plot sample of training images\n",
    "### Please note that although timing channel is provided, it may not necessarily help the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e_IDs16U52-C"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[40,:,:,0])\n",
    "plt.title(\"Channel 0: Energy\")  # Energy\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1,:,:,1])\n",
    "plt.title(\"Channel 1: Time\")  # Time\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke_NQLiz83jZ"
   },
   "source": [
    "# Model 1: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a LeNet architecture with some modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', input_shape=(img_rows, img_cols,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr_init), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "32000/32000 [==============================] - 13s 410us/sample - loss: 0.7350 - accuracy: 0.5369 - val_loss: 0.7640 - val_accuracy: 0.5005\n",
      "Epoch 2/20\n",
      "32000/32000 [==============================] - 9s 274us/sample - loss: 0.6796 - accuracy: 0.5799 - val_loss: 0.6704 - val_accuracy: 0.5825\n",
      "Epoch 3/20\n",
      "32000/32000 [==============================] - 9s 271us/sample - loss: 0.6637 - accuracy: 0.6022 - val_loss: 0.6661 - val_accuracy: 0.5830\n",
      "Epoch 4/20\n",
      "32000/32000 [==============================] - 9s 274us/sample - loss: 0.6538 - accuracy: 0.6181 - val_loss: 0.6981 - val_accuracy: 0.5360\n",
      "Epoch 5/20\n",
      "32000/32000 [==============================] - 9s 271us/sample - loss: 0.6475 - accuracy: 0.6268 - val_loss: 0.6650 - val_accuracy: 0.5880\n",
      "Epoch 6/20\n",
      "32000/32000 [==============================] - 9s 271us/sample - loss: 0.6399 - accuracy: 0.6346 - val_loss: 0.6509 - val_accuracy: 0.6230\n",
      "Epoch 7/20\n",
      "32000/32000 [==============================] - 9s 282us/sample - loss: 0.6308 - accuracy: 0.6475 - val_loss: 0.6491 - val_accuracy: 0.6265\n",
      "Epoch 8/20\n",
      "32000/32000 [==============================] - 9s 286us/sample - loss: 0.6189 - accuracy: 0.6606 - val_loss: 0.6296 - val_accuracy: 0.6545\n",
      "Epoch 9/20\n",
      "32000/32000 [==============================] - 9s 286us/sample - loss: 0.6032 - accuracy: 0.6788 - val_loss: 0.6340 - val_accuracy: 0.6590\n",
      "Epoch 10/20\n",
      "32000/32000 [==============================] - 9s 286us/sample - loss: 0.5916 - accuracy: 0.6905 - val_loss: 0.8196 - val_accuracy: 0.5500\n",
      "Epoch 11/20\n",
      "32000/32000 [==============================] - 9s 278us/sample - loss: 0.5668 - accuracy: 0.7137 - val_loss: 0.6148 - val_accuracy: 0.6705\n",
      "Epoch 12/20\n",
      "32000/32000 [==============================] - 9s 281us/sample - loss: 0.5502 - accuracy: 0.7259 - val_loss: 0.6744 - val_accuracy: 0.6425\n",
      "Epoch 13/20\n",
      "32000/32000 [==============================] - 9s 280us/sample - loss: 0.5382 - accuracy: 0.7368 - val_loss: 0.6262 - val_accuracy: 0.6600\n",
      "Epoch 14/20\n",
      "32000/32000 [==============================] - 9s 281us/sample - loss: 0.5116 - accuracy: 0.7553 - val_loss: 0.6086 - val_accuracy: 0.6835\n",
      "Epoch 15/20\n",
      "32000/32000 [==============================] - 9s 294us/sample - loss: 0.5004 - accuracy: 0.7638 - val_loss: 0.6238 - val_accuracy: 0.6755\n",
      "Epoch 16/20\n",
      "32000/32000 [==============================] - 9s 283us/sample - loss: 0.4948 - accuracy: 0.7660 - val_loss: 0.6308 - val_accuracy: 0.6725\n",
      "Epoch 17/20\n",
      "32000/32000 [==============================] - 9s 292us/sample - loss: 0.4852 - accuracy: 0.7737 - val_loss: 0.6315 - val_accuracy: 0.6740\n",
      "Epoch 18/20\n",
      "32000/32000 [==============================] - 9s 277us/sample - loss: 0.4847 - accuracy: 0.7741 - val_loss: 0.6322 - val_accuracy: 0.6725\n",
      "Epoch 19/20\n",
      "32000/32000 [==============================] - 9s 277us/sample - loss: 0.4828 - accuracy: 0.7781 - val_loss: 0.6330 - val_accuracy: 0.6750\n",
      "Epoch 20/20\n",
      "32000/32000 [==============================] - 9s 273us/sample - loss: 0.4811 - accuracy: 0.7781 - val_loss: 0.6345 - val_accuracy: 0.6725\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
    "\n",
    "history=model.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 193us/sample - loss: 0.6345 - accuracy: 0.6725\n",
      "\n",
      "Validation loss / accuracy: 0.6345 / 0.6725\n",
      "Validation ROC AUC: 0.73543\n",
      "2000/2000 [==============================] - 0s 173us/sample - loss: 0.6159 - accuracy: 0.7000\n",
      "\n",
      "Test loss / accuracy: 0.6159 / 0.7000\n",
      "Test ROC AUC: 0.749857\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"hack_02_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='Model ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Changing the filter size in the above model\n",
    "\n",
    "This model is trained by using the best learning parameters obtained by using RandomizedsearchCV, which is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "id": "OlIJuxXG7KDk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        304       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,156,225\n",
      "Trainable params: 1,155,009\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01), input_shape=(img_rows, img_cols, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01992351943721117), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsQWFD0M86pA"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "ZGuyM25L7uc0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "256000/256000 [==============================] - 107s 420us/sample - loss: 1.4912 - accuracy: 0.5102 - val_loss: 1.2023 - val_accuracy: 0.5012\n",
      "Epoch 2/20\n",
      "256000/256000 [==============================] - 105s 410us/sample - loss: 1.1754 - accuracy: 0.5058 - val_loss: 1.0098 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "256000/256000 [==============================] - 106s 415us/sample - loss: 1.1443 - accuracy: 0.5071 - val_loss: 0.8357 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "256000/256000 [==============================] - 108s 421us/sample - loss: 1.1204 - accuracy: 0.5074 - val_loss: 0.9770 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "256000/256000 [==============================] - 108s 424us/sample - loss: 1.1375 - accuracy: 0.5070 - val_loss: 1.6272 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "256000/256000 [==============================] - 110s 430us/sample - loss: 0.6922 - accuracy: 0.6268 - val_loss: 4.5997 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "256000/256000 [==============================] - 109s 427us/sample - loss: 0.6671 - accuracy: 0.6709 - val_loss: 1.0638 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "256000/256000 [==============================] - 109s 427us/sample - loss: 0.6158 - accuracy: 0.7002 - val_loss: 0.6116 - val_accuracy: 0.6912\n",
      "Epoch 9/20\n",
      "256000/256000 [==============================] - 107s 419us/sample - loss: 0.6049 - accuracy: 0.7038 - val_loss: 0.6105 - val_accuracy: 0.6885\n",
      "Epoch 10/20\n",
      "256000/256000 [==============================] - 107s 417us/sample - loss: 0.6018 - accuracy: 0.7058 - val_loss: 0.6068 - val_accuracy: 0.6955\n",
      "Epoch 11/20\n",
      "256000/256000 [==============================] - 108s 424us/sample - loss: 0.5994 - accuracy: 0.7071 - val_loss: 0.5985 - val_accuracy: 0.7048\n",
      "Epoch 12/20\n",
      "256000/256000 [==============================] - 111s 432us/sample - loss: 0.5982 - accuracy: 0.7075 - val_loss: 0.6631 - val_accuracy: 0.6082\n",
      "Epoch 13/20\n",
      "256000/256000 [==============================] - 107s 418us/sample - loss: 0.5972 - accuracy: 0.7088 - val_loss: 0.6080 - val_accuracy: 0.6861\n",
      "Epoch 14/20\n",
      "256000/256000 [==============================] - 106s 413us/sample - loss: 0.5932 - accuracy: 0.7111 - val_loss: 0.5800 - val_accuracy: 0.7174\n",
      "Epoch 15/20\n",
      "256000/256000 [==============================] - 105s 412us/sample - loss: 0.5923 - accuracy: 0.7125 - val_loss: 0.5879 - val_accuracy: 0.7110\n",
      "Epoch 16/20\n",
      "256000/256000 [==============================] - 105s 411us/sample - loss: 0.5918 - accuracy: 0.7121 - val_loss: 0.5787 - val_accuracy: 0.7182\n",
      "Epoch 17/20\n",
      "256000/256000 [==============================] - 105s 411us/sample - loss: 0.5915 - accuracy: 0.7121 - val_loss: 0.5784 - val_accuracy: 0.7183\n",
      "Epoch 18/20\n",
      "256000/256000 [==============================] - 105s 409us/sample - loss: 0.5910 - accuracy: 0.7132 - val_loss: 0.5788 - val_accuracy: 0.7161\n",
      "Epoch 19/20\n",
      "256000/256000 [==============================] - 107s 419us/sample - loss: 0.5905 - accuracy: 0.7132 - val_loss: 0.5781 - val_accuracy: 0.7174\n",
      "Epoch 20/20\n",
      "256000/256000 [==============================] - 108s 422us/sample - loss: 0.5903 - accuracy: 0.7132 - val_loss: 0.5779 - val_accuracy: 0.7168\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=2, min_lr=1.e-6)\n",
    "history=model.fit(X_train, y_train,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLoN43278_-j"
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ekuQLYas7xh5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 233us/sample - loss: 0.5825 - accuracy: 0.7143\n",
      "\n",
      "Validation loss / accuracy: 0.5825 / 0.7143\n",
      "Validation ROC AUC: 0.777117625\n",
      "4000/4000 [==============================] - 1s 154us/sample - loss: 0.5898 - accuracy: 0.7078\n",
      "\n",
      "Test loss / accuracy: 0.5898 / 0.7078\n",
      "Test ROC AUC: 0.7684195\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "kmSRYI0R72Wn"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "#plt.legend(loc=2, prop={'size': 15})\n",
    "plt.plot(fpr, tpr, label='Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant improvement in the model performance even after using the optimized parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek82eKnpBuI8"
   },
   "source": [
    "# Grid search for best learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is hyperparameter tuning is for the model 2 shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(lr_init=1.e-3, factors = 0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01), input_shape=(img_rows, img_cols, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, activation='relu', kernel_size=3, padding='same', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr_init), metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factors, patience=2, min_lr=1.e-6)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_wrap = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 475us/sample - loss: 5.5601 - accuracy: 0.6522 - val_loss: 3.6202 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 338us/sample - loss: 2.3192 - accuracy: 0.7358 - val_loss: 1.9886 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 1.3884 - accuracy: 0.7437 - val_loss: 1.4966 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.9862 - accuracy: 0.7498 - val_loss: 1.2798 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.7875 - accuracy: 0.7516 - val_loss: 1.1469 - val_accuracy: 0.5002\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 339us/sample - loss: 0.6955 - accuracy: 0.7516 - val_loss: 1.1607 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6435 - accuracy: 0.7540 - val_loss: 0.9034 - val_accuracy: 0.5257\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6368 - accuracy: 0.7537 - val_loss: 1.0364 - val_accuracy: 0.5033\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5996 - accuracy: 0.7550 - val_loss: 0.7614 - val_accuracy: 0.5835\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 347us/sample - loss: 0.5951 - accuracy: 0.7551 - val_loss: 1.0743 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 360us/sample - loss: 0.5767 - accuracy: 0.7583 - val_loss: 0.9345 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 350us/sample - loss: 0.5536 - accuracy: 0.7633 - val_loss: 0.8040 - val_accuracy: 0.5253\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 0.5428 - accuracy: 0.7661 - val_loss: 0.7449 - val_accuracy: 0.6280\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5375 - accuracy: 0.7672 - val_loss: 1.0398 - val_accuracy: 0.5017\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 348us/sample - loss: 0.5331 - accuracy: 0.7702 - val_loss: 0.7460 - val_accuracy: 0.5993\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 360us/sample - loss: 0.5162 - accuracy: 0.7799 - val_loss: 0.9821 - val_accuracy: 0.5142\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 352us/sample - loss: 0.5106 - accuracy: 0.7828 - val_loss: 0.8935 - val_accuracy: 0.5312\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5023 - accuracy: 0.7846 - val_loss: 0.8090 - val_accuracy: 0.5700\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.5001 - accuracy: 0.7832 - val_loss: 0.7725 - val_accuracy: 0.5987\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 346us/sample - loss: 0.4984 - accuracy: 0.7846 - val_loss: 0.7946 - val_accuracy: 0.5845\n",
      "10667/10667 [==============================] - 2s 221us/sample - loss: 1.2863 - accuracy: 0.2325\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 438us/sample - loss: 6.2184 - accuracy: 0.5330 - val_loss: 4.0352 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 2.9744 - accuracy: 0.5631 - val_loss: 2.2379 - val_accuracy: 0.5475\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 1.8380 - accuracy: 0.5775 - val_loss: 1.5354 - val_accuracy: 0.5353\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 1.3302 - accuracy: 0.5898 - val_loss: 1.1707 - val_accuracy: 0.5915\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 1.0495 - accuracy: 0.5967 - val_loss: 0.9673 - val_accuracy: 0.5740\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.9119 - accuracy: 0.6053 - val_loss: 0.8776 - val_accuracy: 0.5895\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.8170 - accuracy: 0.6094 - val_loss: 0.8102 - val_accuracy: 0.5485\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.7615 - accuracy: 0.6159 - val_loss: 0.7562 - val_accuracy: 0.5955\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.7305 - accuracy: 0.6174 - val_loss: 0.7795 - val_accuracy: 0.5160\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.7115 - accuracy: 0.6230 - val_loss: 0.7277 - val_accuracy: 0.5760\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.6969 - accuracy: 0.6295 - val_loss: 0.6926 - val_accuracy: 0.6227\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 334us/sample - loss: 0.6832 - accuracy: 0.6347 - val_loss: 0.7028 - val_accuracy: 0.6050\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.6808 - accuracy: 0.6426 - val_loss: 0.8256 - val_accuracy: 0.5500\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 336us/sample - loss: 0.6506 - accuracy: 0.6684 - val_loss: 0.6576 - val_accuracy: 0.6545\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.6356 - accuracy: 0.6813 - val_loss: 0.6490 - val_accuracy: 0.6620\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 335us/sample - loss: 0.6247 - accuracy: 0.6905 - val_loss: 0.6570 - val_accuracy: 0.6570\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 333us/sample - loss: 0.6205 - accuracy: 0.6965 - val_loss: 0.6501 - val_accuracy: 0.6615\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 335us/sample - loss: 0.6003 - accuracy: 0.7176 - val_loss: 0.6555 - val_accuracy: 0.6603\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 335us/sample - loss: 0.5874 - accuracy: 0.7232 - val_loss: 0.6543 - val_accuracy: 0.6653\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 334us/sample - loss: 0.5723 - accuracy: 0.7356 - val_loss: 0.6583 - val_accuracy: 0.6690\n",
      "10667/10667 [==============================] - 2s 187us/sample - loss: 0.6673 - accuracy: 0.6623\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 10s 482us/sample - loss: 5.7685 - accuracy: 0.6504 - val_loss: 3.7326 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 334us/sample - loss: 2.5136 - accuracy: 0.7220 - val_loss: 2.0567 - val_accuracy: 0.5005\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 333us/sample - loss: 1.5049 - accuracy: 0.7329 - val_loss: 1.3678 - val_accuracy: 0.5140\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 7s 335us/sample - loss: 1.0579 - accuracy: 0.7389 - val_loss: 1.2515 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 334us/sample - loss: 0.8237 - accuracy: 0.7445 - val_loss: 1.0461 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 334us/sample - loss: 0.7059 - accuracy: 0.7461 - val_loss: 0.8472 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 334us/sample - loss: 0.6463 - accuracy: 0.7467 - val_loss: 0.8974 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 335us/sample - loss: 0.6147 - accuracy: 0.7475 - val_loss: 0.7928 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 333us/sample - loss: 0.5952 - accuracy: 0.7485 - val_loss: 0.8303 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 336us/sample - loss: 0.5849 - accuracy: 0.7493 - val_loss: 1.1307 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 333us/sample - loss: 0.5666 - accuracy: 0.7495 - val_loss: 0.8000 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 335us/sample - loss: 0.5555 - accuracy: 0.7498 - val_loss: 0.8532 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 335us/sample - loss: 0.5472 - accuracy: 0.7499 - val_loss: 0.7529 - val_accuracy: 0.5002\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 7s 332us/sample - loss: 0.5427 - accuracy: 0.7496 - val_loss: 0.7712 - val_accuracy: 0.4995\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 336us/sample - loss: 0.5365 - accuracy: 0.7494 - val_loss: 0.7803 - val_accuracy: 0.5027\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 345us/sample - loss: 0.5303 - accuracy: 0.7496 - val_loss: 0.8116 - val_accuracy: 0.5080\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 351us/sample - loss: 0.5268 - accuracy: 0.7502 - val_loss: 0.7991 - val_accuracy: 0.5153\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.5232 - accuracy: 0.7528 - val_loss: 0.8152 - val_accuracy: 0.5205\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 335us/sample - loss: 0.5226 - accuracy: 0.7533 - val_loss: 0.8210 - val_accuracy: 0.5200\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 334us/sample - loss: 0.5227 - accuracy: 0.7543 - val_loss: 0.8193 - val_accuracy: 0.5232\n",
      "10666/10666 [==============================] - 2s 206us/sample - loss: 1.3011 - accuracy: 0.0939\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 445us/sample - loss: 3.7703 - accuracy: 0.6933 - val_loss: 2.1247 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 10s 483us/sample - loss: 1.0828 - accuracy: 0.7449 - val_loss: 1.3859 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 352us/sample - loss: 0.7062 - accuracy: 0.7482 - val_loss: 1.0141 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 338us/sample - loss: 0.6194 - accuracy: 0.7502 - val_loss: 1.0576 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6052 - accuracy: 0.7509 - val_loss: 0.7688 - val_accuracy: 0.5878\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5920 - accuracy: 0.7529 - val_loss: 0.9087 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 347us/sample - loss: 0.5883 - accuracy: 0.7523 - val_loss: 0.8283 - val_accuracy: 0.5023\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5546 - accuracy: 0.7584 - val_loss: 0.9103 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5454 - accuracy: 0.7608 - val_loss: 0.9001 - val_accuracy: 0.5238\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.5327 - accuracy: 0.7628 - val_loss: 0.9988 - val_accuracy: 0.5002\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5226 - accuracy: 0.7684 - val_loss: 0.7248 - val_accuracy: 0.5920\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 358us/sample - loss: 0.5168 - accuracy: 0.7697 - val_loss: 0.6865 - val_accuracy: 0.6317\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 350us/sample - loss: 0.5126 - accuracy: 0.7729 - val_loss: 0.8604 - val_accuracy: 0.5300\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.5076 - accuracy: 0.7765 - val_loss: 1.0262 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.4979 - accuracy: 0.7810 - val_loss: 0.8133 - val_accuracy: 0.5562\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.4932 - accuracy: 0.7842 - val_loss: 0.7754 - val_accuracy: 0.5753\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.4876 - accuracy: 0.7876 - val_loss: 0.7668 - val_accuracy: 0.5932\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.4881 - accuracy: 0.7868 - val_loss: 0.7652 - val_accuracy: 0.5913\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.4869 - accuracy: 0.7872 - val_loss: 0.7571 - val_accuracy: 0.6045\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.4864 - accuracy: 0.7868 - val_loss: 0.7468 - val_accuracy: 0.6095\n",
      "10667/10667 [==============================] - 2s 185us/sample - loss: 1.1897 - accuracy: 0.3048\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 432us/sample - loss: 3.7328 - accuracy: 0.5554 - val_loss: 1.5995 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 1.1456 - accuracy: 0.5824 - val_loss: 0.9932 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.8016 - accuracy: 0.6035 - val_loss: 0.7496 - val_accuracy: 0.6075\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.7227 - accuracy: 0.6098 - val_loss: 0.7172 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6990 - accuracy: 0.6102 - val_loss: 0.7574 - val_accuracy: 0.5002\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.6913 - accuracy: 0.6125 - val_loss: 0.6999 - val_accuracy: 0.5950\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.7001 - accuracy: 0.6220 - val_loss: 0.8039 - val_accuracy: 0.5272\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.7000 - accuracy: 0.6322 - val_loss: 1.0730 - val_accuracy: 0.5040\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6468 - accuracy: 0.6668 - val_loss: 0.6492 - val_accuracy: 0.6773\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.6343 - accuracy: 0.6826 - val_loss: 0.6557 - val_accuracy: 0.6447\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6286 - accuracy: 0.6925 - val_loss: 0.6482 - val_accuracy: 0.6835\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6221 - accuracy: 0.6949 - val_loss: 0.7168 - val_accuracy: 0.5173\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6221 - accuracy: 0.6969 - val_loss: 0.6901 - val_accuracy: 0.5257\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6018 - accuracy: 0.7116 - val_loss: 0.6144 - val_accuracy: 0.7088\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5917 - accuracy: 0.7138 - val_loss: 0.6097 - val_accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5889 - accuracy: 0.7158 - val_loss: 0.6229 - val_accuracy: 0.6858\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5842 - accuracy: 0.7188 - val_loss: 0.6133 - val_accuracy: 0.7020\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.5767 - accuracy: 0.7258 - val_loss: 0.6005 - val_accuracy: 0.7028\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.5720 - accuracy: 0.7294 - val_loss: 0.5983 - val_accuracy: 0.7038\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.5700 - accuracy: 0.7307 - val_loss: 0.6030 - val_accuracy: 0.7103\n",
      "10667/10667 [==============================] - 2s 184us/sample - loss: 0.5949 - accuracy: 0.7103\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 9s 433us/sample - loss: 3.6202 - accuracy: 0.6979 - val_loss: 1.6685 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 1.0086 - accuracy: 0.7433 - val_loss: 0.9173 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.6844 - accuracy: 0.7463 - val_loss: 0.8630 - val_accuracy: 0.4990\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.6180 - accuracy: 0.7484 - val_loss: 0.8399 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.6005 - accuracy: 0.7480 - val_loss: 0.8392 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 344us/sample - loss: 0.5868 - accuracy: 0.7495 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 340us/sample - loss: 0.5982 - accuracy: 0.7478 - val_loss: 0.7711 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 330us/sample - loss: 0.5778 - accuracy: 0.7486 - val_loss: 0.8015 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 331us/sample - loss: 0.5896 - accuracy: 0.7489 - val_loss: 0.7597 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.5857 - accuracy: 0.7497 - val_loss: 2.4486 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 330us/sample - loss: 0.5794 - accuracy: 0.7480 - val_loss: 0.7322 - val_accuracy: 0.5615\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5799 - accuracy: 0.7470 - val_loss: 1.0703 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.5757 - accuracy: 0.7462 - val_loss: 1.3494 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5354 - accuracy: 0.7505 - val_loss: 1.0048 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 330us/sample - loss: 0.5222 - accuracy: 0.7502 - val_loss: 0.6861 - val_accuracy: 0.6325\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.5179 - accuracy: 0.7507 - val_loss: 0.6835 - val_accuracy: 0.6660\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.5218 - accuracy: 0.7519 - val_loss: 0.9215 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.5161 - accuracy: 0.7523 - val_loss: 0.6486 - val_accuracy: 0.6543\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.5117 - accuracy: 0.7542 - val_loss: 0.6812 - val_accuracy: 0.6223\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5117 - accuracy: 0.7544 - val_loss: 0.6831 - val_accuracy: 0.5893\n",
      "10666/10666 [==============================] - 2s 183us/sample - loss: 0.9902 - accuracy: 0.2654\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 437us/sample - loss: 3.0598 - accuracy: 0.7033 - val_loss: 1.6383 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.8463 - accuracy: 0.7445 - val_loss: 0.9612 - val_accuracy: 0.5410\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.6777 - accuracy: 0.7517 - val_loss: 1.0496 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.6149 - accuracy: 0.7523 - val_loss: 1.0821 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.5627 - accuracy: 0.7563 - val_loss: 0.9861 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.5464 - accuracy: 0.7592 - val_loss: 1.1904 - val_accuracy: 0.5045\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.5307 - accuracy: 0.7641 - val_loss: 1.0186 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.5199 - accuracy: 0.7691 - val_loss: 0.8484 - val_accuracy: 0.5255\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.5135 - accuracy: 0.7749 - val_loss: 0.9511 - val_accuracy: 0.5140\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.5086 - accuracy: 0.7761 - val_loss: 1.0236 - val_accuracy: 0.5002\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.4986 - accuracy: 0.7819 - val_loss: 0.8333 - val_accuracy: 0.5460\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.4930 - accuracy: 0.7834 - val_loss: 0.7861 - val_accuracy: 0.5688\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.4890 - accuracy: 0.7853 - val_loss: 0.7742 - val_accuracy: 0.5938\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.4869 - accuracy: 0.7884 - val_loss: 0.8378 - val_accuracy: 0.5315\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.4841 - accuracy: 0.7884 - val_loss: 0.7562 - val_accuracy: 0.5910\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.4817 - accuracy: 0.7905 - val_loss: 0.8139 - val_accuracy: 0.5645\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.4782 - accuracy: 0.7904 - val_loss: 0.7366 - val_accuracy: 0.6438\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.4753 - accuracy: 0.7924 - val_loss: 0.7900 - val_accuracy: 0.5782\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.4726 - accuracy: 0.7931 - val_loss: 0.7256 - val_accuracy: 0.6127\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.4690 - accuracy: 0.7974 - val_loss: 0.8104 - val_accuracy: 0.5738\n",
      "10667/10667 [==============================] - 2s 182us/sample - loss: 1.4009 - accuracy: 0.1898\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 452us/sample - loss: 3.3009 - accuracy: 0.5490 - val_loss: 1.2583 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.9435 - accuracy: 0.5873 - val_loss: 0.8269 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.7424 - accuracy: 0.6060 - val_loss: 0.7608 - val_accuracy: 0.5090\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.7058 - accuracy: 0.6147 - val_loss: 0.7052 - val_accuracy: 0.6225\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.7053 - accuracy: 0.6182 - val_loss: 0.7186 - val_accuracy: 0.6122\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.7073 - accuracy: 0.6268 - val_loss: 1.7967 - val_accuracy: 0.5023\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.6624 - accuracy: 0.6594 - val_loss: 0.6709 - val_accuracy: 0.6413\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 336us/sample - loss: 0.6406 - accuracy: 0.6757 - val_loss: 0.6520 - val_accuracy: 0.6752\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6310 - accuracy: 0.6887 - val_loss: 0.7159 - val_accuracy: 0.6283\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6257 - accuracy: 0.6915 - val_loss: 0.6646 - val_accuracy: 0.5987\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.6069 - accuracy: 0.7045 - val_loss: 0.5984 - val_accuracy: 0.7075\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5965 - accuracy: 0.7114 - val_loss: 0.6252 - val_accuracy: 0.6808\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5924 - accuracy: 0.7127 - val_loss: 0.6195 - val_accuracy: 0.6848\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 323us/sample - loss: 0.5827 - accuracy: 0.7176 - val_loss: 0.5828 - val_accuracy: 0.7210\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5768 - accuracy: 0.7243 - val_loss: 0.5815 - val_accuracy: 0.7220\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5749 - accuracy: 0.7241 - val_loss: 0.5990 - val_accuracy: 0.7085\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5738 - accuracy: 0.7258 - val_loss: 0.5776 - val_accuracy: 0.7200\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.5695 - accuracy: 0.7265 - val_loss: 0.5928 - val_accuracy: 0.7130\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5693 - accuracy: 0.7247 - val_loss: 0.5789 - val_accuracy: 0.7235\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.5666 - accuracy: 0.7298 - val_loss: 0.5773 - val_accuracy: 0.7220\n",
      "10667/10667 [==============================] - 2s 189us/sample - loss: 0.5778 - accuracy: 0.7155\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 9s 432us/sample - loss: 3.0208 - accuracy: 0.7025 - val_loss: 1.4011 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.7937 - accuracy: 0.7416 - val_loss: 0.8005 - val_accuracy: 0.5020\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.6461 - accuracy: 0.7463 - val_loss: 0.8202 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.6130 - accuracy: 0.7481 - val_loss: 0.8245 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5639 - accuracy: 0.7495 - val_loss: 0.7143 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5521 - accuracy: 0.7493 - val_loss: 0.7235 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5468 - accuracy: 0.7488 - val_loss: 0.7047 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5474 - accuracy: 0.7490 - val_loss: 1.7299 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5370 - accuracy: 0.7481 - val_loss: 1.0739 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5236 - accuracy: 0.7485 - val_loss: 0.7367 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.5138 - accuracy: 0.7487 - val_loss: 0.7481 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.5072 - accuracy: 0.7452 - val_loss: 0.7862 - val_accuracy: 0.5238\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5027 - accuracy: 0.7526 - val_loss: 0.7264 - val_accuracy: 0.5132\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.4955 - accuracy: 0.7556 - val_loss: 0.7422 - val_accuracy: 0.5390\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.4937 - accuracy: 0.7571 - val_loss: 0.7296 - val_accuracy: 0.5695\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.4920 - accuracy: 0.7584 - val_loss: 0.7162 - val_accuracy: 0.5660\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.4902 - accuracy: 0.7591 - val_loss: 0.7253 - val_accuracy: 0.5660\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.4910 - accuracy: 0.7594 - val_loss: 0.7177 - val_accuracy: 0.5742\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.4895 - accuracy: 0.7615 - val_loss: 0.7444 - val_accuracy: 0.5665\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.4899 - accuracy: 0.7616 - val_loss: 0.7344 - val_accuracy: 0.5677\n",
      "10666/10666 [==============================] - 2s 185us/sample - loss: 1.1707 - accuracy: 0.2018\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 429us/sample - loss: 5.2343 - accuracy: 0.6655 - val_loss: 3.4968 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 322us/sample - loss: 2.0010 - accuracy: 0.7338 - val_loss: 1.7971 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 1.1818 - accuracy: 0.7427 - val_loss: 1.3725 - val_accuracy: 0.5005\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.8539 - accuracy: 0.7475 - val_loss: 1.2119 - val_accuracy: 0.5008\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 323us/sample - loss: 0.7202 - accuracy: 0.7484 - val_loss: 0.9492 - val_accuracy: 0.5027\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6493 - accuracy: 0.7507 - val_loss: 1.0357 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.6383 - accuracy: 0.7519 - val_loss: 0.8015 - val_accuracy: 0.5520\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6266 - accuracy: 0.7553 - val_loss: 0.9264 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.5860 - accuracy: 0.7538 - val_loss: 0.7985 - val_accuracy: 0.5530\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.5783 - accuracy: 0.7577 - val_loss: 0.8215 - val_accuracy: 0.5040\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.5642 - accuracy: 0.7550 - val_loss: 1.1089 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.5456 - accuracy: 0.7616 - val_loss: 0.8744 - val_accuracy: 0.5025\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5388 - accuracy: 0.7641 - val_loss: 0.9976 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5241 - accuracy: 0.7724 - val_loss: 0.8555 - val_accuracy: 0.5275\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.5188 - accuracy: 0.7741 - val_loss: 0.7452 - val_accuracy: 0.5957\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.5149 - accuracy: 0.7765 - val_loss: 0.6984 - val_accuracy: 0.6340\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5111 - accuracy: 0.7774 - val_loss: 0.8207 - val_accuracy: 0.5335\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 323us/sample - loss: 0.5072 - accuracy: 0.7798 - val_loss: 0.8677 - val_accuracy: 0.5475\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.4953 - accuracy: 0.7838 - val_loss: 0.8017 - val_accuracy: 0.5583\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.4911 - accuracy: 0.7837 - val_loss: 0.7636 - val_accuracy: 0.5840\n",
      "10667/10667 [==============================] - 2s 188us/sample - loss: 1.1977 - accuracy: 0.2625\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 432us/sample - loss: 5.5650 - accuracy: 0.5478 - val_loss: 3.1739 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 2.2921 - accuracy: 0.5663 - val_loss: 1.6996 - val_accuracy: 0.5002\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 1.3717 - accuracy: 0.5869 - val_loss: 1.1646 - val_accuracy: 0.5225\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 1.0099 - accuracy: 0.5975 - val_loss: 0.8975 - val_accuracy: 0.6037\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.8403 - accuracy: 0.6040 - val_loss: 0.8262 - val_accuracy: 0.5110\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.7590 - accuracy: 0.6127 - val_loss: 0.7509 - val_accuracy: 0.5845\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.7218 - accuracy: 0.6143 - val_loss: 0.7089 - val_accuracy: 0.6155\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.7013 - accuracy: 0.6152 - val_loss: 0.7063 - val_accuracy: 0.6077\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6875 - accuracy: 0.6227 - val_loss: 0.6854 - val_accuracy: 0.6200\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.6764 - accuracy: 0.6307 - val_loss: 0.7091 - val_accuracy: 0.5585\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6724 - accuracy: 0.6387 - val_loss: 0.7292 - val_accuracy: 0.5580\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6485 - accuracy: 0.6610 - val_loss: 0.6907 - val_accuracy: 0.5945\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6388 - accuracy: 0.6695 - val_loss: 0.6715 - val_accuracy: 0.6283\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6360 - accuracy: 0.6729 - val_loss: 0.6607 - val_accuracy: 0.6472\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6294 - accuracy: 0.6808 - val_loss: 0.6564 - val_accuracy: 0.6417\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.6245 - accuracy: 0.6832 - val_loss: 0.7513 - val_accuracy: 0.5295\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6186 - accuracy: 0.6903 - val_loss: 0.6631 - val_accuracy: 0.6593\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6026 - accuracy: 0.7094 - val_loss: 0.6467 - val_accuracy: 0.6607\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.5932 - accuracy: 0.7140 - val_loss: 0.7316 - val_accuracy: 0.5763\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5868 - accuracy: 0.7180 - val_loss: 0.7095 - val_accuracy: 0.6492\n",
      "10667/10667 [==============================] - 2s 182us/sample - loss: 0.7057 - accuracy: 0.6547\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 9s 434us/sample - loss: 5.2954 - accuracy: 0.6630 - val_loss: 3.0314 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 2.0497 - accuracy: 0.7282 - val_loss: 1.6595 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 1.1749 - accuracy: 0.7410 - val_loss: 1.0730 - val_accuracy: 0.5907\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.8459 - accuracy: 0.7456 - val_loss: 0.9698 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.6994 - accuracy: 0.7472 - val_loss: 0.9008 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.6361 - accuracy: 0.7473 - val_loss: 0.8538 - val_accuracy: 0.4990\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.6022 - accuracy: 0.7495 - val_loss: 0.8736 - val_accuracy: 0.5015\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 330us/sample - loss: 0.5982 - accuracy: 0.7489 - val_loss: 1.1479 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 324us/sample - loss: 0.5717 - accuracy: 0.7499 - val_loss: 0.8203 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5614 - accuracy: 0.7496 - val_loss: 0.7774 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5570 - accuracy: 0.7500 - val_loss: 0.7218 - val_accuracy: 0.5667\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.5530 - accuracy: 0.7492 - val_loss: 0.8772 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5519 - accuracy: 0.7496 - val_loss: 0.8153 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5378 - accuracy: 0.7493 - val_loss: 0.8313 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 330us/sample - loss: 0.5323 - accuracy: 0.7484 - val_loss: 0.8727 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.5233 - accuracy: 0.7485 - val_loss: 0.7950 - val_accuracy: 0.4997\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.5195 - accuracy: 0.7483 - val_loss: 0.7904 - val_accuracy: 0.5017\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5159 - accuracy: 0.7504 - val_loss: 0.8300 - val_accuracy: 0.5042\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 329us/sample - loss: 0.5150 - accuracy: 0.7489 - val_loss: 0.8282 - val_accuracy: 0.5073\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.5135 - accuracy: 0.7490 - val_loss: 0.8300 - val_accuracy: 0.5130\n",
      "10666/10666 [==============================] - 2s 184us/sample - loss: 1.3186 - accuracy: 0.0293\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 431us/sample - loss: 1.9963 - accuracy: 0.7360 - val_loss: 1.6173 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.9883 - accuracy: 0.7490 - val_loss: 1.4273 - val_accuracy: 0.5393\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.9015 - accuracy: 0.7496 - val_loss: 0.9530 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.8144 - accuracy: 0.7498 - val_loss: 1.4930 - val_accuracy: 0.5782\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 1.0853 - accuracy: 0.7508 - val_loss: 1.3071 - val_accuracy: 0.5048\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6333 - accuracy: 0.7531 - val_loss: 0.9324 - val_accuracy: 0.5372\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6081 - accuracy: 0.7563 - val_loss: 0.9674 - val_accuracy: 0.5188\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6364 - accuracy: 0.7562 - val_loss: 0.8507 - val_accuracy: 0.5985\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.6355 - accuracy: 0.7584 - val_loss: 1.0132 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6161 - accuracy: 0.7560 - val_loss: 0.9956 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 0.5456 - accuracy: 0.7622 - val_loss: 1.0307 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5294 - accuracy: 0.7645 - val_loss: 1.0502 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.5108 - accuracy: 0.7756 - val_loss: 0.7382 - val_accuracy: 0.5675\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.5024 - accuracy: 0.7755 - val_loss: 0.9048 - val_accuracy: 0.5075\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.4983 - accuracy: 0.7770 - val_loss: 0.6280 - val_accuracy: 0.6948\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.4975 - accuracy: 0.7794 - val_loss: 0.8715 - val_accuracy: 0.5322\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.4960 - accuracy: 0.7811 - val_loss: 0.8302 - val_accuracy: 0.5393\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 325us/sample - loss: 0.4882 - accuracy: 0.7854 - val_loss: 0.6657 - val_accuracy: 0.6678\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.4856 - accuracy: 0.7858 - val_loss: 0.7494 - val_accuracy: 0.5863\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.4816 - accuracy: 0.7873 - val_loss: 0.6859 - val_accuracy: 0.6440\n",
      "10667/10667 [==============================] - 2s 182us/sample - loss: 1.0970 - accuracy: 0.3612\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 433us/sample - loss: 2.1951 - accuracy: 0.5691 - val_loss: 1.1162 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 324us/sample - loss: 1.1194 - accuracy: 0.5840 - val_loss: 1.4928 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 1.2239 - accuracy: 0.5921 - val_loss: 1.0501 - val_accuracy: 0.5030\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 1.1512 - accuracy: 0.5904 - val_loss: 1.3504 - val_accuracy: 0.5288\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 1.1791 - accuracy: 0.5899 - val_loss: 1.2827 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.7668 - accuracy: 0.6035 - val_loss: 0.7492 - val_accuracy: 0.5715\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.7307 - accuracy: 0.6088 - val_loss: 0.7345 - val_accuracy: 0.6102\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.7248 - accuracy: 0.6140 - val_loss: 0.7604 - val_accuracy: 0.5013\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.7193 - accuracy: 0.6182 - val_loss: 0.7623 - val_accuracy: 0.5803\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 332us/sample - loss: 0.6636 - accuracy: 0.6455 - val_loss: 0.7373 - val_accuracy: 0.4997\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6437 - accuracy: 0.6696 - val_loss: 0.7688 - val_accuracy: 0.5102\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 330us/sample - loss: 0.6197 - accuracy: 0.6927 - val_loss: 0.6285 - val_accuracy: 0.6877\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.6078 - accuracy: 0.6978 - val_loss: 0.6044 - val_accuracy: 0.7067\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.6035 - accuracy: 0.7023 - val_loss: 0.6399 - val_accuracy: 0.6568\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.6017 - accuracy: 0.7037 - val_loss: 0.6215 - val_accuracy: 0.7055\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 328us/sample - loss: 0.5909 - accuracy: 0.7105 - val_loss: 0.5893 - val_accuracy: 0.7147\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.5859 - accuracy: 0.7169 - val_loss: 0.5853 - val_accuracy: 0.7147\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 336us/sample - loss: 0.5825 - accuracy: 0.7164 - val_loss: 0.5865 - val_accuracy: 0.7190\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.5799 - accuracy: 0.7202 - val_loss: 0.5836 - val_accuracy: 0.7200\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 327us/sample - loss: 0.5781 - accuracy: 0.7209 - val_loss: 0.5833 - val_accuracy: 0.7188\n",
      "10667/10667 [==============================] - 2s 185us/sample - loss: 0.5823 - accuracy: 0.7144\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 9s 435us/sample - loss: 2.2132 - accuracy: 0.7369 - val_loss: 1.2341 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 323us/sample - loss: 0.9817 - accuracy: 0.7490 - val_loss: 1.2358 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 328us/sample - loss: 0.9665 - accuracy: 0.7494 - val_loss: 1.1997 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 7s 324us/sample - loss: 1.0192 - accuracy: 0.7492 - val_loss: 2.6118 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.9816 - accuracy: 0.7496 - val_loss: 1.3240 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.6310 - accuracy: 0.7499 - val_loss: 0.8694 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 327us/sample - loss: 0.5910 - accuracy: 0.7500 - val_loss: 0.8449 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 324us/sample - loss: 0.6121 - accuracy: 0.7499 - val_loss: 0.8809 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.6105 - accuracy: 0.7498 - val_loss: 0.9165 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.8242 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5358 - accuracy: 0.7498 - val_loss: 0.7039 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.5318 - accuracy: 0.7477 - val_loss: 0.8751 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 324us/sample - loss: 0.5261 - accuracy: 0.7485 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.5083 - accuracy: 0.7487 - val_loss: 0.7479 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 324us/sample - loss: 0.5035 - accuracy: 0.7455 - val_loss: 0.6867 - val_accuracy: 0.5067\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 323us/sample - loss: 0.4986 - accuracy: 0.7506 - val_loss: 0.7324 - val_accuracy: 0.5008\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.4957 - accuracy: 0.7552 - val_loss: 0.8171 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.4897 - accuracy: 0.7587 - val_loss: 0.6974 - val_accuracy: 0.5625\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 326us/sample - loss: 0.4862 - accuracy: 0.7640 - val_loss: 0.6842 - val_accuracy: 0.5913\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 325us/sample - loss: 0.4835 - accuracy: 0.7635 - val_loss: 0.6755 - val_accuracy: 0.5753\n",
      "10666/10666 [==============================] - 2s 181us/sample - loss: 1.0391 - accuracy: 0.2178\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 9s 437us/sample - loss: 2.1264 - accuracy: 0.7386 - val_loss: 1.7244 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 326us/sample - loss: 0.9430 - accuracy: 0.7495 - val_loss: 1.1824 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 331us/sample - loss: 0.9317 - accuracy: 0.7514 - val_loss: 1.3687 - val_accuracy: 0.5767\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 335us/sample - loss: 1.0776 - accuracy: 0.7523 - val_loss: 1.6831 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 333us/sample - loss: 0.6490 - accuracy: 0.7562 - val_loss: 0.9881 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 329us/sample - loss: 0.6312 - accuracy: 0.7564 - val_loss: 0.8990 - val_accuracy: 0.5070\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 351us/sample - loss: 0.6123 - accuracy: 0.7561 - val_loss: 0.8561 - val_accuracy: 0.5518\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6401 - accuracy: 0.7551 - val_loss: 1.4453 - val_accuracy: 0.5443\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6250 - accuracy: 0.7561 - val_loss: 0.9640 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21333/21333 [==============================] - 7s 338us/sample - loss: 0.5490 - accuracy: 0.7644 - val_loss: 0.9434 - val_accuracy: 0.5008\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.5248 - accuracy: 0.7689 - val_loss: 1.0127 - val_accuracy: 0.5025\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.5042 - accuracy: 0.7785 - val_loss: 0.6811 - val_accuracy: 0.6053\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 339us/sample - loss: 0.4961 - accuracy: 0.7813 - val_loss: 0.6458 - val_accuracy: 0.6610\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 346us/sample - loss: 0.4926 - accuracy: 0.7835 - val_loss: 0.6576 - val_accuracy: 0.6405\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 350us/sample - loss: 0.4898 - accuracy: 0.7834 - val_loss: 0.6960 - val_accuracy: 0.6058\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.4838 - accuracy: 0.7869 - val_loss: 0.8650 - val_accuracy: 0.5418\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.4807 - accuracy: 0.7869 - val_loss: 0.7215 - val_accuracy: 0.6230\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 0.4775 - accuracy: 0.7898 - val_loss: 0.7337 - val_accuracy: 0.6085\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 349us/sample - loss: 0.4762 - accuracy: 0.7911 - val_loss: 0.7172 - val_accuracy: 0.6258\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 347us/sample - loss: 0.4742 - accuracy: 0.7914 - val_loss: 0.6907 - val_accuracy: 0.6485\n",
      "10667/10667 [==============================] - 2s 199us/sample - loss: 1.1124 - accuracy: 0.3664\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 469us/sample - loss: 2.2765 - accuracy: 0.5229 - val_loss: 1.2194 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 1.1617 - accuracy: 0.5778 - val_loss: 1.2143 - val_accuracy: 0.5753\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 354us/sample - loss: 1.1092 - accuracy: 0.5879 - val_loss: 1.3590 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 1.3252 - accuracy: 0.5907 - val_loss: 1.2878 - val_accuracy: 0.5242\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 374us/sample - loss: 0.7556 - accuracy: 0.6059 - val_loss: 0.7572 - val_accuracy: 0.5975\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 354us/sample - loss: 0.7426 - accuracy: 0.6112 - val_loss: 0.7280 - val_accuracy: 0.5845\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.7243 - accuracy: 0.6192 - val_loss: 0.8151 - val_accuracy: 0.5855\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.7256 - accuracy: 0.6244 - val_loss: 2.0087 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 349us/sample - loss: 0.6681 - accuracy: 0.6630 - val_loss: 0.6505 - val_accuracy: 0.6705\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.6389 - accuracy: 0.6770 - val_loss: 0.6868 - val_accuracy: 0.5982\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6300 - accuracy: 0.6855 - val_loss: 0.8042 - val_accuracy: 0.5515\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6115 - accuracy: 0.7009 - val_loss: 0.6637 - val_accuracy: 0.6187\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 348us/sample - loss: 0.6048 - accuracy: 0.7039 - val_loss: 0.6184 - val_accuracy: 0.6960\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.6012 - accuracy: 0.7089 - val_loss: 0.6355 - val_accuracy: 0.6790\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.5995 - accuracy: 0.7054 - val_loss: 0.5968 - val_accuracy: 0.7132\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.5965 - accuracy: 0.7100 - val_loss: 0.6026 - val_accuracy: 0.7072\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 352us/sample - loss: 0.5938 - accuracy: 0.7124 - val_loss: 0.6029 - val_accuracy: 0.7025\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 355us/sample - loss: 0.5870 - accuracy: 0.7194 - val_loss: 0.5847 - val_accuracy: 0.7153\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 361us/sample - loss: 0.5802 - accuracy: 0.7232 - val_loss: 0.6002 - val_accuracy: 0.7080\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 0.5792 - accuracy: 0.7231 - val_loss: 0.5828 - val_accuracy: 0.7185\n",
      "10667/10667 [==============================] - 2s 192us/sample - loss: 0.5865 - accuracy: 0.7071\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 10s 475us/sample - loss: 2.1277 - accuracy: 0.7359 - val_loss: 1.3545 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 8s 356us/sample - loss: 0.9835 - accuracy: 0.7478 - val_loss: 1.0844 - val_accuracy: 0.5368\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 1.0207 - accuracy: 0.7486 - val_loss: 1.0644 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 8s 372us/sample - loss: 0.9603 - accuracy: 0.7500 - val_loss: 1.6434 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 8s 363us/sample - loss: 1.1358 - accuracy: 0.7499 - val_loss: 1.2931 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 341us/sample - loss: 0.6383 - accuracy: 0.7500 - val_loss: 0.8325 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 336us/sample - loss: 0.6200 - accuracy: 0.7498 - val_loss: 0.7911 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 340us/sample - loss: 0.6024 - accuracy: 0.7499 - val_loss: 2.7133 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 8s 362us/sample - loss: 0.6195 - accuracy: 0.7498 - val_loss: 0.7852 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 8s 356us/sample - loss: 0.6054 - accuracy: 0.7501 - val_loss: 2.3637 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 349us/sample - loss: 0.6145 - accuracy: 0.7500 - val_loss: 0.9912 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 0.5521 - accuracy: 0.7500 - val_loss: 0.7285 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 9s 403us/sample - loss: 0.5396 - accuracy: 0.7495 - val_loss: 0.7096 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 379us/sample - loss: 0.5336 - accuracy: 0.7478 - val_loss: 0.7222 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 341us/sample - loss: 0.5259 - accuracy: 0.7485 - val_loss: 1.1121 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 8s 378us/sample - loss: 0.5067 - accuracy: 0.7481 - val_loss: 0.7265 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.5000 - accuracy: 0.7489 - val_loss: 0.8738 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.4926 - accuracy: 0.7549 - val_loss: 0.7507 - val_accuracy: 0.5288\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.4896 - accuracy: 0.7549 - val_loss: 0.8021 - val_accuracy: 0.5100\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.4860 - accuracy: 0.7611 - val_loss: 0.7100 - val_accuracy: 0.5700\n",
      "10666/10666 [==============================] - 2s 212us/sample - loss: 1.1475 - accuracy: 0.1927\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 485us/sample - loss: 3.0355 - accuracy: 0.7390 - val_loss: 1.4154 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 1.1229 - accuracy: 0.7496 - val_loss: 1.4787 - val_accuracy: 0.5548\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 1.2790 - accuracy: 0.7502 - val_loss: 1.8253 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.7090 - accuracy: 0.7532 - val_loss: 0.9434 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.6915 - accuracy: 0.7539 - val_loss: 1.0497 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.6714 - accuracy: 0.7535 - val_loss: 2.0063 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.5731 - accuracy: 0.7565 - val_loss: 0.9409 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5540 - accuracy: 0.7583 - val_loss: 0.8433 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.5600 - accuracy: 0.7602 - val_loss: 1.0453 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5587 - accuracy: 0.7593 - val_loss: 0.7088 - val_accuracy: 0.6335\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5443 - accuracy: 0.7647 - val_loss: 0.8354 - val_accuracy: 0.5085\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5330 - accuracy: 0.7688 - val_loss: 1.2328 - val_accuracy: 0.4997\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5125 - accuracy: 0.7764 - val_loss: 0.6680 - val_accuracy: 0.6708\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.5045 - accuracy: 0.7792 - val_loss: 0.8120 - val_accuracy: 0.5318\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.5037 - accuracy: 0.7776 - val_loss: 0.8054 - val_accuracy: 0.5490\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.4951 - accuracy: 0.7831 - val_loss: 0.9131 - val_accuracy: 0.5180\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.4906 - accuracy: 0.7868 - val_loss: 0.7442 - val_accuracy: 0.5805\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.4868 - accuracy: 0.7866 - val_loss: 0.7769 - val_accuracy: 0.5705\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.4844 - accuracy: 0.7892 - val_loss: 0.6929 - val_accuracy: 0.6522\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.4861 - accuracy: 0.7873 - val_loss: 0.7092 - val_accuracy: 0.6367\n",
      "10667/10667 [==============================] - 2s 215us/sample - loss: 1.1673 - accuracy: 0.3156\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 11s 521us/sample - loss: 3.1791 - accuracy: 0.5326 - val_loss: 1.2946 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 1.4801 - accuracy: 0.5825 - val_loss: 1.4439 - val_accuracy: 0.5815\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 1.6720 - accuracy: 0.5831 - val_loss: 1.6042 - val_accuracy: 0.5633\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.8275 - accuracy: 0.6003 - val_loss: 0.8245 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.7703 - accuracy: 0.6020 - val_loss: 0.7689 - val_accuracy: 0.5042\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.8293 - accuracy: 0.6027 - val_loss: 0.8127 - val_accuracy: 0.5067\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.7972 - accuracy: 0.6032 - val_loss: 0.8350 - val_accuracy: 0.5458\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.6947 - accuracy: 0.6164 - val_loss: 0.7329 - val_accuracy: 0.5115\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.6643 - accuracy: 0.6377 - val_loss: 0.7156 - val_accuracy: 0.5322\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 377us/sample - loss: 0.6569 - accuracy: 0.6546 - val_loss: 0.7115 - val_accuracy: 0.5555\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6629 - accuracy: 0.6629 - val_loss: 0.8956 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.6585 - accuracy: 0.6677 - val_loss: 0.7136 - val_accuracy: 0.5420\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.6221 - accuracy: 0.6931 - val_loss: 0.9254 - val_accuracy: 0.5383\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6125 - accuracy: 0.6980 - val_loss: 0.8233 - val_accuracy: 0.5048\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.6025 - accuracy: 0.7041 - val_loss: 0.6125 - val_accuracy: 0.6963\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.5983 - accuracy: 0.7068 - val_loss: 0.5967 - val_accuracy: 0.7107\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5951 - accuracy: 0.7121 - val_loss: 0.5996 - val_accuracy: 0.7090\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5933 - accuracy: 0.7113 - val_loss: 0.6846 - val_accuracy: 0.6528\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5876 - accuracy: 0.7165 - val_loss: 0.5901 - val_accuracy: 0.7157\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.5862 - accuracy: 0.7174 - val_loss: 0.5896 - val_accuracy: 0.7157\n",
      "10667/10667 [==============================] - 2s 214us/sample - loss: 0.5888 - accuracy: 0.7084\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 10s 487us/sample - loss: 3.0352 - accuracy: 0.7381 - val_loss: 1.5156 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.8593 - accuracy: 0.7497 - val_loss: 0.9906 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.7927 - accuracy: 0.7500 - val_loss: 1.0380 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.7841 - accuracy: 0.7499 - val_loss: 1.2587 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 8s 369us/sample - loss: 0.6353 - accuracy: 0.7500 - val_loss: 1.0042 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.6566 - accuracy: 0.7499 - val_loss: 0.9904 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 8s 365us/sample - loss: 0.7454 - accuracy: 0.7500 - val_loss: 0.8940 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 8s 370us/sample - loss: 0.7422 - accuracy: 0.7500 - val_loss: 0.8897 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.7289 - accuracy: 0.7499 - val_loss: 0.9732 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.7343 - accuracy: 0.7500 - val_loss: 1.2228 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.5724 - accuracy: 0.7500 - val_loss: 0.7514 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 8s 368us/sample - loss: 0.5547 - accuracy: 0.7499 - val_loss: 0.7891 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.5607 - accuracy: 0.7496 - val_loss: 1.3508 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.5330 - accuracy: 0.7460 - val_loss: 0.8112 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.5169 - accuracy: 0.7459 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.5122 - accuracy: 0.7506 - val_loss: 0.7602 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.5109 - accuracy: 0.7497 - val_loss: 0.6468 - val_accuracy: 0.6815\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 8s 365us/sample - loss: 0.5066 - accuracy: 0.7522 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 8s 367us/sample - loss: 0.5069 - accuracy: 0.7531 - val_loss: 0.6872 - val_accuracy: 0.5270\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 8s 369us/sample - loss: 0.4962 - accuracy: 0.7596 - val_loss: 0.6549 - val_accuracy: 0.6175\n",
      "10666/10666 [==============================] - 2s 209us/sample - loss: 0.9399 - accuracy: 0.3371\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 482us/sample - loss: 1.8086 - accuracy: 0.7259 - val_loss: 0.9551 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.7806 - accuracy: 0.7480 - val_loss: 1.0746 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.7158 - accuracy: 0.7495 - val_loss: 1.0272 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.5997 - accuracy: 0.7500 - val_loss: 0.9879 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.5856 - accuracy: 0.7500 - val_loss: 0.8043 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.5826 - accuracy: 0.7500 - val_loss: 0.7224 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5716 - accuracy: 0.7527 - val_loss: 0.9766 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.5781 - accuracy: 0.7554 - val_loss: 1.0472 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5389 - accuracy: 0.7627 - val_loss: 0.6889 - val_accuracy: 0.6392\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.5294 - accuracy: 0.7681 - val_loss: 1.0388 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5281 - accuracy: 0.7686 - val_loss: 1.0123 - val_accuracy: 0.5720\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5089 - accuracy: 0.7792 - val_loss: 0.6706 - val_accuracy: 0.6435\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.4989 - accuracy: 0.7827 - val_loss: 0.6737 - val_accuracy: 0.6603\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.4965 - accuracy: 0.7841 - val_loss: 0.6675 - val_accuracy: 0.6808\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.4910 - accuracy: 0.7860 - val_loss: 0.7368 - val_accuracy: 0.6450\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.4911 - accuracy: 0.7852 - val_loss: 0.9550 - val_accuracy: 0.5170\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.4863 - accuracy: 0.7884 - val_loss: 0.6592 - val_accuracy: 0.6925\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.4832 - accuracy: 0.7899 - val_loss: 0.6560 - val_accuracy: 0.6873\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.4822 - accuracy: 0.7907 - val_loss: 0.6460 - val_accuracy: 0.6905\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.4800 - accuracy: 0.7908 - val_loss: 0.7088 - val_accuracy: 0.6375\n",
      "10667/10667 [==============================] - 2s 209us/sample - loss: 1.1640 - accuracy: 0.3197\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 11s 515us/sample - loss: 2.0357 - accuracy: 0.5757 - val_loss: 0.8530 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.8221 - accuracy: 0.5969 - val_loss: 0.8634 - val_accuracy: 0.5383\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.8475 - accuracy: 0.6021 - val_loss: 0.7844 - val_accuracy: 0.5925\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.8354 - accuracy: 0.5990 - val_loss: 0.8116 - val_accuracy: 0.6035\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.8507 - accuracy: 0.6031 - val_loss: 1.2137 - val_accuracy: 0.5310\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6940 - accuracy: 0.6249 - val_loss: 0.7477 - val_accuracy: 0.5472\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.6797 - accuracy: 0.6398 - val_loss: 0.6739 - val_accuracy: 0.6447\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6786 - accuracy: 0.6572 - val_loss: 0.8127 - val_accuracy: 0.5055\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.6646 - accuracy: 0.6682 - val_loss: 0.7745 - val_accuracy: 0.5515\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6276 - accuracy: 0.6898 - val_loss: 0.7450 - val_accuracy: 0.6097\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.6165 - accuracy: 0.6972 - val_loss: 0.7532 - val_accuracy: 0.5303\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6027 - accuracy: 0.7067 - val_loss: 0.5992 - val_accuracy: 0.7103\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 374us/sample - loss: 0.5961 - accuracy: 0.7120 - val_loss: 0.5923 - val_accuracy: 0.7117\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.5906 - accuracy: 0.7121 - val_loss: 0.5940 - val_accuracy: 0.7117\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.5891 - accuracy: 0.7138 - val_loss: 0.6026 - val_accuracy: 0.7028\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.5817 - accuracy: 0.7215 - val_loss: 0.5850 - val_accuracy: 0.7205\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.5790 - accuracy: 0.7224 - val_loss: 0.5821 - val_accuracy: 0.7182\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.5772 - accuracy: 0.7245 - val_loss: 0.5857 - val_accuracy: 0.7225\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.5751 - accuracy: 0.7263 - val_loss: 0.5851 - val_accuracy: 0.7190\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.5728 - accuracy: 0.7282 - val_loss: 0.5811 - val_accuracy: 0.7180\n",
      "10667/10667 [==============================] - 2s 208us/sample - loss: 0.5839 - accuracy: 0.7159\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 10s 490us/sample - loss: 2.0720 - accuracy: 0.7232 - val_loss: 1.1751 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 8s 373us/sample - loss: 0.7698 - accuracy: 0.7456 - val_loss: 1.1828 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 8s 373us/sample - loss: 0.7470 - accuracy: 0.7489 - val_loss: 0.9416 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 8s 372us/sample - loss: 0.6973 - accuracy: 0.7491 - val_loss: 0.9294 - val_accuracy: 0.5110\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.6966 - accuracy: 0.7486 - val_loss: 1.0337 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.7166 - accuracy: 0.7496 - val_loss: 1.8454 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 8s 372us/sample - loss: 0.5839 - accuracy: 0.7500 - val_loss: 0.9650 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 8s 373us/sample - loss: 0.5687 - accuracy: 0.7500 - val_loss: 0.7394 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 8s 373us/sample - loss: 0.5713 - accuracy: 0.7497 - val_loss: 1.0212 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 8s 375us/sample - loss: 0.5737 - accuracy: 0.7499 - val_loss: 0.7434 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 8s 373us/sample - loss: 0.5419 - accuracy: 0.7492 - val_loss: 0.7200 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.5262 - accuracy: 0.7474 - val_loss: 0.8895 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.5169 - accuracy: 0.7489 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.5134 - accuracy: 0.7476 - val_loss: 0.7405 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 8s 372us/sample - loss: 0.5099 - accuracy: 0.7491 - val_loss: 0.7173 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.5008 - accuracy: 0.7475 - val_loss: 0.6721 - val_accuracy: 0.5440\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 8s 392us/sample - loss: 0.4950 - accuracy: 0.7513 - val_loss: 0.9456 - val_accuracy: 0.5067\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 8s 370us/sample - loss: 0.4922 - accuracy: 0.7593 - val_loss: 0.8922 - val_accuracy: 0.5040\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 8s 372us/sample - loss: 0.4864 - accuracy: 0.7612 - val_loss: 0.7066 - val_accuracy: 0.5922\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.4840 - accuracy: 0.7649 - val_loss: 0.7018 - val_accuracy: 0.5907\n",
      "10666/10666 [==============================] - 2s 199us/sample - loss: 1.1050 - accuracy: 0.2442\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 451us/sample - loss: 1.9091 - accuracy: 0.7344 - val_loss: 1.2189 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 348us/sample - loss: 0.9141 - accuracy: 0.7521 - val_loss: 1.1428 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 347us/sample - loss: 0.9217 - accuracy: 0.7526 - val_loss: 1.1254 - val_accuracy: 0.5995\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 0.8859 - accuracy: 0.7531 - val_loss: 1.0605 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.9096 - accuracy: 0.7532 - val_loss: 1.1868 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.8701 - accuracy: 0.7525 - val_loss: 1.0223 - val_accuracy: 0.5002\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.9399 - accuracy: 0.7531 - val_loss: 1.0683 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.8732 - accuracy: 0.7532 - val_loss: 1.1361 - val_accuracy: 0.5090\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5996 - accuracy: 0.7560 - val_loss: 0.7290 - val_accuracy: 0.6085\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5804 - accuracy: 0.7586 - val_loss: 0.9413 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5676 - accuracy: 0.7582 - val_loss: 0.9547 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5288 - accuracy: 0.7661 - val_loss: 0.8007 - val_accuracy: 0.5140\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5171 - accuracy: 0.7710 - val_loss: 0.6898 - val_accuracy: 0.6587\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5134 - accuracy: 0.7732 - val_loss: 0.6901 - val_accuracy: 0.6258\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5080 - accuracy: 0.7762 - val_loss: 0.6782 - val_accuracy: 0.6687\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.5082 - accuracy: 0.7761 - val_loss: 0.6364 - val_accuracy: 0.6737\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5065 - accuracy: 0.7742 - val_loss: 0.7399 - val_accuracy: 0.6095\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5076 - accuracy: 0.7747 - val_loss: 1.0176 - val_accuracy: 0.5008\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.4913 - accuracy: 0.7832 - val_loss: 0.7610 - val_accuracy: 0.5590\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 349us/sample - loss: 0.4872 - accuracy: 0.7841 - val_loss: 0.7920 - val_accuracy: 0.5587\n",
      "10667/10667 [==============================] - 2s 198us/sample - loss: 1.3793 - accuracy: 0.1394\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 477us/sample - loss: 2.1477 - accuracy: 0.5302 - val_loss: 0.9387 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 1.0180 - accuracy: 0.5885 - val_loss: 1.0012 - val_accuracy: 0.5150\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 1.0857 - accuracy: 0.5936 - val_loss: 1.1515 - val_accuracy: 0.5285\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.7332 - accuracy: 0.6088 - val_loss: 0.7271 - val_accuracy: 0.5918\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.7202 - accuracy: 0.6132 - val_loss: 0.7542 - val_accuracy: 0.5102\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.7140 - accuracy: 0.6176 - val_loss: 0.7416 - val_accuracy: 0.5938\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6659 - accuracy: 0.6448 - val_loss: 0.7554 - val_accuracy: 0.5033\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6368 - accuracy: 0.6754 - val_loss: 0.6559 - val_accuracy: 0.6490\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6299 - accuracy: 0.6806 - val_loss: 0.6469 - val_accuracy: 0.6495\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 341us/sample - loss: 0.6247 - accuracy: 0.6882 - val_loss: 0.6466 - val_accuracy: 0.6690\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6198 - accuracy: 0.6915 - val_loss: 0.6817 - val_accuracy: 0.5903\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6211 - accuracy: 0.6914 - val_loss: 0.6190 - val_accuracy: 0.6920\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.6194 - accuracy: 0.6916 - val_loss: 0.6234 - val_accuracy: 0.6908\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6142 - accuracy: 0.6977 - val_loss: 0.6457 - val_accuracy: 0.6705\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.6013 - accuracy: 0.7058 - val_loss: 0.6313 - val_accuracy: 0.6780\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5938 - accuracy: 0.7104 - val_loss: 0.6007 - val_accuracy: 0.7057\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 340us/sample - loss: 0.5906 - accuracy: 0.7121 - val_loss: 0.5939 - val_accuracy: 0.7105\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5885 - accuracy: 0.7142 - val_loss: 0.6014 - val_accuracy: 0.7040\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 347us/sample - loss: 0.5882 - accuracy: 0.7135 - val_loss: 0.6047 - val_accuracy: 0.7017\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 348us/sample - loss: 0.5807 - accuracy: 0.7202 - val_loss: 0.5942 - val_accuracy: 0.7107\n",
      "10667/10667 [==============================] - 2s 192us/sample - loss: 0.5919 - accuracy: 0.7050\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 11s 495us/sample - loss: 1.8268 - accuracy: 0.7359 - val_loss: 1.1023 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 340us/sample - loss: 0.9326 - accuracy: 0.7480 - val_loss: 1.2484 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.9999 - accuracy: 0.7488 - val_loss: 1.0494 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.9498 - accuracy: 0.7495 - val_loss: 1.0712 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.9462 - accuracy: 0.7500 - val_loss: 1.0366 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.9279 - accuracy: 0.7497 - val_loss: 1.0860 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.9180 - accuracy: 0.7497 - val_loss: 1.1089 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.6010 - accuracy: 0.7499 - val_loss: 0.8003 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.5828 - accuracy: 0.7500 - val_loss: 1.0753 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 339us/sample - loss: 0.6038 - accuracy: 0.7500 - val_loss: 0.8944 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.5490 - accuracy: 0.7499 - val_loss: 0.8402 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 339us/sample - loss: 0.5303 - accuracy: 0.7484 - val_loss: 0.8194 - val_accuracy: 0.5167\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.5062 - accuracy: 0.7474 - val_loss: 0.9579 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 7s 337us/sample - loss: 0.5007 - accuracy: 0.7501 - val_loss: 2.6956 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.4931 - accuracy: 0.7544 - val_loss: 0.7239 - val_accuracy: 0.5238\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 337us/sample - loss: 0.4905 - accuracy: 0.7597 - val_loss: 0.8978 - val_accuracy: 0.5080\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.4892 - accuracy: 0.7605 - val_loss: 1.3043 - val_accuracy: 0.5077\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 337us/sample - loss: 0.4873 - accuracy: 0.7595 - val_loss: 0.7370 - val_accuracy: 0.5815\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 339us/sample - loss: 0.4852 - accuracy: 0.7630 - val_loss: 0.7083 - val_accuracy: 0.5790\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 338us/sample - loss: 0.4859 - accuracy: 0.7614 - val_loss: 0.7244 - val_accuracy: 0.5838\n",
      "10666/10666 [==============================] - 2s 192us/sample - loss: 1.2001 - accuracy: 0.2335\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 453us/sample - loss: 3.4231 - accuracy: 0.6980 - val_loss: 1.6031 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.9155 - accuracy: 0.7449 - val_loss: 1.0327 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.6602 - accuracy: 0.7502 - val_loss: 1.1869 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.6314 - accuracy: 0.7515 - val_loss: 0.9604 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.6033 - accuracy: 0.7522 - val_loss: 0.9541 - val_accuracy: 0.5002\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5925 - accuracy: 0.7530 - val_loss: 1.0330 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5933 - accuracy: 0.7560 - val_loss: 1.0610 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5536 - accuracy: 0.7605 - val_loss: 0.9395 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5391 - accuracy: 0.7630 - val_loss: 0.9170 - val_accuracy: 0.5197\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5335 - accuracy: 0.7671 - val_loss: 0.8768 - val_accuracy: 0.5238\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5251 - accuracy: 0.7704 - val_loss: 0.7763 - val_accuracy: 0.5885\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.5246 - accuracy: 0.7711 - val_loss: 0.8709 - val_accuracy: 0.5288\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.5211 - accuracy: 0.7739 - val_loss: 0.8095 - val_accuracy: 0.5405\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.5027 - accuracy: 0.7819 - val_loss: 1.0170 - val_accuracy: 0.5030\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.4903 - accuracy: 0.7871 - val_loss: 0.7283 - val_accuracy: 0.6202\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 7s 342us/sample - loss: 0.4870 - accuracy: 0.7896 - val_loss: 0.6367 - val_accuracy: 0.6945\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 7s 346us/sample - loss: 0.4843 - accuracy: 0.7907 - val_loss: 0.8845 - val_accuracy: 0.5312\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.4817 - accuracy: 0.7900 - val_loss: 0.7456 - val_accuracy: 0.6080\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 7s 346us/sample - loss: 0.4712 - accuracy: 0.7982 - val_loss: 0.6997 - val_accuracy: 0.6382\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 7s 346us/sample - loss: 0.4677 - accuracy: 0.8000 - val_loss: 0.7884 - val_accuracy: 0.5957\n",
      "10667/10667 [==============================] - 2s 190us/sample - loss: 1.3800 - accuracy: 0.2293\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 10s 453us/sample - loss: 3.7359 - accuracy: 0.5553 - val_loss: 1.5905 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 7s 351us/sample - loss: 1.1324 - accuracy: 0.5802 - val_loss: 0.9783 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 7s 350us/sample - loss: 0.7987 - accuracy: 0.6019 - val_loss: 0.7523 - val_accuracy: 0.5562\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.7205 - accuracy: 0.6110 - val_loss: 0.9791 - val_accuracy: 0.5110\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 7s 344us/sample - loss: 0.6975 - accuracy: 0.6174 - val_loss: 0.7131 - val_accuracy: 0.5760\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 7s 343us/sample - loss: 0.6884 - accuracy: 0.6251 - val_loss: 0.7318 - val_accuracy: 0.5587\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.6902 - accuracy: 0.6431 - val_loss: 0.9718 - val_accuracy: 0.5365\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 352us/sample - loss: 0.6464 - accuracy: 0.6764 - val_loss: 0.6693 - val_accuracy: 0.6450\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 352us/sample - loss: 0.6342 - accuracy: 0.6848 - val_loss: 0.7120 - val_accuracy: 0.6125\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 7s 345us/sample - loss: 0.6274 - accuracy: 0.6901 - val_loss: 0.8101 - val_accuracy: 0.5005\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 359us/sample - loss: 0.6106 - accuracy: 0.7022 - val_loss: 0.6391 - val_accuracy: 0.6710\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 354us/sample - loss: 0.6022 - accuracy: 0.7036 - val_loss: 0.6678 - val_accuracy: 0.6165\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 354us/sample - loss: 0.5963 - accuracy: 0.7089 - val_loss: 0.6051 - val_accuracy: 0.7057\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 357us/sample - loss: 0.5947 - accuracy: 0.7101 - val_loss: 0.6172 - val_accuracy: 0.6965\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 0.5898 - accuracy: 0.7157 - val_loss: 0.5973 - val_accuracy: 0.7138\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 356us/sample - loss: 0.5876 - accuracy: 0.7157 - val_loss: 0.6532 - val_accuracy: 0.6345\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 355us/sample - loss: 0.5842 - accuracy: 0.7183 - val_loss: 0.6161 - val_accuracy: 0.6977\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 7s 349us/sample - loss: 0.5749 - accuracy: 0.7237 - val_loss: 0.6009 - val_accuracy: 0.7072\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 354us/sample - loss: 0.5714 - accuracy: 0.7257 - val_loss: 0.6008 - val_accuracy: 0.7097\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 352us/sample - loss: 0.5667 - accuracy: 0.7285 - val_loss: 0.5989 - val_accuracy: 0.7092\n",
      "10667/10667 [==============================] - 2s 203us/sample - loss: 0.5963 - accuracy: 0.7060\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 10s 462us/sample - loss: 3.4737 - accuracy: 0.6991 - val_loss: 1.4755 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 7s 347us/sample - loss: 0.9463 - accuracy: 0.7446 - val_loss: 0.9007 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 7s 349us/sample - loss: 0.6689 - accuracy: 0.7473 - val_loss: 0.9154 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 7s 348us/sample - loss: 0.6047 - accuracy: 0.7487 - val_loss: 0.8773 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 7s 345us/sample - loss: 0.5954 - accuracy: 0.7491 - val_loss: 1.0600 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 7s 345us/sample - loss: 0.5898 - accuracy: 0.7491 - val_loss: 0.8017 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 7s 346us/sample - loss: 0.5920 - accuracy: 0.7488 - val_loss: 0.9887 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 7s 346us/sample - loss: 0.6033 - accuracy: 0.7493 - val_loss: 1.2247 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 7s 351us/sample - loss: 0.5621 - accuracy: 0.7479 - val_loss: 0.9464 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 7s 347us/sample - loss: 0.5356 - accuracy: 0.7462 - val_loss: 0.7629 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 7s 349us/sample - loss: 0.5246 - accuracy: 0.7462 - val_loss: 3.2677 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 7s 344us/sample - loss: 0.5175 - accuracy: 0.7453 - val_loss: 0.6827 - val_accuracy: 0.5725\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 7s 343us/sample - loss: 0.5146 - accuracy: 0.7474 - val_loss: 0.7621 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 355us/sample - loss: 0.5155 - accuracy: 0.7476 - val_loss: 0.9090 - val_accuracy: 0.5263\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 7s 350us/sample - loss: 0.4973 - accuracy: 0.7570 - val_loss: 0.7131 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 7s 348us/sample - loss: 0.4899 - accuracy: 0.7615 - val_loss: 0.7565 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 7s 348us/sample - loss: 0.4818 - accuracy: 0.7694 - val_loss: 0.7168 - val_accuracy: 0.6062\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 7s 347us/sample - loss: 0.4783 - accuracy: 0.7729 - val_loss: 0.7055 - val_accuracy: 0.6267\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 7s 344us/sample - loss: 0.4739 - accuracy: 0.7748 - val_loss: 0.7063 - val_accuracy: 0.5972\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 7s 345us/sample - loss: 0.4738 - accuracy: 0.7744 - val_loss: 0.7089 - val_accuracy: 0.6198\n",
      "10666/10666 [==============================] - 2s 189us/sample - loss: 1.1407 - accuracy: 0.3424\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x0000023B3BF19748>, as the constructor either does not set or modifies parameter lr_init",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-02dc6f2a6236>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         verbose=1, shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x0000023B3BF19748>, as the constructor either does not set or modifies parameter lr_init"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "#def exponential_decay(lr_init, s):\n",
    "#  def exponential_decay_fn(epoch):\n",
    "#    return lr_init * 0.1**(epoch/s)\n",
    "#  return exponential_decay_fn\n",
    "param_distribs = {\n",
    "    \"factors\":[0.1, 0.2, 0.3, 0.4, 0.5, 0.55, 0.6],\n",
    "    \"lr_init\":reciprocal(3e-4,3e-2)\n",
    "}\n",
    "\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(cnn_wrap, param_distribs, cv = 3)\n",
    "  \n",
    "rnd_search_cv.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factors': 0.05, 'lr_init': 0.01992351943721117}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "#Let's create a ResidualUnit layer\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "DefaultConv2D = partial(Conv2D, kernel_size=3, strides=1,\n",
    "                        padding=\"SAME\", use_bias=False)\n",
    "\n",
    "class ResidualUnit(tensorflow.keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = tensorflow.keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv2D(filters, strides=strides),\n",
    "            BatchNormalization(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters),\n",
    "            BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 2 convoluation layers each with 16 filters (kernel_size=3) followed by a Max pooling layer. After the pooling layer 4 residual layers, with different filter sizes (16, 32, and 64) are added. The residual block is followed by the Max pooling layer. Then 3 dense layers are added and an output dense layer with one neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        304       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "residual_unit (ResidualUnit) (None, 8, 8, 16)          5056      \n",
      "_________________________________________________________________\n",
      "residual_unit_1 (ResidualUni (None, 4, 4, 32)          14720     \n",
      "_________________________________________________________________\n",
      "residual_unit_2 (ResidualUni (None, 4, 4, 32)          18688     \n",
      "_________________________________________________________________\n",
      "residual_unit_3 (ResidualUni (None, 2, 2, 64)          58112     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 208,113\n",
      "Trainable params: 206,353\n",
      "Non-trainable params: 1,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tensorflow.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal', \n",
    "                 input_shape=(img_rows, img_cols, nb_channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(DefaultConv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "prev_filters = 64\n",
    "for filters in [16] * 1 + [32] * 2 + [64] * 1:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "model.add(MaxPooling2D(pool_size=3, strides=1, padding=\"SAME\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr_init), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "256000/256000 [==============================] - 88s 346us/sample - loss: 0.6683 - accuracy: 0.6003 - val_loss: 0.6391 - val_accuracy: 0.6344\n",
      "Epoch 2/20\n",
      "256000/256000 [==============================] - 82s 322us/sample - loss: 0.6074 - accuracy: 0.6753 - val_loss: 0.8704 - val_accuracy: 0.6213\n",
      "Epoch 3/20\n",
      "256000/256000 [==============================] - 84s 327us/sample - loss: 0.5733 - accuracy: 0.7104 - val_loss: 0.6737 - val_accuracy: 0.5777\n",
      "Epoch 4/20\n",
      "256000/256000 [==============================] - 82s 320us/sample - loss: 0.5583 - accuracy: 0.7218 - val_loss: 0.7126 - val_accuracy: 0.6724\n",
      "Epoch 5/20\n",
      "256000/256000 [==============================] - 82s 320us/sample - loss: 0.5544 - accuracy: 0.7238 - val_loss: 0.5534 - val_accuracy: 0.7273\n",
      "Epoch 6/20\n",
      "256000/256000 [==============================] - 81s 316us/sample - loss: 0.5513 - accuracy: 0.7267 - val_loss: 0.6406 - val_accuracy: 0.7001\n",
      "Epoch 7/20\n",
      "256000/256000 [==============================] - 81s 317us/sample - loss: 0.5499 - accuracy: 0.7274 - val_loss: 0.7899 - val_accuracy: 0.5246\n",
      "Epoch 8/20\n",
      "256000/256000 [==============================] - 81s 318us/sample - loss: 0.5439 - accuracy: 0.7308 - val_loss: 0.5766 - val_accuracy: 0.7086\n",
      "Epoch 9/20\n",
      "256000/256000 [==============================] - 82s 320us/sample - loss: 0.5417 - accuracy: 0.7326 - val_loss: 0.5456 - val_accuracy: 0.7289\n",
      "Epoch 10/20\n",
      "256000/256000 [==============================] - 83s 324us/sample - loss: 0.5410 - accuracy: 0.7334 - val_loss: 0.5439 - val_accuracy: 0.7295\n",
      "Epoch 11/20\n",
      "256000/256000 [==============================] - 83s 323us/sample - loss: 0.5400 - accuracy: 0.7342 - val_loss: 0.6839 - val_accuracy: 0.5450\n",
      "Epoch 12/20\n",
      "256000/256000 [==============================] - 83s 323us/sample - loss: 0.5394 - accuracy: 0.7347 - val_loss: 0.5433 - val_accuracy: 0.7321\n",
      "Epoch 13/20\n",
      "256000/256000 [==============================] - 83s 323us/sample - loss: 0.5382 - accuracy: 0.7351 - val_loss: 0.5891 - val_accuracy: 0.6861\n",
      "Epoch 14/20\n",
      "256000/256000 [==============================] - 83s 325us/sample - loss: 0.5372 - accuracy: 0.7361 - val_loss: 0.5446 - val_accuracy: 0.7317\n",
      "Epoch 15/20\n",
      "256000/256000 [==============================] - 83s 324us/sample - loss: 0.5342 - accuracy: 0.7382 - val_loss: 0.5383 - val_accuracy: 0.7362\n",
      "Epoch 16/20\n",
      "256000/256000 [==============================] - 84s 327us/sample - loss: 0.5334 - accuracy: 0.7390 - val_loss: 0.5499 - val_accuracy: 0.7302\n",
      "Epoch 17/20\n",
      "256000/256000 [==============================] - 81s 317us/sample - loss: 0.5324 - accuracy: 0.7396 - val_loss: 0.5368 - val_accuracy: 0.7363\n",
      "Epoch 18/20\n",
      "256000/256000 [==============================] - 85s 331us/sample - loss: 0.5319 - accuracy: 0.7401 - val_loss: 0.5458 - val_accuracy: 0.7315\n",
      "Epoch 19/20\n",
      "256000/256000 [==============================] - 83s 325us/sample - loss: 0.5314 - accuracy: 0.7396 - val_loss: 0.5378 - val_accuracy: 0.7354\n",
      "Epoch 20/20\n",
      "256000/256000 [==============================] - 82s 319us/sample - loss: 0.5291 - accuracy: 0.7420 - val_loss: 0.5365 - val_accuracy: 0.7361\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1.e-6)\n",
    "#learning_schedule = \n",
    "history=model.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.5365 - accuracy: 0.7361\n",
      "\n",
      "Validation loss / accuracy: 0.5365 / 0.7361\n",
      "Validation ROC AUC: 0.80766684\n",
      "10000/10000 [==============================] - 2s 208us/sample - loss: 0.5336 - accuracy: 0.7394\n",
      "\n",
      "Test loss / accuracy: 0.5336 / 0.7394\n",
      "Test ROC AUC: 0.80878094\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ResNet ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for learning rate for ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lr_init=1.e-3, factors = 0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal', \n",
    "                 input_shape=(img_rows, img_cols, nb_channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(DefaultConv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "    prev_filters = 64\n",
    "    for filters in [16] * 1 + [32] * 2 + [64] * 1:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        model.add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "    model.add(MaxPooling2D(pool_size=3, strides=1, padding=\"SAME\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr_init), metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factors, patience=2, min_lr=1.e-6)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_wrap = tensorflow.keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 543us/sample - loss: 0.6419 - accuracy: 0.6760 - val_loss: 1.0206 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5682 - accuracy: 0.7429 - val_loss: 0.8656 - val_accuracy: 0.5052\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 405us/sample - loss: 0.5521 - accuracy: 0.7504 - val_loss: 0.7741 - val_accuracy: 0.5577\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5455 - accuracy: 0.7540 - val_loss: 0.7361 - val_accuracy: 0.5770\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.5391 - accuracy: 0.7562 - val_loss: 0.7835 - val_accuracy: 0.5533\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5333 - accuracy: 0.7569 - val_loss: 0.7878 - val_accuracy: 0.5343\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.5262 - accuracy: 0.7620 - val_loss: 0.8254 - val_accuracy: 0.5250\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.5217 - accuracy: 0.7636 - val_loss: 0.7845 - val_accuracy: 0.5558\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.5116 - accuracy: 0.7673 - val_loss: 0.8360 - val_accuracy: 0.5372\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5046 - accuracy: 0.7704 - val_loss: 0.7836 - val_accuracy: 0.5615\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.4898 - accuracy: 0.7767 - val_loss: 0.8005 - val_accuracy: 0.5617\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.4780 - accuracy: 0.7794 - val_loss: 0.8454 - val_accuracy: 0.5435\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.4599 - accuracy: 0.7902 - val_loss: 0.8393 - val_accuracy: 0.5615\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.4498 - accuracy: 0.7912 - val_loss: 0.8724 - val_accuracy: 0.5642\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.4335 - accuracy: 0.7997 - val_loss: 0.8564 - val_accuracy: 0.5692\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.8717 - val_accuracy: 0.5767\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.4170 - accuracy: 0.8072 - val_loss: 0.9078 - val_accuracy: 0.5605\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.4123 - accuracy: 0.8102 - val_loss: 0.9023 - val_accuracy: 0.5658\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.4071 - accuracy: 0.8143 - val_loss: 0.9072 - val_accuracy: 0.5700\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.4057 - accuracy: 0.8139 - val_loss: 0.9373 - val_accuracy: 0.5617\n",
      "10667/10667 [==============================] - 3s 317us/sample - loss: 1.5752 - accuracy: 0.2472\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 563us/sample - loss: 0.7404 - accuracy: 0.5375 - val_loss: 0.7367 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 385us/sample - loss: 0.6873 - accuracy: 0.5653 - val_loss: 0.6760 - val_accuracy: 0.5667\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 436us/sample - loss: 0.6685 - accuracy: 0.5922 - val_loss: 0.6651 - val_accuracy: 0.5945\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 418us/sample - loss: 0.6604 - accuracy: 0.6049 - val_loss: 0.6568 - val_accuracy: 0.6115\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 419us/sample - loss: 0.6524 - accuracy: 0.6174 - val_loss: 0.6560 - val_accuracy: 0.6077\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 419us/sample - loss: 0.6477 - accuracy: 0.6232 - val_loss: 0.6599 - val_accuracy: 0.6155\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.6416 - accuracy: 0.6302 - val_loss: 0.6650 - val_accuracy: 0.6043\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 418us/sample - loss: 0.6319 - accuracy: 0.6399 - val_loss: 0.6812 - val_accuracy: 0.5842\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 404us/sample - loss: 0.6245 - accuracy: 0.6451 - val_loss: 0.6613 - val_accuracy: 0.6047\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.6082 - accuracy: 0.6651 - val_loss: 0.6705 - val_accuracy: 0.6033\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 411us/sample - loss: 0.5964 - accuracy: 0.6779 - val_loss: 0.6787 - val_accuracy: 0.5913\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 407us/sample - loss: 0.5677 - accuracy: 0.7047 - val_loss: 0.6980 - val_accuracy: 0.5680\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.5512 - accuracy: 0.7155 - val_loss: 0.7564 - val_accuracy: 0.5880\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.5216 - accuracy: 0.7432 - val_loss: 0.7422 - val_accuracy: 0.5770\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.7716 - val_accuracy: 0.5870\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.4829 - accuracy: 0.7684 - val_loss: 0.7891 - val_accuracy: 0.5652\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 406us/sample - loss: 0.4713 - accuracy: 0.7765 - val_loss: 0.8064 - val_accuracy: 0.5673\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.4585 - accuracy: 0.7864 - val_loss: 0.8158 - val_accuracy: 0.5695\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 407us/sample - loss: 0.4515 - accuracy: 0.7901 - val_loss: 0.8302 - val_accuracy: 0.5675\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.4460 - accuracy: 0.7949 - val_loss: 0.8382 - val_accuracy: 0.5673\n",
      "10667/10667 [==============================] - 3s 263us/sample - loss: 0.8431 - accuracy: 0.5715\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 13s 622us/sample - loss: 0.6443 - accuracy: 0.6817 - val_loss: 0.7626 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.5723 - accuracy: 0.7365 - val_loss: 0.7899 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.5562 - accuracy: 0.7427 - val_loss: 0.8414 - val_accuracy: 0.4997\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 9s 403us/sample - loss: 0.5454 - accuracy: 0.7475 - val_loss: 0.7918 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 9s 399us/sample - loss: 0.5406 - accuracy: 0.7482 - val_loss: 0.7789 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 9s 402us/sample - loss: 0.5358 - accuracy: 0.7478 - val_loss: 0.7838 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 8s 398us/sample - loss: 0.5326 - accuracy: 0.7480 - val_loss: 0.8139 - val_accuracy: 0.4995\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 9s 401us/sample - loss: 0.5243 - accuracy: 0.7490 - val_loss: 0.8247 - val_accuracy: 0.5040\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 9s 401us/sample - loss: 0.5213 - accuracy: 0.7502 - val_loss: 0.7666 - val_accuracy: 0.5117\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.5125 - accuracy: 0.7509 - val_loss: 0.8107 - val_accuracy: 0.5065\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 9s 399us/sample - loss: 0.5050 - accuracy: 0.7541 - val_loss: 0.8153 - val_accuracy: 0.5190\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 8s 398us/sample - loss: 0.4970 - accuracy: 0.7574 - val_loss: 0.8450 - val_accuracy: 0.5128\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.4920 - accuracy: 0.7599 - val_loss: 0.8511 - val_accuracy: 0.5190\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 397us/sample - loss: 0.4861 - accuracy: 0.7645 - val_loss: 0.8556 - val_accuracy: 0.5165\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 9s 399us/sample - loss: 0.4810 - accuracy: 0.7663 - val_loss: 0.8418 - val_accuracy: 0.5170\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 9s 399us/sample - loss: 0.4791 - accuracy: 0.7669 - val_loss: 0.8698 - val_accuracy: 0.5182\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 9s 403us/sample - loss: 0.4772 - accuracy: 0.7677 - val_loss: 0.8641 - val_accuracy: 0.5170\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 8s 397us/sample - loss: 0.4740 - accuracy: 0.7695 - val_loss: 0.8671 - val_accuracy: 0.5173\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 9s 419us/sample - loss: 0.4733 - accuracy: 0.7694 - val_loss: 0.8654 - val_accuracy: 0.5217\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 8s 375us/sample - loss: 0.4728 - accuracy: 0.7686 - val_loss: 0.8667 - val_accuracy: 0.5205\n",
      "10666/10666 [==============================] - 3s 269us/sample - loss: 1.4446 - accuracy: 0.1081\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 11s 522us/sample - loss: 0.5774 - accuracy: 0.7337 - val_loss: 1.2815 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.5431 - accuracy: 0.7542 - val_loss: 0.7312 - val_accuracy: 0.6018\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.5343 - accuracy: 0.7569 - val_loss: 0.7451 - val_accuracy: 0.5907\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.5312 - accuracy: 0.7589 - val_loss: 0.7416 - val_accuracy: 0.6015\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.5227 - accuracy: 0.7629 - val_loss: 0.9306 - val_accuracy: 0.5080\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 374us/sample - loss: 0.5180 - accuracy: 0.7635 - val_loss: 0.7547 - val_accuracy: 0.5665\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.5044 - accuracy: 0.7736 - val_loss: 0.6844 - val_accuracy: 0.6308\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.4965 - accuracy: 0.7757 - val_loss: 0.7682 - val_accuracy: 0.5707\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.4901 - accuracy: 0.7801 - val_loss: 0.7735 - val_accuracy: 0.6037\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.4748 - accuracy: 0.7903 - val_loss: 0.6824 - val_accuracy: 0.6457\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.4661 - accuracy: 0.7955 - val_loss: 1.0520 - val_accuracy: 0.5008\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.4586 - accuracy: 0.7971 - val_loss: 0.8716 - val_accuracy: 0.5518\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.4370 - accuracy: 0.8071 - val_loss: 0.8743 - val_accuracy: 0.5810\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.8111 - val_accuracy: 0.6068\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.3953 - accuracy: 0.8259 - val_loss: 0.9630 - val_accuracy: 0.5822\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.3815 - accuracy: 0.8324 - val_loss: 0.8196 - val_accuracy: 0.6270\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 374us/sample - loss: 0.3539 - accuracy: 0.8456 - val_loss: 0.8949 - val_accuracy: 0.6083\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.3412 - accuracy: 0.8526 - val_loss: 0.9913 - val_accuracy: 0.5882\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.3240 - accuracy: 0.8592 - val_loss: 0.9624 - val_accuracy: 0.6133\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.3192 - accuracy: 0.8610 - val_loss: 1.0007 - val_accuracy: 0.6035\n",
      "10667/10667 [==============================] - 3s 256us/sample - loss: 1.6720 - accuracy: 0.3602\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 598us/sample - loss: 0.6968 - accuracy: 0.5726 - val_loss: 0.7082 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 442us/sample - loss: 0.6597 - accuracy: 0.6090 - val_loss: 0.6536 - val_accuracy: 0.6235\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 425us/sample - loss: 0.6501 - accuracy: 0.6247 - val_loss: 0.6823 - val_accuracy: 0.5633\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 425us/sample - loss: 0.6387 - accuracy: 0.6356 - val_loss: 0.6337 - val_accuracy: 0.6470\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 429us/sample - loss: 0.6253 - accuracy: 0.6547 - val_loss: 0.7682 - val_accuracy: 0.5315\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 431us/sample - loss: 0.6148 - accuracy: 0.6675 - val_loss: 1.1064 - val_accuracy: 0.5280\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 430us/sample - loss: 0.5994 - accuracy: 0.6861 - val_loss: 1.0782 - val_accuracy: 0.5260\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5948 - accuracy: 0.6930 - val_loss: 0.7971 - val_accuracy: 0.5125\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 427us/sample - loss: 0.5796 - accuracy: 0.7040 - val_loss: 0.6242 - val_accuracy: 0.6752\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 434us/sample - loss: 0.5755 - accuracy: 0.7100 - val_loss: 1.7198 - val_accuracy: 0.5005\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.5713 - accuracy: 0.7139 - val_loss: 0.8148 - val_accuracy: 0.6118\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 425us/sample - loss: 0.5569 - accuracy: 0.7277 - val_loss: 0.6325 - val_accuracy: 0.6712\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 429us/sample - loss: 0.5500 - accuracy: 0.7318 - val_loss: 0.7079 - val_accuracy: 0.5180\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5337 - accuracy: 0.7436 - val_loss: 0.6755 - val_accuracy: 0.6235\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 9s 435us/sample - loss: 0.5294 - accuracy: 0.7477 - val_loss: 0.9343 - val_accuracy: 0.5863\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 442us/sample - loss: 0.5188 - accuracy: 0.7565 - val_loss: 0.6121 - val_accuracy: 0.6858\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 432us/sample - loss: 0.5113 - accuracy: 0.7611 - val_loss: 0.6217 - val_accuracy: 0.6760\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.5093 - accuracy: 0.7622 - val_loss: 0.7215 - val_accuracy: 0.6135\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 407us/sample - loss: 0.5004 - accuracy: 0.7675 - val_loss: 0.6241 - val_accuracy: 0.6808\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 414us/sample - loss: 0.4963 - accuracy: 0.7700 - val_loss: 0.6266 - val_accuracy: 0.6798\n",
      "10667/10667 [==============================] - 3s 273us/sample - loss: 0.6348 - accuracy: 0.6701\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 12s 578us/sample - loss: 0.5837 - accuracy: 0.7280 - val_loss: 0.8807 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.5429 - accuracy: 0.7490 - val_loss: 0.7553 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 9s 416us/sample - loss: 0.5371 - accuracy: 0.7495 - val_loss: 0.8067 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.5334 - accuracy: 0.7493 - val_loss: 0.7123 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.5288 - accuracy: 0.7490 - val_loss: 0.8756 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 9s 406us/sample - loss: 0.5254 - accuracy: 0.7489 - val_loss: 1.2033 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 9s 408us/sample - loss: 0.5126 - accuracy: 0.7491 - val_loss: 0.8082 - val_accuracy: 0.5415\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 9s 403us/sample - loss: 0.5048 - accuracy: 0.7493 - val_loss: 0.6787 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.5000 - accuracy: 0.7488 - val_loss: 0.6910 - val_accuracy: 0.5232\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.4954 - accuracy: 0.7490 - val_loss: 0.6681 - val_accuracy: 0.5742\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.4886 - accuracy: 0.7482 - val_loss: 0.6923 - val_accuracy: 0.5013\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.4860 - accuracy: 0.7517 - val_loss: 0.7039 - val_accuracy: 0.4305\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 9s 407us/sample - loss: 0.4702 - accuracy: 0.7639 - val_loss: 2.1379 - val_accuracy: 0.5010\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 9s 408us/sample - loss: 0.4648 - accuracy: 0.7681 - val_loss: 1.6131 - val_accuracy: 0.5040\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 9s 419us/sample - loss: 0.4498 - accuracy: 0.7795 - val_loss: 1.0541 - val_accuracy: 0.5372\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 9s 416us/sample - loss: 0.4399 - accuracy: 0.7864 - val_loss: 0.8245 - val_accuracy: 0.5897\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.4266 - accuracy: 0.7951 - val_loss: 1.0288 - val_accuracy: 0.6053\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 9s 411us/sample - loss: 0.4183 - accuracy: 0.8009 - val_loss: 0.9134 - val_accuracy: 0.6127\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.4025 - accuracy: 0.8119 - val_loss: 0.7442 - val_accuracy: 0.5188\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.3976 - accuracy: 0.8164 - val_loss: 0.9646 - val_accuracy: 0.6220\n",
      "10666/10666 [==============================] - 3s 267us/sample - loss: 1.6478 - accuracy: 0.3896\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 572us/sample - loss: 0.6473 - accuracy: 0.6763 - val_loss: 0.9943 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 410us/sample - loss: 0.5649 - accuracy: 0.7452 - val_loss: 0.8427 - val_accuracy: 0.5188\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 429us/sample - loss: 0.5485 - accuracy: 0.7499 - val_loss: 0.8266 - val_accuracy: 0.5213\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 416us/sample - loss: 0.5419 - accuracy: 0.7517 - val_loss: 0.7439 - val_accuracy: 0.5742\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.5369 - accuracy: 0.7543 - val_loss: 0.7674 - val_accuracy: 0.5642\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.5306 - accuracy: 0.7569 - val_loss: 0.7420 - val_accuracy: 0.5660\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 405us/sample - loss: 0.5273 - accuracy: 0.7604 - val_loss: 0.8477 - val_accuracy: 0.5182\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 413us/sample - loss: 0.5241 - accuracy: 0.7598 - val_loss: 0.7528 - val_accuracy: 0.5680\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.5147 - accuracy: 0.7656 - val_loss: 0.8125 - val_accuracy: 0.5512\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 404us/sample - loss: 0.5074 - accuracy: 0.7697 - val_loss: 0.8209 - val_accuracy: 0.5530\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.4940 - accuracy: 0.7746 - val_loss: 0.8223 - val_accuracy: 0.5472racy: 0.77\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.4841 - accuracy: 0.7796 - val_loss: 0.7372 - val_accuracy: 0.6012\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 422us/sample - loss: 0.4711 - accuracy: 0.7835 - val_loss: 0.8910 - val_accuracy: 0.5602\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 374us/sample - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.8556 - val_accuracy: 0.5763\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.4210 - accuracy: 0.8017 - val_loss: 0.8591 - val_accuracy: 0.5732\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.3972 - accuracy: 0.8116 - val_loss: 1.0802 - val_accuracy: 0.5485\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 379us/sample - loss: 0.3577 - accuracy: 0.8320 - val_loss: 1.1257 - val_accuracy: 0.5550\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 379us/sample - loss: 0.3401 - accuracy: 0.8433 - val_loss: 1.1184 - val_accuracy: 0.5472\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 388us/sample - loss: 0.3111 - accuracy: 0.8568 - val_loss: 1.0770 - val_accuracy: 0.5540\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 381us/sample - loss: 0.3019 - accuracy: 0.8638 - val_loss: 1.1557 - val_accuracy: 0.5575\n",
      "10667/10667 [==============================] - 3s 246us/sample - loss: 1.8807 - accuracy: 0.3411\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 589us/sample - loss: 0.7593 - accuracy: 0.5289 - val_loss: 0.7479 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.6893 - accuracy: 0.5691 - val_loss: 0.6746 - val_accuracy: 0.5702\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 395us/sample - loss: 0.6715 - accuracy: 0.5898 - val_loss: 0.6675 - val_accuracy: 0.5882\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.6614 - accuracy: 0.6040 - val_loss: 0.6585 - val_accuracy: 0.6030\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 395us/sample - loss: 0.6533 - accuracy: 0.6101 - val_loss: 0.6582 - val_accuracy: 0.6085\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.6495 - accuracy: 0.6184 - val_loss: 0.6630 - val_accuracy: 0.6033\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 410us/sample - loss: 0.6438 - accuracy: 0.6297 - val_loss: 0.6687 - val_accuracy: 0.6053\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 426us/sample - loss: 0.6341 - accuracy: 0.6372 - val_loss: 0.6608 - val_accuracy: 0.6122\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.6280 - accuracy: 0.6486 - val_loss: 0.6620 - val_accuracy: 0.6110\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 397us/sample - loss: 0.6136 - accuracy: 0.6613 - val_loss: 0.6692 - val_accuracy: 0.6060\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.6043 - accuracy: 0.6764 - val_loss: 0.6754 - val_accuracy: 0.5990\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5827 - accuracy: 0.6962 - val_loss: 0.6982 - val_accuracy: 0.5925\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.5701 - accuracy: 0.7076 - val_loss: 0.7077 - val_accuracy: 0.5890\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5448 - accuracy: 0.7291 - val_loss: 0.7257 - val_accuracy: 0.5860\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.5315 - accuracy: 0.7370 - val_loss: 0.7591 - val_accuracy: 0.5910\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.5123 - accuracy: 0.7544 - val_loss: 0.7557 - val_accuracy: 0.5820\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.5028 - accuracy: 0.7584 - val_loss: 0.7692 - val_accuracy: 0.5760\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.4912 - accuracy: 0.7681 - val_loss: 0.7790 - val_accuracy: 0.5775\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 398us/sample - loss: 0.4884 - accuracy: 0.7690 - val_loss: 0.7876 - val_accuracy: 0.5810\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 397us/sample - loss: 0.4814 - accuracy: 0.7764 - val_loss: 0.7915 - val_accuracy: 0.5763\n",
      "10667/10667 [==============================] - 3s 266us/sample - loss: 0.7836 - accuracy: 0.5795\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 13s 597us/sample - loss: 0.6414 - accuracy: 0.6744 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 9s 434us/sample - loss: 0.5624 - accuracy: 0.7406 - val_loss: 0.7754 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 9s 411us/sample - loss: 0.5488 - accuracy: 0.7459 - val_loss: 0.7747 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 9s 411us/sample - loss: 0.5409 - accuracy: 0.7482 - val_loss: 0.7864 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.5375 - accuracy: 0.7492 - val_loss: 0.8107 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 9s 402us/sample - loss: 0.5326 - accuracy: 0.7483 - val_loss: 0.8014 - val_accuracy: 0.5005\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 9s 402us/sample - loss: 0.5292 - accuracy: 0.7490 - val_loss: 0.8063 - val_accuracy: 0.5040\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.5189 - accuracy: 0.7484 - val_loss: 0.8175 - val_accuracy: 0.5048\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 9s 402us/sample - loss: 0.5168 - accuracy: 0.7500 - val_loss: 0.7885 - val_accuracy: 0.5070\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 8s 398us/sample - loss: 0.5039 - accuracy: 0.7540 - val_loss: 0.8273 - val_accuracy: 0.5135\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 9s 405us/sample - loss: 0.4963 - accuracy: 0.7587 - val_loss: 0.8710 - val_accuracy: 0.5160\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.4832 - accuracy: 0.7672 - val_loss: 0.8443 - val_accuracy: 0.5197\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 9s 404us/sample - loss: 0.4746 - accuracy: 0.7699 - val_loss: 0.9119 - val_accuracy: 0.5165\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 398us/sample - loss: 0.4668 - accuracy: 0.7764 - val_loss: 0.8450 - val_accuracy: 0.5215\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 9s 401us/sample - loss: 0.4636 - accuracy: 0.7762 - val_loss: 0.8609 - val_accuracy: 0.5260\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 9s 404us/sample - loss: 0.4592 - accuracy: 0.7813 - val_loss: 0.8891 - val_accuracy: 0.5238\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 9s 405us/sample - loss: 0.4573 - accuracy: 0.7819 - val_loss: 0.8789 - val_accuracy: 0.5242\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 9s 402us/sample - loss: 0.4548 - accuracy: 0.7845 - val_loss: 0.8874 - val_accuracy: 0.5245\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 9s 401us/sample - loss: 0.4518 - accuracy: 0.7852 - val_loss: 0.8886 - val_accuracy: 0.5272\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 9s 400us/sample - loss: 0.4515 - accuracy: 0.7870 - val_loss: 0.8944 - val_accuracy: 0.5257\n",
      "10666/10666 [==============================] - 3s 269us/sample - loss: 1.4530 - accuracy: 0.1658\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 568us/sample - loss: 0.6353 - accuracy: 0.6862 - val_loss: 0.9371 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5688 - accuracy: 0.7442 - val_loss: 0.9179 - val_accuracy: 0.5040\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 407us/sample - loss: 0.5514 - accuracy: 0.7497 - val_loss: 0.8453 - val_accuracy: 0.5247\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5437 - accuracy: 0.7526 - val_loss: 0.8455 - val_accuracy: 0.5128\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.5384 - accuracy: 0.7528 - val_loss: 0.7369 - val_accuracy: 0.5965\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.5333 - accuracy: 0.7573 - val_loss: 0.7996 - val_accuracy: 0.5360\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 431us/sample - loss: 0.5294 - accuracy: 0.7586 - val_loss: 0.7500 - val_accuracy: 0.5782\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 414us/sample - loss: 0.5216 - accuracy: 0.7634 - val_loss: 0.8088 - val_accuracy: 0.5523\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.5178 - accuracy: 0.7652 - val_loss: 0.7787 - val_accuracy: 0.5702\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.5073 - accuracy: 0.7707 - val_loss: 0.8423 - val_accuracy: 0.5530\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 397us/sample - loss: 0.5004 - accuracy: 0.7756 - val_loss: 0.8723 - val_accuracy: 0.5253\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.4849 - accuracy: 0.7802 - val_loss: 0.7678 - val_accuracy: 0.5845\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 399us/sample - loss: 0.4745 - accuracy: 0.7840 - val_loss: 0.8938 - val_accuracy: 0.5620\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 405us/sample - loss: 0.4568 - accuracy: 0.7888 - val_loss: 0.8749 - val_accuracy: 0.5665\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.4473 - accuracy: 0.7925 - val_loss: 0.9153 - val_accuracy: 0.5602\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.4326 - accuracy: 0.7978 - val_loss: 0.8857 - val_accuracy: 0.5630\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.4249 - accuracy: 0.8024 - val_loss: 0.8875 - val_accuracy: 0.5688\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 429us/sample - loss: 0.4158 - accuracy: 0.8068 - val_loss: 0.8980 - val_accuracy: 0.5685\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 404us/sample - loss: 0.4114 - accuracy: 0.8062 - val_loss: 0.9094 - val_accuracy: 0.5680\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 408us/sample - loss: 0.4060 - accuracy: 0.8091 - val_loss: 0.9246 - val_accuracy: 0.5650\n",
      "10667/10667 [==============================] - 3s 273us/sample - loss: 1.5321 - accuracy: 0.2407\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 603us/sample - loss: 0.7340 - accuracy: 0.5349 - val_loss: 0.7121 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 405us/sample - loss: 0.6825 - accuracy: 0.5790 - val_loss: 0.6671 - val_accuracy: 0.5960\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 407us/sample - loss: 0.6659 - accuracy: 0.5969 - val_loss: 0.6605 - val_accuracy: 0.6005\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.6592 - accuracy: 0.6092 - val_loss: 0.6604 - val_accuracy: 0.5997\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.6495 - accuracy: 0.6223 - val_loss: 0.6601 - val_accuracy: 0.6045\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.6452 - accuracy: 0.6303 - val_loss: 0.6549 - val_accuracy: 0.6060\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.6403 - accuracy: 0.6339 - val_loss: 0.6563 - val_accuracy: 0.6090\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 404us/sample - loss: 0.6351 - accuracy: 0.6390 - val_loss: 0.6747 - val_accuracy: 0.6035\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.6191 - accuracy: 0.6579 - val_loss: 0.6522 - val_accuracy: 0.6205\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.6113 - accuracy: 0.6668 - val_loss: 0.6781 - val_accuracy: 0.6133\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.6020 - accuracy: 0.6734 - val_loss: 0.6661 - val_accuracy: 0.6220\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 405us/sample - loss: 0.5754 - accuracy: 0.7014 - val_loss: 0.6703 - val_accuracy: 0.6158\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.5590 - accuracy: 0.7144 - val_loss: 0.7023 - val_accuracy: 0.6162\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.5189 - accuracy: 0.7444 - val_loss: 0.7233 - val_accuracy: 0.5993\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.4977 - accuracy: 0.7585 - val_loss: 0.7442 - val_accuracy: 0.5920\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 404us/sample - loss: 0.4560 - accuracy: 0.7886 - val_loss: 0.7975 - val_accuracy: 0.5962\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.4334 - accuracy: 0.8032 - val_loss: 0.8337 - val_accuracy: 0.5907\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 403us/sample - loss: 0.4053 - accuracy: 0.8235 - val_loss: 0.8576 - val_accuracy: 0.5792\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 405us/sample - loss: 0.3923 - accuracy: 0.8284 - val_loss: 0.8818 - val_accuracy: 0.5810\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 427us/sample - loss: 0.3806 - accuracy: 0.8372 - val_loss: 0.8966 - val_accuracy: 0.5820\n",
      "10667/10667 [==============================] - 3s 271us/sample - loss: 0.8946 - accuracy: 0.5926\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 12s 544us/sample - loss: 0.6436 - accuracy: 0.6753 - val_loss: 0.7173 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 8s 375us/sample - loss: 0.5702 - accuracy: 0.7373 - val_loss: 0.7206 - val_accuracy: 0.5080\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 8s 374us/sample - loss: 0.5535 - accuracy: 0.7440 - val_loss: 0.7851 - val_accuracy: 0.5002\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 8s 373us/sample - loss: 0.5425 - accuracy: 0.7474 - val_loss: 0.7565 - val_accuracy: 0.5005\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 8s 370us/sample - loss: 0.5385 - accuracy: 0.7481 - val_loss: 0.8063 - val_accuracy: 0.4997\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 8s 369us/sample - loss: 0.5313 - accuracy: 0.7485 - val_loss: 0.8049 - val_accuracy: 0.5023\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 8s 376us/sample - loss: 0.5268 - accuracy: 0.7498 - val_loss: 0.7846 - val_accuracy: 0.5138\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 10s 445us/sample - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.8297 - val_accuracy: 0.5120\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 9s 408us/sample - loss: 0.5124 - accuracy: 0.7531 - val_loss: 0.7679 - val_accuracy: 0.5213\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 9s 414us/sample - loss: 0.4990 - accuracy: 0.7585 - val_loss: 0.8151 - val_accuracy: 0.5222\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 9s 425us/sample - loss: 0.4917 - accuracy: 0.7619 - val_loss: 0.8203 - val_accuracy: 0.5318\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 9s 423us/sample - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.8647 - val_accuracy: 0.5225\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 9s 423us/sample - loss: 0.4751 - accuracy: 0.7732 - val_loss: 0.8845 - val_accuracy: 0.5235\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.4676 - accuracy: 0.7797 - val_loss: 0.8584 - val_accuracy: 0.5290\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 9s 428us/sample - loss: 0.4640 - accuracy: 0.7796 - val_loss: 0.8465 - val_accuracy: 0.5335\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 10s 447us/sample - loss: 0.4574 - accuracy: 0.7857 - val_loss: 0.8835 - val_accuracy: 0.5307\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 9s 422us/sample - loss: 0.4572 - accuracy: 0.7857 - val_loss: 0.8754 - val_accuracy: 0.5315\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 9s 424us/sample - loss: 0.4556 - accuracy: 0.7886 - val_loss: 0.8813 - val_accuracy: 0.5307\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 9s 421us/sample - loss: 0.4513 - accuracy: 0.7886 - val_loss: 0.8742 - val_accuracy: 0.5343\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 9s 420us/sample - loss: 0.4521 - accuracy: 0.7888 - val_loss: 0.8793 - val_accuracy: 0.5350\n",
      "10666/10666 [==============================] - 3s 287us/sample - loss: 1.4409 - accuracy: 0.1878\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 594us/sample - loss: 0.5784 - accuracy: 0.7301 - val_loss: 0.7731 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 414us/sample - loss: 0.5411 - accuracy: 0.7546 - val_loss: 0.8057 - val_accuracy: 0.5290\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 418us/sample - loss: 0.5322 - accuracy: 0.7595 - val_loss: 0.7418 - val_accuracy: 0.5980\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 414us/sample - loss: 0.5253 - accuracy: 0.7598 - val_loss: 0.8159 - val_accuracy: 0.5635\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5174 - accuracy: 0.7649 - val_loss: 0.7664 - val_accuracy: 0.5587\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 10s 479us/sample - loss: 0.5038 - accuracy: 0.7713 - val_loss: 0.8381 - val_accuracy: 0.5155\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.4978 - accuracy: 0.7745 - val_loss: 0.6622 - val_accuracy: 0.6603\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.4948 - accuracy: 0.7754 - val_loss: 0.7372 - val_accuracy: 0.5615\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 415us/sample - loss: 0.4909 - accuracy: 0.7773 - val_loss: 0.9856 - val_accuracy: 0.5125\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 415us/sample - loss: 0.4808 - accuracy: 0.7844 - val_loss: 0.8962 - val_accuracy: 0.5010\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 415us/sample - loss: 0.4736 - accuracy: 0.7861 - val_loss: 0.9859 - val_accuracy: 0.5002\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 418us/sample - loss: 0.4619 - accuracy: 0.7910 - val_loss: 0.8962 - val_accuracy: 0.5362\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 423us/sample - loss: 0.4555 - accuracy: 0.8001 - val_loss: 0.7814 - val_accuracy: 0.6345\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.4417 - accuracy: 0.8037 - val_loss: 0.8476 - val_accuracy: 0.5295\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.4345 - accuracy: 0.8046 - val_loss: 0.7463 - val_accuracy: 0.6395\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 414us/sample - loss: 0.4221 - accuracy: 0.8101 - val_loss: 0.7965 - val_accuracy: 0.6060\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.4140 - accuracy: 0.8121 - val_loss: 0.8133 - val_accuracy: 0.6068\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.4042 - accuracy: 0.8177 - val_loss: 0.8425 - val_accuracy: 0.6065\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 406us/sample - loss: 0.3998 - accuracy: 0.8177 - val_loss: 0.8213 - val_accuracy: 0.6335\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.3930 - accuracy: 0.8222 - val_loss: 0.8002 - val_accuracy: 0.6315\n",
      "10667/10667 [==============================] - 3s 269us/sample - loss: 1.3224 - accuracy: 0.3600\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 570us/sample - loss: 0.6914 - accuracy: 0.5701 - val_loss: 0.7844 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 401us/sample - loss: 0.6589 - accuracy: 0.6094 - val_loss: 0.6564 - val_accuracy: 0.6168\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.6505 - accuracy: 0.6197 - val_loss: 0.7616 - val_accuracy: 0.5085\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 404us/sample - loss: 0.6383 - accuracy: 0.6373 - val_loss: 0.6796 - val_accuracy: 0.6118\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 400us/sample - loss: 0.6153 - accuracy: 0.6634 - val_loss: 0.8061 - val_accuracy: 0.4992\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 409us/sample - loss: 0.6074 - accuracy: 0.6757 - val_loss: 1.2569 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 402us/sample - loss: 0.5917 - accuracy: 0.6957 - val_loss: 0.6573 - val_accuracy: 0.6043\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 390us/sample - loss: 0.5873 - accuracy: 0.6968 - val_loss: 0.7503 - val_accuracy: 0.5100\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5738 - accuracy: 0.7102 - val_loss: 0.6475 - val_accuracy: 0.6643\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.5680 - accuracy: 0.7184 - val_loss: 0.7398 - val_accuracy: 0.5468\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5635 - accuracy: 0.7215 - val_loss: 0.7266 - val_accuracy: 0.6417\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.5494 - accuracy: 0.7326 - val_loss: 0.6144 - val_accuracy: 0.6785\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 364us/sample - loss: 0.5441 - accuracy: 0.7349 - val_loss: 0.7210 - val_accuracy: 0.6562\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5369 - accuracy: 0.7391 - val_loss: 0.6214 - val_accuracy: 0.6950\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5265 - accuracy: 0.7466 - val_loss: 0.6489 - val_accuracy: 0.6580\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.5203 - accuracy: 0.7537 - val_loss: 0.8889 - val_accuracy: 0.5335\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.5103 - accuracy: 0.7602 - val_loss: 0.6565 - val_accuracy: 0.6860TA: 0s - loss: 0.5112 - accu\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5087 - accuracy: 0.7607 - val_loss: 0.6806 - val_accuracy: 0.6360\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5023 - accuracy: 0.7649 - val_loss: 0.6178 - val_accuracy: 0.6942\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5007 - accuracy: 0.7659 - val_loss: 0.6185 - val_accuracy: 0.6963\n",
      "10667/10667 [==============================] - 2s 234us/sample - loss: 0.6205 - accuracy: 0.6858\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 11s 516us/sample - loss: 0.5762 - accuracy: 0.7303 - val_loss: 0.7295 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 8s 365us/sample - loss: 0.5404 - accuracy: 0.7482 - val_loss: 0.7266 - val_accuracy: 0.4997\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 8s 365us/sample - loss: 0.5364 - accuracy: 0.7479 - val_loss: 0.7877 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 0.5300 - accuracy: 0.7493 - val_loss: 0.7538 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 0.5157 - accuracy: 0.7492 - val_loss: 1.0760 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 8s 362us/sample - loss: 0.5075 - accuracy: 0.7494 - val_loss: 0.6911 - val_accuracy: 0.5067\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 0.5017 - accuracy: 0.7481 - val_loss: 0.7471 - val_accuracy: 0.5965\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 8s 363us/sample - loss: 0.4958 - accuracy: 0.7545 - val_loss: 0.8398 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 8s 366us/sample - loss: 0.4851 - accuracy: 0.7589 - val_loss: 0.7186 - val_accuracy: 0.5673\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 8s 371us/sample - loss: 0.4788 - accuracy: 0.7609 - val_loss: 0.6402 - val_accuracy: 0.6260\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 8s 394us/sample - loss: 0.4730 - accuracy: 0.7643 - val_loss: 0.7196 - val_accuracy: 0.5125\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 8s 371us/sample - loss: 0.4692 - accuracy: 0.7680 - val_loss: 0.6809 - val_accuracy: 0.5465\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 0.4487 - accuracy: 0.7805 - val_loss: 1.2125 - val_accuracy: 0.5720\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 8s 362us/sample - loss: 0.4397 - accuracy: 0.7887 - val_loss: 0.6697 - val_accuracy: 0.5832\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 8s 361us/sample - loss: 0.4203 - accuracy: 0.8029 - val_loss: 0.6948 - val_accuracy: 0.5625\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 8s 360us/sample - loss: 0.4069 - accuracy: 0.8104 - val_loss: 0.6937 - val_accuracy: 0.5807\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 8s 363us/sample - loss: 0.3896 - accuracy: 0.8218 - val_loss: 0.7018 - val_accuracy: 0.6065\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 8s 361us/sample - loss: 0.3804 - accuracy: 0.8271 - val_loss: 0.8936 - val_accuracy: 0.5893\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 8s 364us/sample - loss: 0.3661 - accuracy: 0.8366 - val_loss: 0.8036 - val_accuracy: 0.6148\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 8s 362us/sample - loss: 0.3577 - accuracy: 0.8418 - val_loss: 0.9506 - val_accuracy: 0.6095\n",
      "10666/10666 [==============================] - 3s 236us/sample - loss: 1.5775 - accuracy: 0.3606\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 542us/sample - loss: 0.5598 - accuracy: 0.7470 - val_loss: 0.8437 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 359us/sample - loss: 0.5425 - accuracy: 0.7535 - val_loss: 0.7122 - val_accuracy: 0.6102\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 359us/sample - loss: 0.5376 - accuracy: 0.7549 - val_loss: 1.0218 - val_accuracy: 0.5820\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 360us/sample - loss: 0.5402 - accuracy: 0.7531 - val_loss: 0.7044 - val_accuracy: 0.6085\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 361us/sample - loss: 0.5375 - accuracy: 0.7560 - val_loss: 0.8617 - val_accuracy: 0.5140\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5344 - accuracy: 0.7541 - val_loss: 0.7559 - val_accuracy: 0.5910\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.5164 - accuracy: 0.7637 - val_loss: 0.9731 - val_accuracy: 0.5005\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.5045 - accuracy: 0.7679 - val_loss: 0.6341 - val_accuracy: 0.6593\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.5011 - accuracy: 0.7674 - val_loss: 0.6446 - val_accuracy: 0.6743\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.4990 - accuracy: 0.7667 - val_loss: 1.5932 - val_accuracy: 0.5375\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 390us/sample - loss: 0.4849 - accuracy: 0.7805 - val_loss: 0.9160 - val_accuracy: 0.5038\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 361us/sample - loss: 0.4815 - accuracy: 0.7777 - val_loss: 0.9935 - val_accuracy: 0.5010\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.4724 - accuracy: 0.7842 - val_loss: 0.6322 - val_accuracy: 0.6895\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 361us/sample - loss: 0.4690 - accuracy: 0.7873 - val_loss: 0.8559 - val_accuracy: 0.5142\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 362us/sample - loss: 0.4661 - accuracy: 0.7910 - val_loss: 0.6576 - val_accuracy: 0.6948\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 360us/sample - loss: 0.4613 - accuracy: 0.7923 - val_loss: 0.6698 - val_accuracy: 0.6805\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 362us/sample - loss: 0.4570 - accuracy: 0.7956 - val_loss: 0.6437 - val_accuracy: 0.6888\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 360us/sample - loss: 0.4501 - accuracy: 0.7996 - val_loss: 0.7252 - val_accuracy: 0.6345\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.4473 - accuracy: 0.8000 - val_loss: 0.6900 - val_accuracy: 0.6880\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.4436 - accuracy: 0.8004 - val_loss: 0.6696 - val_accuracy: 0.6718\n",
      "10667/10667 [==============================] - 3s 246us/sample - loss: 1.0589 - accuracy: 0.4444\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 11s 519us/sample - loss: 0.6885 - accuracy: 0.5749 - val_loss: 0.7008 - val_accuracy: 0.5033\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.6655 - accuracy: 0.5998 - val_loss: 0.8059 - val_accuracy: 0.5615\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 362us/sample - loss: 0.6593 - accuracy: 0.6133 - val_loss: 0.7535 - val_accuracy: 0.6170\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 360us/sample - loss: 0.6448 - accuracy: 0.6341 - val_loss: 0.6399 - val_accuracy: 0.6365\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.6332 - accuracy: 0.6521 - val_loss: 0.7162 - val_accuracy: 0.5192\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 361us/sample - loss: 0.6274 - accuracy: 0.6602 - val_loss: 0.6226 - val_accuracy: 0.6672\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.6219 - accuracy: 0.6722 - val_loss: 0.6479 - val_accuracy: 0.6072\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.6157 - accuracy: 0.6727 - val_loss: 0.7465 - val_accuracy: 0.5015\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 385us/sample - loss: 0.5951 - accuracy: 0.6934 - val_loss: 0.5978 - val_accuracy: 0.7040\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 373us/sample - loss: 0.5932 - accuracy: 0.6999 - val_loss: 0.7559 - val_accuracy: 0.5008\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5914 - accuracy: 0.7007 - val_loss: 0.6582 - val_accuracy: 0.6003\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 396us/sample - loss: 0.5777 - accuracy: 0.7097 - val_loss: 0.8610 - val_accuracy: 0.5050\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5735 - accuracy: 0.7120 - val_loss: 0.6849 - val_accuracy: 0.6087\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5621 - accuracy: 0.7204 - val_loss: 0.7823 - val_accuracy: 0.6210\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 369us/sample - loss: 0.5593 - accuracy: 0.7227 - val_loss: 0.5756 - val_accuracy: 0.7072\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5576 - accuracy: 0.7246 - val_loss: 0.6130 - val_accuracy: 0.6683\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.5527 - accuracy: 0.7281 - val_loss: 0.7459 - val_accuracy: 0.5940\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 376us/sample - loss: 0.5438 - accuracy: 0.7332 - val_loss: 0.5895 - val_accuracy: 0.6927\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 363us/sample - loss: 0.5402 - accuracy: 0.7352 - val_loss: 0.6316 - val_accuracy: 0.6743\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 374us/sample - loss: 0.5320 - accuracy: 0.7409 - val_loss: 0.5869 - val_accuracy: 0.7005\n",
      "10667/10667 [==============================] - 3s 241us/sample - loss: 0.5937 - accuracy: 0.6905\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 12s 568us/sample - loss: 0.5590 - accuracy: 0.7444 - val_loss: 0.8062 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 9s 417us/sample - loss: 0.5415 - accuracy: 0.7482 - val_loss: 0.9983 - val_accuracy: 0.5105\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 9s 424us/sample - loss: 0.5376 - accuracy: 0.7483 - val_loss: 0.7573 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 9s 426us/sample - loss: 0.5372 - accuracy: 0.7451 - val_loss: 0.7609 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 9s 420us/sample - loss: 0.5297 - accuracy: 0.7463 - val_loss: 0.9915 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 9s 418us/sample - loss: 0.5196 - accuracy: 0.7455 - val_loss: 0.6526 - val_accuracy: 0.5422\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 9s 415us/sample - loss: 0.5079 - accuracy: 0.7479 - val_loss: 1.2337 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 9s 411us/sample - loss: 0.5021 - accuracy: 0.7456 - val_loss: 1.2366 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 9s 411us/sample - loss: 0.4901 - accuracy: 0.7478 - val_loss: 0.6693 - val_accuracy: 0.5853\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.4859 - accuracy: 0.7515 - val_loss: 0.6327 - val_accuracy: 0.6647\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 9s 409us/sample - loss: 0.4849 - accuracy: 0.7502 - val_loss: 0.7483 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 9s 412us/sample - loss: 0.4857 - accuracy: 0.7518 - val_loss: 0.7119 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.4745 - accuracy: 0.7577 - val_loss: 0.9319 - val_accuracy: 0.5788\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 9s 417us/sample - loss: 0.4703 - accuracy: 0.7639 - val_loss: 0.7677 - val_accuracy: 0.5458\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 9s 433us/sample - loss: 0.4625 - accuracy: 0.7683 - val_loss: 0.7200 - val_accuracy: 0.5048\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 9s 416us/sample - loss: 0.4573 - accuracy: 0.7737 - val_loss: 0.7013 - val_accuracy: 0.6127\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 9s 410us/sample - loss: 0.4502 - accuracy: 0.7801 - val_loss: 0.6683 - val_accuracy: 0.5795\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 9s 412us/sample - loss: 0.4494 - accuracy: 0.7792 - val_loss: 0.7518 - val_accuracy: 0.6430\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 9s 414us/sample - loss: 0.4420 - accuracy: 0.7846 - val_loss: 0.6994 - val_accuracy: 0.6190\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 9s 428us/sample - loss: 0.4396 - accuracy: 0.7890 - val_loss: 0.6627 - val_accuracy: 0.6183\n",
      "10666/10666 [==============================] - 3s 252us/sample - loss: 0.9900 - accuracy: 0.3641\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 604us/sample - loss: 0.5706 - accuracy: 0.7400 - val_loss: 0.8609 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 8s 379us/sample - loss: 0.5402 - accuracy: 0.7541 - val_loss: 0.7762 - val_accuracy: 0.5570\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.5306 - accuracy: 0.7582 - val_loss: 0.7222 - val_accuracy: 0.6115\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.5232 - accuracy: 0.7609 - val_loss: 0.7353 - val_accuracy: 0.5962\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.5173 - accuracy: 0.7636 - val_loss: 0.8524 - val_accuracy: 0.5395\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.5035 - accuracy: 0.7713 - val_loss: 0.8738 - val_accuracy: 0.5142\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.4973 - accuracy: 0.7744 - val_loss: 0.9864 - val_accuracy: 0.5002\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 8s 364us/sample - loss: 0.4826 - accuracy: 0.7845 - val_loss: 0.6397 - val_accuracy: 0.6825\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.4772 - accuracy: 0.7838 - val_loss: 0.7055 - val_accuracy: 0.6237\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 8s 372us/sample - loss: 0.4744 - accuracy: 0.7852 - val_loss: 0.6203 - val_accuracy: 0.6862\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 8s 370us/sample - loss: 0.4706 - accuracy: 0.7885 - val_loss: 0.6528 - val_accuracy: 0.6820\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 8s 375us/sample - loss: 0.4669 - accuracy: 0.7890 - val_loss: 1.1310 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 8s 368us/sample - loss: 0.4536 - accuracy: 0.7966 - val_loss: 1.0178 - val_accuracy: 0.5052\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.4460 - accuracy: 0.8004 - val_loss: 1.1638 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 8s 367us/sample - loss: 0.4331 - accuracy: 0.8079 - val_loss: 0.9000 - val_accuracy: 0.5642\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 8s 371us/sample - loss: 0.4254 - accuracy: 0.8089 - val_loss: 0.6903 - val_accuracy: 0.6612\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.4141 - accuracy: 0.8157 - val_loss: 0.6868 - val_accuracy: 0.6808\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 8s 364us/sample - loss: 0.4084 - accuracy: 0.8186 - val_loss: 0.7336 - val_accuracy: 0.6568\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 8s 365us/sample - loss: 0.3982 - accuracy: 0.8210 - val_loss: 0.7440 - val_accuracy: 0.6575\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 8s 366us/sample - loss: 0.3959 - accuracy: 0.8237 - val_loss: 0.8273 - val_accuracy: 0.6045\n",
      "10667/10667 [==============================] - 3s 242us/sample - loss: 1.4543 - accuracy: 0.2878\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 12s 554us/sample - loss: 0.6869 - accuracy: 0.5818 - val_loss: 0.7543 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 413us/sample - loss: 0.6585 - accuracy: 0.6106 - val_loss: 0.6531 - val_accuracy: 0.6155\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 410us/sample - loss: 0.6509 - accuracy: 0.6239 - val_loss: 0.6457 - val_accuracy: 0.6270\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 408us/sample - loss: 0.6407 - accuracy: 0.6384 - val_loss: 0.6324 - val_accuracy: 0.6545\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 408us/sample - loss: 0.6292 - accuracy: 0.6517 - val_loss: 0.7055 - val_accuracy: 0.5735\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 408us/sample - loss: 0.6207 - accuracy: 0.6624 - val_loss: 0.7242 - val_accuracy: 0.5400\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 410us/sample - loss: 0.6053 - accuracy: 0.6818 - val_loss: 0.6657 - val_accuracy: 0.5882\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 410us/sample - loss: 0.5975 - accuracy: 0.6868 - val_loss: 0.6640 - val_accuracy: 0.5932\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 413us/sample - loss: 0.5830 - accuracy: 0.7029 - val_loss: 0.5917 - val_accuracy: 0.6975\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 408us/sample - loss: 0.5788 - accuracy: 0.7068 - val_loss: 1.8354 - val_accuracy: 0.5025\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 409us/sample - loss: 0.5749 - accuracy: 0.7114 - val_loss: 1.1255 - val_accuracy: 0.5860\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 411us/sample - loss: 0.5605 - accuracy: 0.7234 - val_loss: 0.8298 - val_accuracy: 0.5082\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 410us/sample - loss: 0.5552 - accuracy: 0.7256 - val_loss: 0.7960 - val_accuracy: 0.6330\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 414us/sample - loss: 0.5392 - accuracy: 0.7371 - val_loss: 0.6317 - val_accuracy: 0.6980\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 9s 412us/sample - loss: 0.5340 - accuracy: 0.7411 - val_loss: 0.6040 - val_accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 409us/sample - loss: 0.5237 - accuracy: 0.7484 - val_loss: 0.7561 - val_accuracy: 0.5425\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 416us/sample - loss: 0.5184 - accuracy: 0.7535 - val_loss: 0.5946 - val_accuracy: 0.6960\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 409us/sample - loss: 0.5127 - accuracy: 0.7567 - val_loss: 0.6055 - val_accuracy: 0.7013\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 409us/sample - loss: 0.5096 - accuracy: 0.7594 - val_loss: 0.6025 - val_accuracy: 0.6938\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 411us/sample - loss: 0.5047 - accuracy: 0.7623 - val_loss: 0.5970 - val_accuracy: 0.6995\n",
      "10667/10667 [==============================] - 3s 238us/sample - loss: 0.5942 - accuracy: 0.6926\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 13s 622us/sample - loss: 0.5709 - accuracy: 0.7385 - val_loss: 0.8703 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 10s 475us/sample - loss: 0.5424 - accuracy: 0.7490 - val_loss: 0.7838 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 10s 466us/sample - loss: 0.5374 - accuracy: 0.7483 - val_loss: 0.8124 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 10s 466us/sample - loss: 0.5340 - accuracy: 0.7500 - val_loss: 0.7772 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 10s 464us/sample - loss: 0.5287 - accuracy: 0.7488 - val_loss: 0.8151 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 10s 468us/sample - loss: 0.5213 - accuracy: 0.7492 - val_loss: 1.4846 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 10s 470us/sample - loss: 0.5076 - accuracy: 0.7496 - val_loss: 0.8211 - val_accuracy: 0.5472\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 10s 472us/sample - loss: 0.4973 - accuracy: 0.7488 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 10s 470us/sample - loss: 0.4909 - accuracy: 0.7507 - val_loss: 1.0005 - val_accuracy: 0.5222\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 10s 463us/sample - loss: 0.4856 - accuracy: 0.7543 - val_loss: 0.7119 - val_accuracy: 0.4815\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 10s 465us/sample - loss: 0.4750 - accuracy: 0.7609 - val_loss: 0.7119 - val_accuracy: 0.4290\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 10s 464us/sample - loss: 0.4699 - accuracy: 0.7647 - val_loss: 0.9209 - val_accuracy: 0.5130\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21334/21334 [==============================] - 10s 457us/sample - loss: 0.4560 - accuracy: 0.7742 - val_loss: 1.1816 - val_accuracy: 0.5372\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 10s 459us/sample - loss: 0.4511 - accuracy: 0.7797 - val_loss: 0.8771 - val_accuracy: 0.5957\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 10s 462us/sample - loss: 0.4402 - accuracy: 0.7884 - val_loss: 0.7362 - val_accuracy: 0.5840\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 10s 466us/sample - loss: 0.4332 - accuracy: 0.7910 - val_loss: 0.8394 - val_accuracy: 0.6130\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 10s 467us/sample - loss: 0.4226 - accuracy: 0.7992 - val_loss: 0.7609 - val_accuracy: 0.6065\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 10s 465us/sample - loss: 0.4196 - accuracy: 0.8027 - val_loss: 0.8094 - val_accuracy: 0.5890\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 10s 463us/sample - loss: 0.4096 - accuracy: 0.8086 - val_loss: 0.7755 - val_accuracy: 0.6083\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 10s 467us/sample - loss: 0.4070 - accuracy: 0.8092 - val_loss: 0.7730 - val_accuracy: 0.6168\n",
      "10666/10666 [==============================] - 3s 239us/sample - loss: 1.2974 - accuracy: 0.3604\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 615us/sample - loss: 0.5602 - accuracy: 0.7466 - val_loss: 0.8413 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5430 - accuracy: 0.7538 - val_loss: 1.2727 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 9s 425us/sample - loss: 0.5389 - accuracy: 0.7538 - val_loss: 0.8449 - val_accuracy: 0.5545\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 9s 422us/sample - loss: 0.5307 - accuracy: 0.7569 - val_loss: 0.8162 - val_accuracy: 0.5405\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.5287 - accuracy: 0.7583 - val_loss: 0.9662 - val_accuracy: 0.5050\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 9s 422us/sample - loss: 0.5237 - accuracy: 0.7574 - val_loss: 0.7983 - val_accuracy: 0.5372\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 9s 422us/sample - loss: 0.5177 - accuracy: 0.7646 - val_loss: 0.7863 - val_accuracy: 0.5610\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5127 - accuracy: 0.7645 - val_loss: 0.6629 - val_accuracy: 0.6390\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 9s 420us/sample - loss: 0.5071 - accuracy: 0.7665 - val_loss: 0.8635 - val_accuracy: 0.5535\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.5058 - accuracy: 0.7673 - val_loss: 0.9855 - val_accuracy: 0.5757\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.4898 - accuracy: 0.7777 - val_loss: 0.6627 - val_accuracy: 0.6735\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 9s 423us/sample - loss: 0.4869 - accuracy: 0.7804 - val_loss: 0.7008 - val_accuracy: 0.6110\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 9s 421us/sample - loss: 0.4843 - accuracy: 0.7812 - val_loss: 0.7005 - val_accuracy: 0.6450\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 9s 416us/sample - loss: 0.4750 - accuracy: 0.7856 - val_loss: 0.7547 - val_accuracy: 0.6285\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 9s 420us/sample - loss: 0.4697 - accuracy: 0.7894 - val_loss: 0.7627 - val_accuracy: 0.5957\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 9s 418us/sample - loss: 0.4637 - accuracy: 0.7903 - val_loss: 0.6566 - val_accuracy: 0.7003\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 9s 419us/sample - loss: 0.4577 - accuracy: 0.7952 - val_loss: 0.9764 - val_accuracy: 0.5010\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 9s 422us/sample - loss: 0.4536 - accuracy: 0.7981 - val_loss: 0.7195 - val_accuracy: 0.6798\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 9s 424us/sample - loss: 0.4458 - accuracy: 0.8043 - val_loss: 0.7446 - val_accuracy: 0.6267\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 9s 423us/sample - loss: 0.4411 - accuracy: 0.8035 - val_loss: 0.6912 - val_accuracy: 0.6440\n",
      "10667/10667 [==============================] - 3s 240us/sample - loss: 1.0938 - accuracy: 0.4006\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 13s 616us/sample - loss: 0.6854 - accuracy: 0.5746 - val_loss: 0.7039 - val_accuracy: 0.5025\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 10s 475us/sample - loss: 0.6649 - accuracy: 0.6007 - val_loss: 0.7175 - val_accuracy: 0.6053\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 10s 472us/sample - loss: 0.6621 - accuracy: 0.6037 - val_loss: 1.0942 - val_accuracy: 0.5955\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 10s 469us/sample - loss: 0.6509 - accuracy: 0.6222 - val_loss: 0.7893 - val_accuracy: 0.5023\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 10s 464us/sample - loss: 0.6442 - accuracy: 0.6380 - val_loss: 0.6396 - val_accuracy: 0.6330\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 10s 464us/sample - loss: 0.6391 - accuracy: 0.6446 - val_loss: 0.8849 - val_accuracy: 0.5683\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 10s 465us/sample - loss: 0.6310 - accuracy: 0.6549 - val_loss: 0.9270 - val_accuracy: 0.5620\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 10s 472us/sample - loss: 0.6129 - accuracy: 0.6774 - val_loss: 0.6182 - val_accuracy: 0.6670\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 10s 463us/sample - loss: 0.6042 - accuracy: 0.6870 - val_loss: 0.7142 - val_accuracy: 0.6310\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5999 - accuracy: 0.6902 - val_loss: 0.9993 - val_accuracy: 0.5470\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5876 - accuracy: 0.7011 - val_loss: 0.6111 - val_accuracy: 0.6940\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 10s 456us/sample - loss: 0.5819 - accuracy: 0.7074 - val_loss: 0.5861 - val_accuracy: 0.6988\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 10s 461us/sample - loss: 0.5802 - accuracy: 0.7079 - val_loss: 0.6506 - val_accuracy: 0.6085\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 10s 460us/sample - loss: 0.5735 - accuracy: 0.7106 - val_loss: 0.7268 - val_accuracy: 0.6500\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5663 - accuracy: 0.7206 - val_loss: 0.6006 - val_accuracy: 0.6905\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5625 - accuracy: 0.7230 - val_loss: 0.5845 - val_accuracy: 0.7045\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5584 - accuracy: 0.7259 - val_loss: 0.6611 - val_accuracy: 0.6765\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 10s 460us/sample - loss: 0.5552 - accuracy: 0.7280 - val_loss: 0.6479 - val_accuracy: 0.6900\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5457 - accuracy: 0.7335 - val_loss: 0.6581 - val_accuracy: 0.6902\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 10s 459us/sample - loss: 0.5415 - accuracy: 0.7370 - val_loss: 0.6148 - val_accuracy: 0.6935\n",
      "10667/10667 [==============================] - 3s 239us/sample - loss: 0.6138 - accuracy: 0.6994\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 14s 650us/sample - loss: 0.5587 - accuracy: 0.7436 - val_loss: 0.7863 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 11s 506us/sample - loss: 0.5433 - accuracy: 0.7489 - val_loss: 0.7773 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 11s 507us/sample - loss: 0.5398 - accuracy: 0.7483 - val_loss: 0.8722 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 11s 511us/sample - loss: 0.5370 - accuracy: 0.7467 - val_loss: 0.8404 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 11s 508us/sample - loss: 0.5224 - accuracy: 0.7481 - val_loss: 0.9120 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 11s 510us/sample - loss: 0.5205 - accuracy: 0.7468 - val_loss: 0.6631 - val_accuracy: 0.5857\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 11s 507us/sample - loss: 0.5139 - accuracy: 0.7460 - val_loss: 2.5510 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 11s 507us/sample - loss: 0.5061 - accuracy: 0.7447 - val_loss: 1.9973 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 11s 506us/sample - loss: 0.4922 - accuracy: 0.7539 - val_loss: 1.3085 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 11s 508us/sample - loss: 0.4872 - accuracy: 0.7536 - val_loss: 0.6452 - val_accuracy: 0.5978\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 11s 508us/sample - loss: 0.4854 - accuracy: 0.7548 - val_loss: 0.7492 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 11s 509us/sample - loss: 0.4852 - accuracy: 0.7560 - val_loss: 0.8250 - val_accuracy: 0.5420\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 11s 508us/sample - loss: 0.4728 - accuracy: 0.7654 - val_loss: 1.0023 - val_accuracy: 0.5495\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 11s 516us/sample - loss: 0.4697 - accuracy: 0.7687 - val_loss: 1.2258 - val_accuracy: 0.5148\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 11s 508us/sample - loss: 0.4631 - accuracy: 0.7724 - val_loss: 0.7588 - val_accuracy: 0.6083\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 11s 507us/sample - loss: 0.4578 - accuracy: 0.7752 - val_loss: 0.6909 - val_accuracy: 0.5455\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 11s 508us/sample - loss: 0.4502 - accuracy: 0.7811 - val_loss: 0.8788 - val_accuracy: 0.6005\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 11s 510us/sample - loss: 0.4488 - accuracy: 0.7827 - val_loss: 0.6780 - val_accuracy: 0.5950\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 11s 509us/sample - loss: 0.4428 - accuracy: 0.7864 - val_loss: 0.8122 - val_accuracy: 0.6155\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 11s 506us/sample - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.6436 - val_accuracy: 0.6342\n",
      "10666/10666 [==============================] - 3s 236us/sample - loss: 0.8797 - accuracy: 0.4257\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 15s 704us/sample - loss: 0.5641 - accuracy: 0.7458 - val_loss: 0.8841 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 12s 558us/sample - loss: 0.5399 - accuracy: 0.7542 - val_loss: 0.7020 - val_accuracy: 0.6150\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 12s 559us/sample - loss: 0.5339 - accuracy: 0.7543 - val_loss: 1.6508 - val_accuracy: 0.5428\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 12s 560us/sample - loss: 0.5302 - accuracy: 0.7569 - val_loss: 0.7342 - val_accuracy: 0.6525\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 12s 558us/sample - loss: 0.5100 - accuracy: 0.7674 - val_loss: 0.7629 - val_accuracy: 0.5755\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 12s 558us/sample - loss: 0.5046 - accuracy: 0.7684 - val_loss: 1.0353 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 12s 557us/sample - loss: 0.4919 - accuracy: 0.7776 - val_loss: 0.6717 - val_accuracy: 0.6702\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 12s 556us/sample - loss: 0.4889 - accuracy: 0.7786 - val_loss: 0.6748 - val_accuracy: 0.6148\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 12s 557us/sample - loss: 0.4848 - accuracy: 0.7786 - val_loss: 0.9804 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 12s 561us/sample - loss: 0.4757 - accuracy: 0.7856 - val_loss: 0.6245 - val_accuracy: 0.6852\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 12s 568us/sample - loss: 0.4736 - accuracy: 0.7846 - val_loss: 0.9247 - val_accuracy: 0.5805\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 12s 565us/sample - loss: 0.4706 - accuracy: 0.7862 - val_loss: 0.8529 - val_accuracy: 0.5340\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 12s 558us/sample - loss: 0.4645 - accuracy: 0.7918 - val_loss: 0.9247 - val_accuracy: 0.5090\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 12s 557us/sample - loss: 0.4602 - accuracy: 0.7949 - val_loss: 0.6706 - val_accuracy: 0.6873\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 12s 559us/sample - loss: 0.4541 - accuracy: 0.7987 - val_loss: 0.7989 - val_accuracy: 0.5890\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 12s 556us/sample - loss: 0.4526 - accuracy: 0.7980 - val_loss: 0.6931 - val_accuracy: 0.6453\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 12s 563us/sample - loss: 0.4467 - accuracy: 0.7993 - val_loss: 0.6539 - val_accuracy: 0.6998\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 12s 558us/sample - loss: 0.4448 - accuracy: 0.8007 - val_loss: 0.6935 - val_accuracy: 0.6637\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 12s 555us/sample - loss: 0.4408 - accuracy: 0.8036 - val_loss: 0.6851 - val_accuracy: 0.6685\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 12s 558us/sample - loss: 0.4403 - accuracy: 0.8035 - val_loss: 0.6768 - val_accuracy: 0.6880\n",
      "10667/10667 [==============================] - 3s 234us/sample - loss: 1.0424 - accuracy: 0.4996\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 14s 657us/sample - loss: 0.6901 - accuracy: 0.5603 - val_loss: 0.6950 - val_accuracy: 0.5128\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 11s 512us/sample - loss: 0.6650 - accuracy: 0.6019 - val_loss: 0.7044 - val_accuracy: 0.6110\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.6618 - accuracy: 0.6063 - val_loss: 0.6626 - val_accuracy: 0.6047\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.6533 - accuracy: 0.6234 - val_loss: 0.6767 - val_accuracy: 0.6305\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 11s 513us/sample - loss: 0.6521 - accuracy: 0.6262 - val_loss: 0.7081 - val_accuracy: 0.5153\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 11s 512us/sample - loss: 0.6241 - accuracy: 0.6680 - val_loss: 0.6295 - val_accuracy: 0.6697\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 11s 512us/sample - loss: 0.6146 - accuracy: 0.6772 - val_loss: 0.7340 - val_accuracy: 0.5005\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 11s 512us/sample - loss: 0.6070 - accuracy: 0.6830 - val_loss: 0.6963 - val_accuracy: 0.4815\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 11s 509us/sample - loss: 0.5903 - accuracy: 0.6959 - val_loss: 0.7332 - val_accuracy: 0.6252\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.5881 - accuracy: 0.7030 - val_loss: 0.6462 - val_accuracy: 0.6485\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 11s 513us/sample - loss: 0.5778 - accuracy: 0.7075 - val_loss: 0.7005 - val_accuracy: 0.5002\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.5723 - accuracy: 0.7131 - val_loss: 0.5880 - val_accuracy: 0.6935\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.5711 - accuracy: 0.7156 - val_loss: 0.7077 - val_accuracy: 0.5002\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.5664 - accuracy: 0.7187 - val_loss: 0.5785 - val_accuracy: 0.7138\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 11s 511us/sample - loss: 0.5664 - accuracy: 0.7146 - val_loss: 0.9212 - val_accuracy: 0.5340\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21333/21333 [==============================] - 11s 514us/sample - loss: 0.5639 - accuracy: 0.7205 - val_loss: 0.6760 - val_accuracy: 0.5595\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 11s 515us/sample - loss: 0.5533 - accuracy: 0.7262 - val_loss: 0.5739 - val_accuracy: 0.7105\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 11s 514us/sample - loss: 0.5513 - accuracy: 0.7302 - val_loss: 0.6138 - val_accuracy: 0.6908\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 11s 513us/sample - loss: 0.5481 - accuracy: 0.7316 - val_loss: 0.7640 - val_accuracy: 0.6250\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 11s 513us/sample - loss: 0.5389 - accuracy: 0.7374 - val_loss: 0.5770 - val_accuracy: 0.7055\n",
      "10667/10667 [==============================] - 2s 232us/sample - loss: 0.5799 - accuracy: 0.6987\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 15s 711us/sample - loss: 0.5751 - accuracy: 0.7443 - val_loss: 0.8024 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.5461 - accuracy: 0.7487 - val_loss: 0.7083 - val_accuracy: 0.5008\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 12s 565us/sample - loss: 0.5417 - accuracy: 0.7487 - val_loss: 0.7164 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.5429 - accuracy: 0.7476 - val_loss: 0.8439 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 12s 565us/sample - loss: 0.5356 - accuracy: 0.7471 - val_loss: 0.7629 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.5322 - accuracy: 0.7492 - val_loss: 0.9868 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 12s 563us/sample - loss: 0.5255 - accuracy: 0.7489 - val_loss: 0.7730 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 12s 565us/sample - loss: 0.5199 - accuracy: 0.7477 - val_loss: 0.8538 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 12s 565us/sample - loss: 0.5106 - accuracy: 0.7502 - val_loss: 0.7296 - val_accuracy: 0.5008\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 12s 564us/sample - loss: 0.5052 - accuracy: 0.7487 - val_loss: 0.6498 - val_accuracy: 0.6233\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.5003 - accuracy: 0.7511 - val_loss: 0.8416 - val_accuracy: 0.5035\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.4976 - accuracy: 0.7485 - val_loss: 0.6814 - val_accuracy: 0.5192\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.4850 - accuracy: 0.7516 - val_loss: 1.1667 - val_accuracy: 0.5347\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 12s 567us/sample - loss: 0.4830 - accuracy: 0.7549 - val_loss: 0.6370 - val_accuracy: 0.6415\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 12s 568us/sample - loss: 0.4775 - accuracy: 0.7585 - val_loss: 0.6850 - val_accuracy: 0.5353\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 12s 567us/sample - loss: 0.4735 - accuracy: 0.7584 - val_loss: 1.2160 - val_accuracy: 0.5117\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 12s 568us/sample - loss: 0.4626 - accuracy: 0.7679 - val_loss: 0.7780 - val_accuracy: 0.5907\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 12s 566us/sample - loss: 0.4574 - accuracy: 0.7693 - val_loss: 0.8146 - val_accuracy: 0.5715\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 12s 567us/sample - loss: 0.4465 - accuracy: 0.7780 - val_loss: 0.6460 - val_accuracy: 0.6532\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 12s 564us/sample - loss: 0.4416 - accuracy: 0.7806 - val_loss: 0.7870 - val_accuracy: 0.6130\n",
      "10666/10666 [==============================] - 2s 234us/sample - loss: 1.2969 - accuracy: 0.3432\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 16s 752us/sample - loss: 0.6454 - accuracy: 0.6740 - val_loss: 0.9197 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 13s 600us/sample - loss: 0.5686 - accuracy: 0.7393 - val_loss: 0.7838 - val_accuracy: 0.5472\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 13s 603us/sample - loss: 0.5516 - accuracy: 0.7511 - val_loss: 0.8000 - val_accuracy: 0.5440\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 13s 601us/sample - loss: 0.5427 - accuracy: 0.7538 - val_loss: 0.7387 - val_accuracy: 0.5770\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 13s 603us/sample - loss: 0.5381 - accuracy: 0.7562 - val_loss: 0.7817 - val_accuracy: 0.5537\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 13s 603us/sample - loss: 0.5344 - accuracy: 0.7583 - val_loss: 0.8690 - val_accuracy: 0.5117\n",
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 13s 600us/sample - loss: 0.5236 - accuracy: 0.7623 - val_loss: 0.8538 - val_accuracy: 0.5268\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 13s 602us/sample - loss: 0.5213 - accuracy: 0.7653 - val_loss: 0.7461 - val_accuracy: 0.5730\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 13s 607us/sample - loss: 0.5114 - accuracy: 0.7676 - val_loss: 0.8197 - val_accuracy: 0.5375\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 13s 603us/sample - loss: 0.5011 - accuracy: 0.7736 - val_loss: 0.8207 - val_accuracy: 0.5393\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 13s 599us/sample - loss: 0.4854 - accuracy: 0.7810 - val_loss: 0.8657 - val_accuracy: 0.5372\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 13s 600us/sample - loss: 0.4729 - accuracy: 0.7851 - val_loss: 0.9371 - val_accuracy: 0.5462\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 13s 601us/sample - loss: 0.4484 - accuracy: 0.7992 - val_loss: 0.8738 - val_accuracy: 0.5602\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 13s 603us/sample - loss: 0.4356 - accuracy: 0.8027 - val_loss: 0.9456 - val_accuracy: 0.5502\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 13s 601us/sample - loss: 0.4166 - accuracy: 0.8123 - val_loss: 0.9793 - val_accuracy: 0.5445y: 0.81 - ETA: 0s - loss: 0.4167 - accuracy: 0.81\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 13s 599us/sample - loss: 0.4086 - accuracy: 0.8207 - val_loss: 0.9665 - val_accuracy: 0.5493\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 13s 599us/sample - loss: 0.3958 - accuracy: 0.8245 - val_loss: 0.9562 - val_accuracy: 0.5508\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 13s 600us/sample - loss: 0.3892 - accuracy: 0.8267 - val_loss: 0.9813 - val_accuracy: 0.5555\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 13s 601us/sample - loss: 0.3820 - accuracy: 0.8311 - val_loss: 0.9844 - val_accuracy: 0.5548\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 13s 599us/sample - loss: 0.3825 - accuracy: 0.8315 - val_loss: 0.9845 - val_accuracy: 0.5537\n",
      "10667/10667 [==============================] - 3s 238us/sample - loss: 1.5935 - accuracy: 0.2635\n",
      "Train on 21333 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21333/21333 [==============================] - 16s 744us/sample - loss: 0.7587 - accuracy: 0.5282 - val_loss: 0.7216 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21333/21333 [==============================] - 12s 562us/sample - loss: 0.6903 - accuracy: 0.5671 - val_loss: 0.6740 - val_accuracy: 0.5773\n",
      "Epoch 3/20\n",
      "21333/21333 [==============================] - 12s 563us/sample - loss: 0.6710 - accuracy: 0.5873 - val_loss: 0.6619 - val_accuracy: 0.5947\n",
      "Epoch 4/20\n",
      "21333/21333 [==============================] - 12s 564us/sample - loss: 0.6632 - accuracy: 0.5973 - val_loss: 0.6623 - val_accuracy: 0.6025\n",
      "Epoch 5/20\n",
      "21333/21333 [==============================] - 12s 565us/sample - loss: 0.6546 - accuracy: 0.6122 - val_loss: 0.6567 - val_accuracy: 0.6095\n",
      "Epoch 6/20\n",
      "21333/21333 [==============================] - 12s 564us/sample - loss: 0.6477 - accuracy: 0.6212 - val_loss: 0.6624 - val_accuracy: 0.6033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "21333/21333 [==============================] - 12s 564us/sample - loss: 0.6434 - accuracy: 0.6286 - val_loss: 0.6597 - val_accuracy: 0.6080\n",
      "Epoch 8/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.6324 - accuracy: 0.6440 - val_loss: 0.7001 - val_accuracy: 0.5710\n",
      "Epoch 9/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.6270 - accuracy: 0.6482 - val_loss: 0.6707 - val_accuracy: 0.6033\n",
      "Epoch 10/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.6137 - accuracy: 0.6664 - val_loss: 0.6686 - val_accuracy: 0.6090\n",
      "Epoch 11/20\n",
      "21333/21333 [==============================] - 12s 567us/sample - loss: 0.6039 - accuracy: 0.6744 - val_loss: 0.6713 - val_accuracy: 0.6120\n",
      "Epoch 12/20\n",
      "21333/21333 [==============================] - 12s 565us/sample - loss: 0.5852 - accuracy: 0.6944 - val_loss: 0.6842 - val_accuracy: 0.6008\n",
      "Epoch 13/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.5733 - accuracy: 0.7051 - val_loss: 0.6897 - val_accuracy: 0.6008\n",
      "Epoch 14/20\n",
      "21333/21333 [==============================] - 12s 565us/sample - loss: 0.5529 - accuracy: 0.7216 - val_loss: 0.7025 - val_accuracy: 0.6000\n",
      "Epoch 15/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.5415 - accuracy: 0.7339 - val_loss: 0.7161 - val_accuracy: 0.5922\n",
      "Epoch 16/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.5270 - accuracy: 0.7444 - val_loss: 0.7285 - val_accuracy: 0.5920\n",
      "Epoch 17/20\n",
      "21333/21333 [==============================] - 12s 564us/sample - loss: 0.5173 - accuracy: 0.7494 - val_loss: 0.7402 - val_accuracy: 0.5932\n",
      "Epoch 18/20\n",
      "21333/21333 [==============================] - 12s 566us/sample - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.7489 - val_accuracy: 0.5915\n",
      "Epoch 19/20\n",
      "21333/21333 [==============================] - 12s 567us/sample - loss: 0.5047 - accuracy: 0.7615 - val_loss: 0.7549 - val_accuracy: 0.5875\n",
      "Epoch 20/20\n",
      "21333/21333 [==============================] - 12s 565us/sample - loss: 0.5010 - accuracy: 0.7630 - val_loss: 0.7577 - val_accuracy: 0.5905\n",
      "10667/10667 [==============================] - 3s 235us/sample - loss: 0.7555 - accuracy: 0.5875\n",
      "Train on 21334 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "21334/21334 [==============================] - 16s 728us/sample - loss: 0.6462 - accuracy: 0.6757 - val_loss: 0.7409 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "21334/21334 [==============================] - 12s 579us/sample - loss: 0.5656 - accuracy: 0.7371 - val_loss: 0.7815 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "21334/21334 [==============================] - 12s 579us/sample - loss: 0.5511 - accuracy: 0.7422 - val_loss: 0.7613 - val_accuracy: 0.5013\n",
      "Epoch 4/20\n",
      "21334/21334 [==============================] - 12s 577us/sample - loss: 0.5426 - accuracy: 0.7472 - val_loss: 0.7605 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "21334/21334 [==============================] - 12s 579us/sample - loss: 0.5378 - accuracy: 0.7457 - val_loss: 0.8257 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "21334/21334 [==============================] - 12s 575us/sample - loss: 0.5333 - accuracy: 0.7496 - val_loss: 0.8137 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "21334/21334 [==============================] - 12s 577us/sample - loss: 0.5309 - accuracy: 0.7476 - val_loss: 0.8098 - val_accuracy: 0.5065\n",
      "Epoch 8/20\n",
      "21334/21334 [==============================] - 12s 576us/sample - loss: 0.5230 - accuracy: 0.7481 - val_loss: 0.8237 - val_accuracy: 0.5045\n",
      "Epoch 9/20\n",
      "21334/21334 [==============================] - 12s 577us/sample - loss: 0.5215 - accuracy: 0.7470 - val_loss: 0.7870 - val_accuracy: 0.5052\n",
      "Epoch 10/20\n",
      "21334/21334 [==============================] - 12s 578us/sample - loss: 0.5144 - accuracy: 0.7481 - val_loss: 0.7434 - val_accuracy: 0.5175\n",
      "Epoch 11/20\n",
      "21334/21334 [==============================] - 12s 575us/sample - loss: 0.5095 - accuracy: 0.7494 - val_loss: 0.8209 - val_accuracy: 0.5120\n",
      "Epoch 12/20\n",
      "21334/21334 [==============================] - 12s 578us/sample - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.7935 - val_accuracy: 0.5173\n",
      "Epoch 13/20\n",
      "21334/21334 [==============================] - 12s 574us/sample - loss: 0.5000 - accuracy: 0.7529 - val_loss: 0.8721 - val_accuracy: 0.5165\n",
      "Epoch 14/20\n",
      "21334/21334 [==============================] - 12s 577us/sample - loss: 0.4959 - accuracy: 0.7549 - val_loss: 0.8067 - val_accuracy: 0.5192\n",
      "Epoch 15/20\n",
      "21334/21334 [==============================] - 12s 576us/sample - loss: 0.4928 - accuracy: 0.7587 - val_loss: 0.8454 - val_accuracy: 0.5182\n",
      "Epoch 16/20\n",
      "21334/21334 [==============================] - 12s 577us/sample - loss: 0.4897 - accuracy: 0.7594 - val_loss: 0.8364 - val_accuracy: 0.5200\n",
      "Epoch 17/20\n",
      "21334/21334 [==============================] - 12s 576us/sample - loss: 0.4893 - accuracy: 0.7613 - val_loss: 0.8299 - val_accuracy: 0.5195\n",
      "Epoch 18/20\n",
      "21334/21334 [==============================] - 12s 576us/sample - loss: 0.4884 - accuracy: 0.7597 - val_loss: 0.8271 - val_accuracy: 0.5230\n",
      "Epoch 19/20\n",
      "21334/21334 [==============================] - 12s 575us/sample - loss: 0.4856 - accuracy: 0.7609 - val_loss: 0.8240 - val_accuracy: 0.5265\n",
      "Epoch 20/20\n",
      "21334/21334 [==============================] - 12s 576us/sample - loss: 0.4873 - accuracy: 0.7592 - val_loss: 0.8313 - val_accuracy: 0.5232\n",
      "10666/10666 [==============================] - 3s 236us/sample - loss: 1.3411 - accuracy: 0.1159\n",
      "Train on 32000 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "32000/32000 [==============================] - 20s 612us/sample - loss: 0.6822 - accuracy: 0.5768 - val_loss: 0.6945 - val_accuracy: 0.5750\n",
      "Epoch 2/20\n",
      "32000/32000 [==============================] - 17s 519us/sample - loss: 0.6600 - accuracy: 0.6128 - val_loss: 0.6560 - val_accuracy: 0.6108\n",
      "Epoch 3/20\n",
      "32000/32000 [==============================] - 17s 521us/sample - loss: 0.6449 - accuracy: 0.6420 - val_loss: 0.6849 - val_accuracy: 0.5773\n",
      "Epoch 4/20\n",
      "32000/32000 [==============================] - 17s 519us/sample - loss: 0.6261 - accuracy: 0.6658 - val_loss: 2.5887 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "32000/32000 [==============================] - 17s 519us/sample - loss: 0.6066 - accuracy: 0.6882 - val_loss: 0.6233 - val_accuracy: 0.6658\n",
      "Epoch 6/20\n",
      "32000/32000 [==============================] - 17s 520us/sample - loss: 0.5991 - accuracy: 0.6925 - val_loss: 0.5847 - val_accuracy: 0.6973\n",
      "Epoch 7/20\n",
      "32000/32000 [==============================] - 17s 521us/sample - loss: 0.5976 - accuracy: 0.6943 - val_loss: 0.9445 - val_accuracy: 0.5805\n",
      "Epoch 8/20\n",
      "32000/32000 [==============================] - 17s 519us/sample - loss: 0.5969 - accuracy: 0.6952 - val_loss: 0.7118 - val_accuracy: 0.5042\n",
      "Epoch 9/20\n",
      "32000/32000 [==============================] - 18s 556us/sample - loss: 0.5817 - accuracy: 0.7050 - val_loss: 0.7045 - val_accuracy: 0.6425\n",
      "Epoch 10/20\n",
      "32000/32000 [==============================] - 17s 524us/sample - loss: 0.5794 - accuracy: 0.7061 - val_loss: 0.6373 - val_accuracy: 0.6565\n",
      "Epoch 11/20\n",
      "32000/32000 [==============================] - 17s 528us/sample - loss: 0.5738 - accuracy: 0.7097 - val_loss: 0.5699 - val_accuracy: 0.7175\n",
      "Epoch 12/20\n",
      "32000/32000 [==============================] - 17s 531us/sample - loss: 0.5694 - accuracy: 0.7159 - val_loss: 0.6314 - val_accuracy: 0.6670\n",
      "Epoch 13/20\n",
      "32000/32000 [==============================] - 17s 535us/sample - loss: 0.5676 - accuracy: 0.7148 - val_loss: 0.6327 - val_accuracy: 0.6795\n",
      "Epoch 14/20\n",
      "32000/32000 [==============================] - 18s 560us/sample - loss: 0.5629 - accuracy: 0.7175 - val_loss: 0.5792 - val_accuracy: 0.7080\n",
      "Epoch 15/20\n",
      "32000/32000 [==============================] - 19s 597us/sample - loss: 0.5600 - accuracy: 0.7198 - val_loss: 0.6423 - val_accuracy: 0.6875\n",
      "Epoch 16/20\n",
      "32000/32000 [==============================] - 18s 573us/sample - loss: 0.5566 - accuracy: 0.7217 - val_loss: 0.5575 - val_accuracy: 0.7247\n",
      "Epoch 17/20\n",
      "32000/32000 [==============================] - 18s 570us/sample - loss: 0.5553 - accuracy: 0.7235 - val_loss: 0.5974 - val_accuracy: 0.7105\n",
      "Epoch 18/20\n",
      "32000/32000 [==============================] - 18s 574us/sample - loss: 0.5539 - accuracy: 0.7248 - val_loss: 0.5572 - val_accuracy: 0.7207\n",
      "Epoch 19/20\n",
      "32000/32000 [==============================] - 18s 577us/sample - loss: 0.5531 - accuracy: 0.7237 - val_loss: 0.5651 - val_accuracy: 0.7145\n",
      "Epoch 20/20\n",
      "32000/32000 [==============================] - 19s 580us/sample - loss: 0.5513 - accuracy: 0.7258 - val_loss: 0.5633 - val_accuracy: 0.7205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DDF5AD4DC8>,\n",
       "                   param_distributions={'factors': [0.1, 0.2, 0.3, 0.4, 0.5,\n",
       "                                                    0.55, 0.6],\n",
       "                                        'lr_init': [0.001, 0.005, 0.01, 0.05]})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"factors\":[0.1, 0.2, 0.3, 0.4, 0.5, 0.55, 0.6],\n",
    "    \"lr_init\":[0.001, 0.005, 0.01, 0.05],\n",
    "}\n",
    "\n",
    "rnd_search_lr = RandomizedSearchCV(lr_wrap, param_distribs, cv = 3)\n",
    "\n",
    "#exponential_decay_fn = exponential_decay(lr_init, s = 20) \n",
    "#lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)   \n",
    "rnd_search_lr.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_init': 0.05, 'factors': 0.1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Train the ResNet with optimized learning parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/25\n",
      "256000/256000 [==============================] - 153s 599us/sample - loss: 0.6337 - accuracy: 0.6510 - val_loss: 0.6822 - val_accuracy: 0.5662\n",
      "Epoch 2/25\n",
      "256000/256000 [==============================] - 151s 589us/sample - loss: 0.6017 - accuracy: 0.6912 - val_loss: 0.6020 - val_accuracy: 0.6904\n",
      "Epoch 3/25\n",
      "256000/256000 [==============================] - 151s 590us/sample - loss: 0.5902 - accuracy: 0.7020 - val_loss: 0.7775 - val_accuracy: 0.5091\n",
      "Epoch 4/25\n",
      "256000/256000 [==============================] - 150s 586us/sample - loss: 0.5852 - accuracy: 0.7053 - val_loss: 0.6373 - val_accuracy: 0.6738\n",
      "Epoch 5/25\n",
      "256000/256000 [==============================] - 156s 608us/sample - loss: 0.5628 - accuracy: 0.7194 - val_loss: 0.5967 - val_accuracy: 0.7260\n",
      "Epoch 6/25\n",
      "256000/256000 [==============================] - 155s 606us/sample - loss: 0.5581 - accuracy: 0.7228 - val_loss: 8.5761 - val_accuracy: 0.7263\n",
      "Epoch 7/25\n",
      "256000/256000 [==============================] - 155s 606us/sample - loss: 0.5554 - accuracy: 0.7242 - val_loss: 0.5711 - val_accuracy: 0.7097\n",
      "Epoch 8/25\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5539 - accuracy: 0.7256 - val_loss: 0.5682 - val_accuracy: 0.7290\n",
      "Epoch 9/25\n",
      "256000/256000 [==============================] - 169s 659us/sample - loss: 0.5522 - accuracy: 0.7271 - val_loss: 0.5638 - val_accuracy: 0.7196\n",
      "Epoch 10/25\n",
      "256000/256000 [==============================] - 167s 651us/sample - loss: 0.5519 - accuracy: 0.7268 - val_loss: 0.5467 - val_accuracy: 0.7311\n",
      "Epoch 11/25\n",
      "256000/256000 [==============================] - 170s 666us/sample - loss: 0.5507 - accuracy: 0.7278 - val_loss: 0.5498 - val_accuracy: 0.7282\n",
      "Epoch 12/25\n",
      "256000/256000 [==============================] - 174s 680us/sample - loss: 0.5500 - accuracy: 0.7285 - val_loss: 0.5789 - val_accuracy: 0.7179\n",
      "Epoch 13/25\n",
      "256000/256000 [==============================] - 167s 654us/sample - loss: 0.5462 - accuracy: 0.7305 - val_loss: 0.5422 - val_accuracy: 0.7324\n",
      "Epoch 14/25\n",
      "256000/256000 [==============================] - 166s 648us/sample - loss: 0.5453 - accuracy: 0.7307 - val_loss: 0.5434 - val_accuracy: 0.7327\n",
      "Epoch 15/25\n",
      "256000/256000 [==============================] - 165s 646us/sample - loss: 0.5456 - accuracy: 0.7302 - val_loss: 0.5420 - val_accuracy: 0.7327\n",
      "Epoch 16/25\n",
      "256000/256000 [==============================] - 166s 650us/sample - loss: 0.5456 - accuracy: 0.7311 - val_loss: 0.5423 - val_accuracy: 0.7329\n",
      "Epoch 17/25\n",
      "256000/256000 [==============================] - 168s 656us/sample - loss: 0.5451 - accuracy: 0.7309 - val_loss: 0.5414 - val_accuracy: 0.7330\n",
      "Epoch 18/25\n",
      "256000/256000 [==============================] - 167s 651us/sample - loss: 0.5450 - accuracy: 0.7307 - val_loss: 0.5433 - val_accuracy: 0.7311\n",
      "Epoch 19/25\n",
      "256000/256000 [==============================] - 166s 647us/sample - loss: 0.5450 - accuracy: 0.7313 - val_loss: 0.5415 - val_accuracy: 0.7331\n",
      "Epoch 20/25\n",
      "256000/256000 [==============================] - 153s 599us/sample - loss: 0.5445 - accuracy: 0.7314 - val_loss: 0.5412 - val_accuracy: 0.7329\n",
      "Epoch 21/25\n",
      "256000/256000 [==============================] - 151s 589us/sample - loss: 0.5448 - accuracy: 0.7311 - val_loss: 0.5412 - val_accuracy: 0.7331\n",
      "Epoch 22/25\n",
      "256000/256000 [==============================] - 150s 585us/sample - loss: 0.5447 - accuracy: 0.7311 - val_loss: 0.5412 - val_accuracy: 0.7332\n",
      "Epoch 23/25\n",
      "256000/256000 [==============================] - 151s 589us/sample - loss: 0.5445 - accuracy: 0.7323 - val_loss: 0.5412 - val_accuracy: 0.7332\n",
      "Epoch 24/25\n",
      "256000/256000 [==============================] - 151s 590us/sample - loss: 0.5445 - accuracy: 0.7314 - val_loss: 0.5412 - val_accuracy: 0.7333\n",
      "Epoch 25/25\n",
      "256000/256000 [==============================] - 151s 588us/sample - loss: 0.5444 - accuracy: 0.7312 - val_loss: 0.5412 - val_accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "tensorflow.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal', \n",
    "                 input_shape=(img_rows, img_cols, nb_channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(DefaultConv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "prev_filters = 64\n",
    "for filters in [16] * 1 + [32] * 2 + [64] * 1:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "model.add(MaxPooling2D(pool_size=3, strides=1, padding=\"SAME\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.05), metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1.e-6)\n",
    "#learning_schedule = \n",
    "history=model.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 8s 205us/sample - loss: 0.5412 - accuracy: 0.7333\n",
      "\n",
      "Validation loss / accuracy: 0.5412 / 0.7333\n",
      "Validation ROC AUC: 0.80162424\n",
      "40000/40000 [==============================] - 8s 191us/sample - loss: 0.5376 - accuracy: 0.7352\n",
      "\n",
      "Test loss / accuracy: 0.5376 / 0.7352\n",
      "Test ROC AUC: 0.80502400875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ResNet ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the optimized learning rate didn't improve the overall model performance. So, let's build an ensemble and check if we can enhance the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Create an Ensemble of 50 ResNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_models = 50\n",
    "\n",
    "model = [0] * no_of_models\n",
    "\n",
    "for index in range(no_of_models):\n",
    "    model[index] = Sequential()\n",
    "    model[index].add(Conv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal', \n",
    "                 input_shape=(img_rows, img_cols, nb_channels)))\n",
    "    model[index].add(BatchNormalization())\n",
    "    model[index].add(Activation(\"relu\"))\n",
    "    model[index].add(DefaultConv2D(16, kernel_size=3, padding='same', kernel_initializer='glorot_normal'))\n",
    "    model[index].add(BatchNormalization())\n",
    "    model[index].add(Activation(\"relu\"))\n",
    "    model[index].add(MaxPooling2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "    prev_filters = 64\n",
    "    for filters in [16] * 1 + [32] * 2 + [64] * 1:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        model[index].add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "    model[index].add(MaxPooling2D(pool_size=3, strides=1, padding=\"SAME\"))\n",
    "    model[index].add(Flatten())\n",
    "    model[index].add(Dense(256, activation='relu'))\n",
    "    model[index].add(BatchNormalization())\n",
    "    model[index].add(Dropout(0.3))\n",
    "    model[index].add(Dense(128, activation='relu'))\n",
    "    model[index].add(BatchNormalization())\n",
    "    model[index].add(Dropout(0.3))\n",
    "    model[index].add(Dense(64, activation='relu'))\n",
    "    model[index].add(BatchNormalization())\n",
    "    model[index].add(Dropout(0.2))\n",
    "    model[index].add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model[index].compile(loss='binary_crossentropy', optimizer=Adam(lr=0.05), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 50 ResNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 122s 477us/sample - loss: 0.6442 - accuracy: 0.6369 - val_loss: 0.7189 - val_accuracy: 0.5113\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.6027 - accuracy: 0.6905 - val_loss: 2.0652 - val_accuracy: 0.6148\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5895 - accuracy: 0.7032 - val_loss: 0.6035 - val_accuracy: 0.6956\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 119s 466us/sample - loss: 0.5891 - accuracy: 0.7022 - val_loss: 0.6012 - val_accuracy: 0.6952\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5812 - accuracy: 0.7096 - val_loss: 3.8298 - val_accuracy: 0.7090\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5873 - accuracy: 0.7035 - val_loss: 0.5911 - val_accuracy: 0.7211\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5764 - accuracy: 0.7141 - val_loss: 0.5655 - val_accuracy: 0.7171\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5731 - accuracy: 0.7147 - val_loss: 0.7255 - val_accuracy: 0.5001\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5724 - accuracy: 0.7157 - val_loss: 0.6189 - val_accuracy: 0.6647\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5744 - accuracy: 0.7098 - val_loss: 0.5546 - val_accuracy: 0.7242\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5562 - accuracy: 0.7259 - val_loss: 0.5474 - val_accuracy: 0.7324\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5526 - accuracy: 0.7273 - val_loss: 0.5696 - val_accuracy: 0.7291\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5504 - accuracy: 0.7290 - val_loss: 0.5451 - val_accuracy: 0.7305\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 120s 469us/sample - loss: 0.5502 - accuracy: 0.7291 - val_loss: 0.5441 - val_accuracy: 0.7304\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5492 - accuracy: 0.7300 - val_loss: 0.5428 - val_accuracy: 0.7327\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 121s 472us/sample - loss: 0.6380 - accuracy: 0.6465 - val_loss: 0.6970 - val_accuracy: 0.4983\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.6001 - accuracy: 0.6927 - val_loss: 0.6979 - val_accuracy: 0.5069\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5881 - accuracy: 0.7032 - val_loss: 8.8240 - val_accuracy: 0.6866\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5608 - accuracy: 0.7222 - val_loss: 0.5583 - val_accuracy: 0.7236\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5566 - accuracy: 0.7239 - val_loss: 0.5492 - val_accuracy: 0.7279\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5540 - accuracy: 0.7262 - val_loss: 0.5591 - val_accuracy: 0.7277\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5527 - accuracy: 0.7274 - val_loss: 0.5455 - val_accuracy: 0.7318\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 118s 463us/sample - loss: 0.5510 - accuracy: 0.7276 - val_loss: 0.5553 - val_accuracy: 0.7320\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5494 - accuracy: 0.7291 - val_loss: 0.5582 - val_accuracy: 0.7192\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5461 - accuracy: 0.7309 - val_loss: 0.5412 - val_accuracy: 0.7348\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5450 - accuracy: 0.7319 - val_loss: 0.5418 - val_accuracy: 0.7347\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5447 - accuracy: 0.7319 - val_loss: 0.5413 - val_accuracy: 0.7337\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5439 - accuracy: 0.7320 - val_loss: 0.5407 - val_accuracy: 0.7350\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5438 - accuracy: 0.7326 - val_loss: 0.5408 - val_accuracy: 0.7351\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5440 - accuracy: 0.7324 - val_loss: 0.5407 - val_accuracy: 0.7354\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 121s 473us/sample - loss: 0.6337 - accuracy: 0.6502 - val_loss: 0.8870 - val_accuracy: 0.5465\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 118s 463us/sample - loss: 0.6039 - accuracy: 0.6878 - val_loss: 0.7227 - val_accuracy: 0.5296\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.6350 - accuracy: 0.6478 - val_loss: 0.6567 - val_accuracy: 0.6163\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.6085 - accuracy: 0.6834 - val_loss: 0.7255 - val_accuracy: 0.5429\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5965 - accuracy: 0.6958 - val_loss: 0.5746 - val_accuracy: 0.7145\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 120s 469us/sample - loss: 0.5912 - accuracy: 0.7030 - val_loss: 51819.1500 - val_accuracy: 0.6734\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 119s 463us/sample - loss: 0.5893 - accuracy: 0.7019 - val_loss: 71.1787 - val_accuracy: 0.6790\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 119s 463us/sample - loss: 0.5622 - accuracy: 0.7220 - val_loss: 0.5907 - val_accuracy: 0.6969\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5591 - accuracy: 0.7228 - val_loss: 0.5580 - val_accuracy: 0.7228\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5587 - accuracy: 0.7234 - val_loss: 0.5551 - val_accuracy: 0.7241\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 119s 465us/sample - loss: 0.5573 - accuracy: 0.7241 - val_loss: 0.5516 - val_accuracy: 0.7279\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5566 - accuracy: 0.7242 - val_loss: 0.5758 - val_accuracy: 0.7122\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5552 - accuracy: 0.7253 - val_loss: 0.5500 - val_accuracy: 0.7286\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 118s 463us/sample - loss: 0.5549 - accuracy: 0.7263 - val_loss: 0.5859 - val_accuracy: 0.6970\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5542 - accuracy: 0.7262 - val_loss: 0.5505 - val_accuracy: 0.7264\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 122s 479us/sample - loss: 0.6375 - accuracy: 0.6456 - val_loss: 0.7393 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.6005 - accuracy: 0.6916 - val_loss: 248.3653 - val_accuracy: 0.6899\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5993 - accuracy: 0.6906 - val_loss: 0.6959 - val_accuracy: 0.5067\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5921 - accuracy: 0.7003 - val_loss: 0.7086 - val_accuracy: 0.5019\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5850 - accuracy: 0.7062 - val_loss: 1.8612 - val_accuracy: 0.7018\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5611 - accuracy: 0.7212 - val_loss: 291.8206 - val_accuracy: 0.7257\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5587 - accuracy: 0.7228 - val_loss: 0.5578 - val_accuracy: 0.7234\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5570 - accuracy: 0.7235 - val_loss: 0.6036 - val_accuracy: 0.6953\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 119s 463us/sample - loss: 0.5555 - accuracy: 0.7252 - val_loss: 9.5127 - val_accuracy: 0.7143\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5530 - accuracy: 0.7258 - val_loss: 0.5480 - val_accuracy: 0.7282\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5522 - accuracy: 0.7266 - val_loss: 0.5480 - val_accuracy: 0.7281\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 119s 464us/sample - loss: 0.5525 - accuracy: 0.7265 - val_loss: 0.5476 - val_accuracy: 0.7284\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 118s 462us/sample - loss: 0.5519 - accuracy: 0.7269 - val_loss: 0.5478 - val_accuracy: 0.7276\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 119s 463us/sample - loss: 0.5513 - accuracy: 0.7268 - val_loss: 0.5477 - val_accuracy: 0.7280\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 119s 466us/sample - loss: 0.5513 - accuracy: 0.7271 - val_loss: 0.5618 - val_accuracy: 0.7278\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 125s 488us/sample - loss: 0.6498 - accuracy: 0.6268 - val_loss: 1.0834 - val_accuracy: 0.5270\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.6102 - accuracy: 0.6812 - val_loss: 0.7015 - val_accuracy: 0.6430\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 119s 467us/sample - loss: 0.5987 - accuracy: 0.6942 - val_loss: 0.6575 - val_accuracy: 0.6012\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5904 - accuracy: 0.6999 - val_loss: 0.5829 - val_accuracy: 0.6974\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5847 - accuracy: 0.7053 - val_loss: 0.6746 - val_accuracy: 0.6781\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5812 - accuracy: 0.7081 - val_loss: 0.6136 - val_accuracy: 0.7186\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5584 - accuracy: 0.7233 - val_loss: 0.5654 - val_accuracy: 0.7258\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5550 - accuracy: 0.7254 - val_loss: 0.5550 - val_accuracy: 0.7302\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5537 - accuracy: 0.7257 - val_loss: 0.5465 - val_accuracy: 0.7294\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5530 - accuracy: 0.7261 - val_loss: 0.5472 - val_accuracy: 0.7295\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 120s 469us/sample - loss: 0.5525 - accuracy: 0.7268 - val_loss: 0.5494 - val_accuracy: 0.7265\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 122s 476us/sample - loss: 0.5494 - accuracy: 0.7284 - val_loss: 0.5442 - val_accuracy: 0.7305\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5490 - accuracy: 0.7288 - val_loss: 0.5452 - val_accuracy: 0.7311\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 120s 467us/sample - loss: 0.5484 - accuracy: 0.7294 - val_loss: 0.5445 - val_accuracy: 0.7317\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 120s 468us/sample - loss: 0.5485 - accuracy: 0.7288 - val_loss: 0.5440 - val_accuracy: 0.7313\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 327s 1ms/sample - loss: 0.6332 - accuracy: 0.6549 - val_loss: 0.6181 - val_accuracy: 0.6555\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5990 - accuracy: 0.6946 - val_loss: 0.6304 - val_accuracy: 0.6622\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5913 - accuracy: 0.7007 - val_loss: 0.5980 - val_accuracy: 0.6939\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5849 - accuracy: 0.7052 - val_loss: 0.6613 - val_accuracy: 0.7000\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.6320 - accuracy: 0.6501 - val_loss: 0.6167 - val_accuracy: 0.6655\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5866 - accuracy: 0.7002 - val_loss: 0.5789 - val_accuracy: 0.7082\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5749 - accuracy: 0.7118 - val_loss: 0.5656 - val_accuracy: 0.7186\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5692 - accuracy: 0.7163 - val_loss: 0.5758 - val_accuracy: 0.7120\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5655 - accuracy: 0.7187 - val_loss: 0.5652 - val_accuracy: 0.7162\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5614 - accuracy: 0.7206 - val_loss: 0.5574 - val_accuracy: 0.7245\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 320s 1ms/sample - loss: 0.5590 - accuracy: 0.7220 - val_loss: 0.5667 - val_accuracy: 0.7139\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5576 - accuracy: 0.7229 - val_loss: 0.5513 - val_accuracy: 0.7241\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5558 - accuracy: 0.7244 - val_loss: 0.5517 - val_accuracy: 0.7279\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 321s 1ms/sample - loss: 0.5543 - accuracy: 0.7251 - val_loss: 0.5518 - val_accuracy: 0.7265\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 322s 1ms/sample - loss: 0.5506 - accuracy: 0.7278 - val_loss: 0.5462 - val_accuracy: 0.7294\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 134s 524us/sample - loss: 0.6381 - accuracy: 0.6462 - val_loss: 0.6134 - val_accuracy: 0.6688\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 132s 514us/sample - loss: 0.6006 - accuracy: 0.6932 - val_loss: 0.7320 - val_accuracy: 0.6905\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 132s 514us/sample - loss: 0.5905 - accuracy: 0.7025 - val_loss: 0.6876 - val_accuracy: 0.5284\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 128s 498us/sample - loss: 0.5625 - accuracy: 0.7198 - val_loss: 0.5595 - val_accuracy: 0.7236\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 128s 499us/sample - loss: 0.5577 - accuracy: 0.7238 - val_loss: 0.5503 - val_accuracy: 0.7298\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 128s 499us/sample - loss: 0.5548 - accuracy: 0.7251 - val_loss: 0.5586 - val_accuracy: 0.7222\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 128s 498us/sample - loss: 0.5533 - accuracy: 0.7263 - val_loss: 0.5651 - val_accuracy: 0.7159\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 128s 499us/sample - loss: 0.5485 - accuracy: 0.7289 - val_loss: 0.5443 - val_accuracy: 0.7332\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 127s 498us/sample - loss: 0.5475 - accuracy: 0.7300 - val_loss: 0.5437 - val_accuracy: 0.7340\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 128s 499us/sample - loss: 0.5475 - accuracy: 0.7302 - val_loss: 0.5447 - val_accuracy: 0.7336\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 130s 506us/sample - loss: 0.5473 - accuracy: 0.7309 - val_loss: 0.5435 - val_accuracy: 0.7333\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 128s 499us/sample - loss: 0.5472 - accuracy: 0.7301 - val_loss: 0.5431 - val_accuracy: 0.7343\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 128s 498us/sample - loss: 0.5467 - accuracy: 0.7307 - val_loss: 0.5434 - val_accuracy: 0.7323\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256000/256000 [==============================] - 127s 498us/sample - loss: 0.5463 - accuracy: 0.7315 - val_loss: 0.5431 - val_accuracy: 0.7339\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 127s 497us/sample - loss: 0.5461 - accuracy: 0.7309 - val_loss: 0.5429 - val_accuracy: 0.7343\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 121s 471us/sample - loss: 0.6323 - accuracy: 0.6513 - val_loss: 0.8698 - val_accuracy: 0.5002\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.6015 - accuracy: 0.6904 - val_loss: 0.6175 - val_accuracy: 0.6895\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5937 - accuracy: 0.7000 - val_loss: 1.2795 - val_accuracy: 0.5802\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5871 - accuracy: 0.7034 - val_loss: 9642.7221 - val_accuracy: 0.6444\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 118s 463us/sample - loss: 0.5606 - accuracy: 0.7209 - val_loss: 0.6302 - val_accuracy: 0.7217\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5567 - accuracy: 0.7229 - val_loss: 0.6014 - val_accuracy: 0.7193\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 117s 459us/sample - loss: 0.5553 - accuracy: 0.7245 - val_loss: 0.5489 - val_accuracy: 0.7298\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5538 - accuracy: 0.7252 - val_loss: 0.5553 - val_accuracy: 0.7309\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5528 - accuracy: 0.7262 - val_loss: 0.5494 - val_accuracy: 0.7309\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 126s 491us/sample - loss: 0.5497 - accuracy: 0.7280 - val_loss: 0.5441 - val_accuracy: 0.7327\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 126s 491us/sample - loss: 0.5490 - accuracy: 0.7284 - val_loss: 0.5441 - val_accuracy: 0.7321\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 126s 491us/sample - loss: 0.5490 - accuracy: 0.7286 - val_loss: 0.5438 - val_accuracy: 0.7332\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 125s 490us/sample - loss: 0.5483 - accuracy: 0.7285 - val_loss: 0.5439 - val_accuracy: 0.7328\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 126s 491us/sample - loss: 0.5481 - accuracy: 0.7294 - val_loss: 0.5439 - val_accuracy: 0.7317\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5479 - accuracy: 0.7290 - val_loss: 0.5435 - val_accuracy: 0.7319\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 121s 471us/sample - loss: 0.6349 - accuracy: 0.6511 - val_loss: 0.5953 - val_accuracy: 0.6919\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5988 - accuracy: 0.6939 - val_loss: 0.7495 - val_accuracy: 0.6339\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5920 - accuracy: 0.6995 - val_loss: 0.7436 - val_accuracy: 0.5352\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5668 - accuracy: 0.7172 - val_loss: 11.8672 - val_accuracy: 0.6851\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5607 - accuracy: 0.7216 - val_loss: 189.1284 - val_accuracy: 0.7270\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5548 - accuracy: 0.7250 - val_loss: 0.5494 - val_accuracy: 0.7296\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5543 - accuracy: 0.7256 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5535 - accuracy: 0.7254 - val_loss: 0.5489 - val_accuracy: 0.7310\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5527 - accuracy: 0.7261 - val_loss: 0.5500 - val_accuracy: 0.7297\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5529 - accuracy: 0.7263 - val_loss: 0.5479 - val_accuracy: 0.7301\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5524 - accuracy: 0.7270 - val_loss: 0.5495 - val_accuracy: 0.7302\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5521 - accuracy: 0.7269 - val_loss: 0.5479 - val_accuracy: 0.7296\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5512 - accuracy: 0.7275 - val_loss: 0.5466 - val_accuracy: 0.7314\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5509 - accuracy: 0.7271 - val_loss: 0.5466 - val_accuracy: 0.7316\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5511 - accuracy: 0.7275 - val_loss: 0.5466 - val_accuracy: 0.7317\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 120s 469us/sample - loss: 0.6632 - accuracy: 0.6061 - val_loss: 0.7149 - val_accuracy: 0.5016\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 118s 459us/sample - loss: 0.6201 - accuracy: 0.6716 - val_loss: 0.7377 - val_accuracy: 0.5683\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 118s 459us/sample - loss: 0.5944 - accuracy: 0.6994 - val_loss: 0.8088 - val_accuracy: 0.5134\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5659 - accuracy: 0.7185 - val_loss: 0.5568 - val_accuracy: 0.7248\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 118s 459us/sample - loss: 0.5612 - accuracy: 0.7207 - val_loss: 0.5531 - val_accuracy: 0.7240\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 118s 459us/sample - loss: 0.5581 - accuracy: 0.7226 - val_loss: 0.5546 - val_accuracy: 0.7248\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5563 - accuracy: 0.7241 - val_loss: 0.5513 - val_accuracy: 0.7254\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5548 - accuracy: 0.7249 - val_loss: 0.5607 - val_accuracy: 0.7258\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 118s 459us/sample - loss: 0.5531 - accuracy: 0.7265 - val_loss: 0.5485 - val_accuracy: 0.7289\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 118s 460us/sample - loss: 0.5525 - accuracy: 0.7268 - val_loss: 0.5508 - val_accuracy: 0.7268\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 117s 458us/sample - loss: 0.5513 - accuracy: 0.7274 - val_loss: 0.5969 - val_accuracy: 0.7217\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 117s 458us/sample - loss: 0.5474 - accuracy: 0.7294 - val_loss: 0.7320 - val_accuracy: 0.7326\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 118s 461us/sample - loss: 0.5465 - accuracy: 0.7306 - val_loss: 0.5417 - val_accuracy: 0.7326\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 118s 459us/sample - loss: 0.5461 - accuracy: 0.7308 - val_loss: 29.6539 - val_accuracy: 0.7326\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 117s 458us/sample - loss: 0.5460 - accuracy: 0.7304 - val_loss: 0.5412 - val_accuracy: 0.7331\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 127s 494us/sample - loss: 0.6444 - accuracy: 0.6356 - val_loss: 0.6943 - val_accuracy: 0.5018\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 124s 484us/sample - loss: 0.6024 - accuracy: 0.6904 - val_loss: 0.6081 - val_accuracy: 0.6878\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 124s 485us/sample - loss: 0.5933 - accuracy: 0.6992 - val_loss: 0.6226 - val_accuracy: 0.6788\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 124s 485us/sample - loss: 0.5849 - accuracy: 0.7051 - val_loss: 2.2321 - val_accuracy: 0.6783\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5597 - accuracy: 0.7217 - val_loss: 0.5508 - val_accuracy: 0.7251\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5560 - accuracy: 0.7240 - val_loss: 0.5534 - val_accuracy: 0.7274\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5541 - accuracy: 0.7254 - val_loss: 0.5491 - val_accuracy: 0.7272\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5529 - accuracy: 0.7266 - val_loss: 0.5552 - val_accuracy: 0.7244\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 123s 481us/sample - loss: 0.5513 - accuracy: 0.7276 - val_loss: 0.5461 - val_accuracy: 0.7301\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5504 - accuracy: 0.7282 - val_loss: 0.5461 - val_accuracy: 0.7294\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 124s 482us/sample - loss: 0.5496 - accuracy: 0.7287 - val_loss: 0.5505 - val_accuracy: 0.7290\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5462 - accuracy: 0.7307 - val_loss: 0.5429 - val_accuracy: 0.7327\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 124s 482us/sample - loss: 0.5451 - accuracy: 0.7315 - val_loss: 0.5426 - val_accuracy: 0.7329\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 124s 483us/sample - loss: 0.5447 - accuracy: 0.7318 - val_loss: 0.5429 - val_accuracy: 0.7327\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 123s 482us/sample - loss: 0.5447 - accuracy: 0.7325 - val_loss: 0.5425 - val_accuracy: 0.7339\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 134s 524us/sample - loss: 0.6428 - accuracy: 0.6406 - val_loss: 0.8545 - val_accuracy: 0.5713\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.6149 - accuracy: 0.6769 - val_loss: 0.8338 - val_accuracy: 0.6327\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5988 - accuracy: 0.6949 - val_loss: 0.6364 - val_accuracy: 0.6259\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 131s 513us/sample - loss: 0.5951 - accuracy: 0.6982 - val_loss: 0.8264 - val_accuracy: 0.5056\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5993 - accuracy: 0.6930 - val_loss: 1.9629 - val_accuracy: 0.6497\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5685 - accuracy: 0.7161 - val_loss: 0.7333 - val_accuracy: 0.7179\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5660 - accuracy: 0.7187 - val_loss: 0.5593 - val_accuracy: 0.7218\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 131s 513us/sample - loss: 0.5636 - accuracy: 0.7193 - val_loss: 0.6361 - val_accuracy: 0.7217\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 131s 513us/sample - loss: 0.5618 - accuracy: 0.7210 - val_loss: 0.5551 - val_accuracy: 0.7260\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5611 - accuracy: 0.7212 - val_loss: 0.5747 - val_accuracy: 0.7172\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5596 - accuracy: 0.7218 - val_loss: 0.5619 - val_accuracy: 0.7207\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 131s 512us/sample - loss: 0.5568 - accuracy: 0.7237 - val_loss: 0.5514 - val_accuracy: 0.7280\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 132s 516us/sample - loss: 0.5559 - accuracy: 0.7238 - val_loss: 0.5516 - val_accuracy: 0.7268\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 133s 518us/sample - loss: 0.5556 - accuracy: 0.7244 - val_loss: 0.5510 - val_accuracy: 0.7288\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 133s 518us/sample - loss: 0.5556 - accuracy: 0.7236 - val_loss: 0.5508 - val_accuracy: 0.7278\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 156s 611us/sample - loss: 0.6429 - accuracy: 0.6403 - val_loss: 0.6747 - val_accuracy: 0.5731\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 146s 569us/sample - loss: 0.6044 - accuracy: 0.6885 - val_loss: 0.5988 - val_accuracy: 0.6898\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 154s 601us/sample - loss: 0.5928 - accuracy: 0.6995 - val_loss: 0.6854 - val_accuracy: 0.5179\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 145s 567us/sample - loss: 0.5843 - accuracy: 0.7060 - val_loss: 0.7320 - val_accuracy: 0.5272\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 144s 564us/sample - loss: 0.5615 - accuracy: 0.7205 - val_loss: 0.5515 - val_accuracy: 0.7280\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 144s 564us/sample - loss: 0.5559 - accuracy: 0.7245 - val_loss: 0.5542 - val_accuracy: 0.7257\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 145s 565us/sample - loss: 0.5543 - accuracy: 0.7256 - val_loss: 0.5864 - val_accuracy: 0.7275\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 145s 565us/sample - loss: 0.5504 - accuracy: 0.7275 - val_loss: 0.5463 - val_accuracy: 0.7318\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 154s 600us/sample - loss: 0.5494 - accuracy: 0.7280 - val_loss: 0.8026 - val_accuracy: 0.7315\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 146s 571us/sample - loss: 0.5497 - accuracy: 0.7278 - val_loss: 0.5457 - val_accuracy: 0.7323\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 145s 567us/sample - loss: 0.5492 - accuracy: 0.7289 - val_loss: 51.1739 - val_accuracy: 0.7315\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 155s 606us/sample - loss: 0.5489 - accuracy: 0.7285 - val_loss: 25.7700 - val_accuracy: 0.7320\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 146s 569us/sample - loss: 0.5480 - accuracy: 0.7287 - val_loss: 18.0473 - val_accuracy: 0.7323\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 146s 570us/sample - loss: 0.5482 - accuracy: 0.7291 - val_loss: 5.7943 - val_accuracy: 0.7325\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 154s 600us/sample - loss: 0.5483 - accuracy: 0.7289 - val_loss: 60.9246 - val_accuracy: 0.7321\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 157s 612us/sample - loss: 0.6407 - accuracy: 0.6417 - val_loss: 0.9441 - val_accuracy: 0.5408\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 151s 589us/sample - loss: 0.6006 - accuracy: 0.6925 - val_loss: 0.7299 - val_accuracy: 0.6582\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 157s 613us/sample - loss: 0.5982 - accuracy: 0.6933 - val_loss: 0.5813 - val_accuracy: 0.7082\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 151s 589us/sample - loss: 0.5919 - accuracy: 0.6986 - val_loss: 0.6074 - val_accuracy: 0.6975\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 151s 590us/sample - loss: 0.5872 - accuracy: 0.7034 - val_loss: 0.6375 - val_accuracy: 0.6902\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 154s 603us/sample - loss: 0.5583 - accuracy: 0.7223 - val_loss: 0.5597 - val_accuracy: 0.7266\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 151s 589us/sample - loss: 0.5555 - accuracy: 0.7246 - val_loss: 0.5474 - val_accuracy: 0.7281\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 151s 590us/sample - loss: 0.5537 - accuracy: 0.7260 - val_loss: 0.5545 - val_accuracy: 0.7272\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 154s 602us/sample - loss: 0.5518 - accuracy: 0.7271 - val_loss: 0.5462 - val_accuracy: 0.7283\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 151s 592us/sample - loss: 0.5510 - accuracy: 0.7276 - val_loss: 0.5452 - val_accuracy: 0.7318\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256000/256000 [==============================] - 151s 591us/sample - loss: 0.5498 - accuracy: 0.7286 - val_loss: 0.5464 - val_accuracy: 0.7320\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 161s 630us/sample - loss: 0.5494 - accuracy: 0.7285 - val_loss: 0.5432 - val_accuracy: 0.7317\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 151s 588us/sample - loss: 0.5482 - accuracy: 0.7295 - val_loss: 0.5458 - val_accuracy: 0.7303\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 155s 607us/sample - loss: 0.5474 - accuracy: 0.7303 - val_loss: 58.0028 - val_accuracy: 0.7319\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 156s 611us/sample - loss: 0.5444 - accuracy: 0.7313 - val_loss: 3820.6905 - val_accuracy: 0.7338\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 157s 613us/sample - loss: 0.6374 - accuracy: 0.6450 - val_loss: 0.6861 - val_accuracy: 0.6791\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 154s 601us/sample - loss: 0.6001 - accuracy: 0.6933 - val_loss: 0.6802 - val_accuracy: 0.6548\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 153s 599us/sample - loss: 0.5891 - accuracy: 0.7031 - val_loss: 0.6973 - val_accuracy: 0.5289\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 153s 599us/sample - loss: 0.5830 - accuracy: 0.7072 - val_loss: 0.7164 - val_accuracy: 0.5163\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 153s 599us/sample - loss: 0.5584 - accuracy: 0.7231 - val_loss: 0.5500 - val_accuracy: 0.7271\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 159s 620us/sample - loss: 0.5545 - accuracy: 0.7247 - val_loss: 0.5631 - val_accuracy: 0.7171\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 159s 621us/sample - loss: 0.5531 - accuracy: 0.7263 - val_loss: 0.5458 - val_accuracy: 0.7301\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 159s 622us/sample - loss: 0.5516 - accuracy: 0.7272 - val_loss: 0.5593 - val_accuracy: 0.7217\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 159s 621us/sample - loss: 0.5500 - accuracy: 0.7280 - val_loss: 0.5448 - val_accuracy: 0.7304\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 159s 621us/sample - loss: 0.5493 - accuracy: 0.7284 - val_loss: 0.5554 - val_accuracy: 0.7248\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 159s 620us/sample - loss: 0.5495 - accuracy: 0.7288 - val_loss: 0.8909 - val_accuracy: 0.7330\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 159s 621us/sample - loss: 0.5455 - accuracy: 0.7306 - val_loss: 0.5513 - val_accuracy: 0.7341\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 159s 620us/sample - loss: 0.5446 - accuracy: 0.7317 - val_loss: 0.9880 - val_accuracy: 0.7344\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 159s 619us/sample - loss: 0.5439 - accuracy: 0.7316 - val_loss: 0.6729 - val_accuracy: 0.7353\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 159s 619us/sample - loss: 0.5442 - accuracy: 0.7314 - val_loss: 1.4034 - val_accuracy: 0.7349\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 173s 675us/sample - loss: 0.6467 - accuracy: 0.6333 - val_loss: 0.7858 - val_accuracy: 0.5813\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.6015 - accuracy: 0.6922 - val_loss: 0.7076 - val_accuracy: 0.6354\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 167s 654us/sample - loss: 0.5965 - accuracy: 0.6955 - val_loss: 0.6141 - val_accuracy: 0.6642\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5913 - accuracy: 0.7016 - val_loss: 0.7739 - val_accuracy: 0.5143\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5853 - accuracy: 0.7073 - val_loss: 0.6674 - val_accuracy: 0.6463\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5620 - accuracy: 0.7203 - val_loss: 0.5588 - val_accuracy: 0.7225\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 167s 652us/sample - loss: 0.5582 - accuracy: 0.7222 - val_loss: 0.5502 - val_accuracy: 0.7261\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 169s 661us/sample - loss: 0.5569 - accuracy: 0.7238 - val_loss: 0.5573 - val_accuracy: 0.7218\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5546 - accuracy: 0.7251 - val_loss: 0.5491 - val_accuracy: 0.7276\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5535 - accuracy: 0.7258 - val_loss: 0.5470 - val_accuracy: 0.7283\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 167s 654us/sample - loss: 0.5523 - accuracy: 0.7270 - val_loss: 0.5538 - val_accuracy: 0.7257\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5515 - accuracy: 0.7278 - val_loss: 0.5483 - val_accuracy: 0.7300\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 171s 666us/sample - loss: 0.5479 - accuracy: 0.7301 - val_loss: 0.5442 - val_accuracy: 0.7316\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 168s 655us/sample - loss: 0.5473 - accuracy: 0.7297 - val_loss: 0.5440 - val_accuracy: 0.7319\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 167s 653us/sample - loss: 0.5474 - accuracy: 0.7298 - val_loss: 0.5436 - val_accuracy: 0.7317\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "256000/256000 [==============================] - 177s 691us/sample - loss: 0.6356 - accuracy: 0.6478 - val_loss: 0.8087 - val_accuracy: 0.5094\n",
      "Epoch 2/15\n",
      "256000/256000 [==============================] - 173s 677us/sample - loss: 0.5996 - accuracy: 0.6929 - val_loss: 1.0364 - val_accuracy: 0.6274\n",
      "Epoch 3/15\n",
      "256000/256000 [==============================] - 173s 677us/sample - loss: 0.5924 - accuracy: 0.7004 - val_loss: 14.0384 - val_accuracy: 0.6184: 0.5924 - accura\n",
      "Epoch 4/15\n",
      "256000/256000 [==============================] - 173s 677us/sample - loss: 0.5660 - accuracy: 0.7188 - val_loss: 0.5584 - val_accuracy: 0.7242\n",
      "Epoch 5/15\n",
      "256000/256000 [==============================] - 173s 676us/sample - loss: 0.5618 - accuracy: 0.7216 - val_loss: 0.6939 - val_accuracy: 0.7259\n",
      "Epoch 6/15\n",
      "256000/256000 [==============================] - 174s 681us/sample - loss: 0.5594 - accuracy: 0.7234 - val_loss: 0.5549 - val_accuracy: 0.7277\n",
      "Epoch 7/15\n",
      "256000/256000 [==============================] - 174s 680us/sample - loss: 0.5576 - accuracy: 0.7245 - val_loss: 0.5505 - val_accuracy: 0.7295\n",
      "Epoch 8/15\n",
      "256000/256000 [==============================] - 174s 679us/sample - loss: 0.5562 - accuracy: 0.7253 - val_loss: 0.5579 - val_accuracy: 0.7234\n",
      "Epoch 9/15\n",
      "256000/256000 [==============================] - 175s 684us/sample - loss: 0.5543 - accuracy: 0.7264 - val_loss: 0.5500 - val_accuracy: 0.7301\n",
      "Epoch 10/15\n",
      "256000/256000 [==============================] - 175s 683us/sample - loss: 0.5537 - accuracy: 0.7269 - val_loss: 0.5520 - val_accuracy: 0.7255\n",
      "Epoch 11/15\n",
      "256000/256000 [==============================] - 174s 680us/sample - loss: 0.5526 - accuracy: 0.7273 - val_loss: 0.5689 - val_accuracy: 0.7158\n",
      "Epoch 12/15\n",
      "256000/256000 [==============================] - 174s 681us/sample - loss: 0.5485 - accuracy: 0.7297 - val_loss: 0.5446 - val_accuracy: 0.7316\n",
      "Epoch 13/15\n",
      "256000/256000 [==============================] - 175s 684us/sample - loss: 0.5475 - accuracy: 0.7304 - val_loss: 0.5438 - val_accuracy: 0.7315\n",
      "Epoch 14/15\n",
      "256000/256000 [==============================] - 175s 683us/sample - loss: 0.5470 - accuracy: 0.7308 - val_loss: 0.5439 - val_accuracy: 0.7321\n",
      "Epoch 15/15\n",
      "256000/256000 [==============================] - 178s 694us/sample - loss: 0.5471 - accuracy: 0.7303 - val_loss: 0.5436 - val_accuracy: 0.7322\n",
      "Train on 256000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      " 61248/256000 [======>.......................] - ETA: 2:20 - loss: 0.6695 - accuracy: 0.5942WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-907c346f7b75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         verbose=1, shuffle=True)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = [0] *no_of_models\n",
    "epochs = 15\n",
    "\n",
    "for j in range(no_of_models):\n",
    "   reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1.e-6)\n",
    "   history[j] = model[j].fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we were able to train only 17 ResNets, we will use them to make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.zeros([len(X_test), 17], dtype=np.float16)\n",
    "\n",
    "for j in range(17):\n",
    "    prob_predict =model[j].predict(X_test)   # the predicted probabilites of a model are added\n",
    "    Y_pred[:,j] = prob_predict.reshape([-1])\n",
    "\n",
    "threshold = 0.5\n",
    "Y_pred_class = np.where(Y_pred > threshold, 1 ,0)  # defining the class based on threshold probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `scipy.stats.mode` to get the majority votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred_class, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ResNet in the ensemble print the accuracy and also print the ensemble accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 14s 360us/sample - loss: 0.7517 - accuracy: 0.7368\n",
      "ResNet 1  Accuracy 0.73675\n",
      "40000/40000 [==============================] - 14s 358us/sample - loss: 0.5362 - accuracy: 0.7381\n",
      "ResNet 2  Accuracy 0.73810\n",
      "40000/40000 [==============================] - 15s 373us/sample - loss: 0.5450 - accuracy: 0.7305\n",
      "ResNet 3  Accuracy 0.73048\n",
      "40000/40000 [==============================] - 16s 389us/sample - loss: 0.5443 - accuracy: 0.7296\n",
      "ResNet 4  Accuracy 0.72962\n",
      "40000/40000 [==============================] - 16s 391us/sample - loss: 0.5413 - accuracy: 0.7344\n",
      "ResNet 5  Accuracy 0.73445\n",
      "40000/40000 [==============================] - 16s 397us/sample - loss: 0.5439 - accuracy: 0.7328\n",
      "ResNet 6  Accuracy 0.73277\n",
      "40000/40000 [==============================] - 14s 353us/sample - loss: 0.5385 - accuracy: 0.7354\n",
      "ResNet 7  Accuracy 0.73537\n",
      "40000/40000 [==============================] - 14s 360us/sample - loss: 0.5401 - accuracy: 0.7331\n",
      "ResNet 8  Accuracy 0.73310\n",
      "40000/40000 [==============================] - 15s 369us/sample - loss: 0.5414 - accuracy: 0.7336\n",
      "ResNet 9  Accuracy 0.73360\n",
      "40000/40000 [==============================] - 15s 381us/sample - loss: 0.5371 - accuracy: 0.7373\n",
      "ResNet 10  Accuracy 0.73733\n",
      "40000/40000 [==============================] - 15s 369us/sample - loss: 0.5385 - accuracy: 0.7354\n",
      "ResNet 11  Accuracy 0.73537\n",
      "40000/40000 [==============================] - 15s 377us/sample - loss: 0.5468 - accuracy: 0.7307\n",
      "ResNet 12  Accuracy 0.73072\n",
      "40000/40000 [==============================] - 15s 366us/sample - loss: 109.1985 - accuracy: 0.7317\n",
      "ResNet 13  Accuracy 0.73168\n",
      "40000/40000 [==============================] - 14s 361us/sample - loss: 2675.2740 - accuracy: 0.7370\n",
      "ResNet 14  Accuracy 0.73698\n",
      "40000/40000 [==============================] - 15s 364us/sample - loss: 1.4255 - accuracy: 0.7358\n",
      "ResNet 15  Accuracy 0.73577\n",
      "40000/40000 [==============================] - 15s 373us/sample - loss: 0.5405 - accuracy: 0.7344\n",
      "ResNet 16  Accuracy 0.73438\n",
      "40000/40000 [==============================] - 15s 374us/sample - loss: 0.5392 - accuracy: 0.7354\n",
      "ResNet 17  Accuracy 0.73535\n",
      "The Ensemble accuracy is  0.73845\n"
     ]
    }
   ],
   "source": [
    "for j in range(17):\n",
    "    los, accu = model[j].evaluate(X_test, y_test)\n",
    "    print(\"ResNet {0}  Accuracy {1:.5f}\".format(j+1, accu))\n",
    "ensem_accu = accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))\n",
    "print(\"The Ensemble accuracy is \", ensem_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble ROC AUC: 0.80804678125\n"
     ]
    }
   ],
   "source": [
    "Y_pred_averaged = Y_pred.mean(axis=1)  # finding the average of predicted probabilities by each ResNet.\n",
    "fpr, tpr, _ = roc_curve(y_test, Y_pred_averaged)  \n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Ensemble ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='Ensemble ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble increased the accuracy and AUC only slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ParticleImages.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "gpu_tf",
   "language": "python",
   "name": "gpu_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
